{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of image cleaning on the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from ctapipe.visualization import CameraDisplay\n",
    "from torchmetrics.classification import AUROC, Accuracy\n",
    "\n",
    "\n",
    "import gammalearn.data.LST_dataset as dsets\n",
    "from gammalearn.configuration.constants import GAMMA_ID, PROTON_ID\n",
    "\n",
    "THIS_DIR = Path.cwd()\n",
    "OUTPUT_DIR = THIS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_basename(path: str) -> str:\n",
    "    pattern = \"dl1.*\\.h5\"\n",
    "    match = re.search(pattern, path)\n",
    "    if match:\n",
    "        return match.group()[:-3]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp files\n",
    "example_dl1_file = THIS_DIR /  \"../../share/data/MC_data/dl1_gamma_example.h5\"\n",
    "assert example_dl1_file.exists(), f\"File {example_dl1_file} does not exist\"\n",
    "simu_type = \"mc\"\n",
    "example_name_mc = get_example_basename(example_dl1_file.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This define the required parameters loaded from an experiment settings file.\n",
    "#This function may be used when exp file is not available to test default dataset parameters.\n",
    "\n",
    "particle_dict = {\n",
    "    GAMMA_ID: 0,\n",
    "    PROTON_ID: 1,\n",
    "}\n",
    "\"\"\"particle_dict is mandatory and maps cta particle types with class id. e.g. gamma (0) is class 0\"\"\"\n",
    "targets = collections.OrderedDict(\n",
    "    {\n",
    "        \"energy\": {\n",
    "            \"output_shape\": 1,\n",
    "            \"loss\": torch.nn.L1Loss(reduction=\"none\"),\n",
    "            \"loss_weight\": 1,\n",
    "            \"metrics\": {\n",
    "                # 'functions': ,\n",
    "            },\n",
    "            \"mt_balancing\": True,\n",
    "        },\n",
    "        \"impact\": {\n",
    "            \"output_shape\": 2,\n",
    "            \"loss\": torch.nn.L1Loss(reduction=\"none\"),\n",
    "            \"loss_weight\": 1,\n",
    "            \"metrics\": {},\n",
    "            \"mt_balancing\": True,\n",
    "        },\n",
    "        \"direction\": {\n",
    "            \"output_shape\": 2,\n",
    "            \"loss\": torch.nn.L1Loss(reduction=\"none\"),\n",
    "            \"loss_weight\": 1,\n",
    "            \"metrics\": {},\n",
    "            \"mt_balancing\": True,\n",
    "        },\n",
    "        \"class\": {\n",
    "            \"label_shape\": 1,\n",
    "            \"output_shape\": len(particle_dict),\n",
    "            \"loss\": torch.nn.CrossEntropyLoss(),\n",
    "            \"loss_weight\": 1,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy_particle\": Accuracy(threshold=0.5, task=\"MULTICLASS\", num_classes=len(particle_dict)),\n",
    "                \"AUC_particle\": AUROC(\n",
    "                    task=\"MULTICLASS\",\n",
    "                    num_classes=len(particle_dict),\n",
    "                ),\n",
    "            },\n",
    "            \"mt_balancing\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\"\"\"dict: mandatory, defines for every objectives of the experiment\n",
    "the loss function and its weight\n",
    "\"\"\"\n",
    "\n",
    "dataset_class = dsets.MemoryLSTDataset\n",
    "# dataset_class = dsets.FileLSTDataset\n",
    "\"\"\"Dataset: mandatory, the Dataset class to load the data. Currently 2 classes are available, MemoryLSTDataset that \n",
    "loads images in memory, and FileLSTDataset that loads images from files during training.\n",
    "\"\"\"\n",
    "dataset_parameters = {\n",
    "    \"camera_type\": \"LST_LSTCam\",\n",
    "    \"group_by\": \"image\",\n",
    "    \"use_time\": True,\n",
    "    \"particle_dict\": particle_dict,\n",
    "    \"targets\": list(targets.keys()),\n",
    "    # 'subarray': [1],\n",
    "}\n",
    "\"\"\"dict: mandatory, the parameters of the dataset.\n",
    "camera_type is mandatory and can be:\n",
    "'LST_LSTCam', 'MST_NectarCam', 'MST_FlashCam', 'SST_ASTRICam', 'SST1M_DigiCam', 'SST_CHEC', 'MST-SCT_SCTCam'.\n",
    "group_by is mandatory and can be 'image', 'event_all_tels', 'event_triggered_tels'.\n",
    "particle_dict is mandatory and maps cta particle types with class id. e.g. gamma (0) is class 0, \n",
    "proton (101) is class 1 and electron (1) is class 2.\n",
    "use_time (optional): whether or not to use time information\n",
    "subarray (optional): the list of telescope ids to select as a subarray\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the specific dataset parameters for each experiment\n",
    "dataset_parameters_dvr = dataset_parameters.copy()\n",
    "dataset_parameters_dvr[\"use_cleaning_masks\"] = True\n",
    "dataset_parameters_dvr[\"mask_method\"] = \"data_reduction_mask\"\n",
    "\n",
    "dataset_parameters_default_tailcut = dataset_parameters.copy()\n",
    "dataset_parameters_default_tailcut[\"use_cleaning_masks\"] = True\n",
    "dataset_parameters_default_tailcut[\"mask_method\"] = \"tailcuts_standard_analysis\"\n",
    "\n",
    "dataset_parameters_lstchain = dataset_parameters.copy()\n",
    "dataset_parameters_lstchain[\"use_cleaning_masks\"] = True\n",
    "dataset_parameters_lstchain[\"mask_method\"] = \"precomputed_lstchain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "methods = [\"no mask\", \"dvr\", \"tailcuts_standard_analysis\", \"precomputed lstchain\"]\n",
    "dataset_parameters_list = [\n",
    "    dataset_parameters,\n",
    "    dataset_parameters_dvr,\n",
    "    dataset_parameters_default_tailcut,\n",
    "    dataset_parameters_lstchain,\n",
    "]\n",
    "\n",
    "datasets = {}\n",
    "for method, dataset_parameters in zip(methods, dataset_parameters_list):\n",
    "    datasets[method] = dataset_class(example_dl1_file, **dataset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to load the same image id in order to plot the same image for all methods\n",
    "# (removing the black images create a shift in the image id so images[0] may not be the same in all methods)\n",
    "\n",
    "# lstchain precomputed is the less conservative mask methods\n",
    "# so retrieve an image_id from this method has more chance to be found in other methods.\n",
    "\n",
    "image_ids_simus = {}\n",
    "# get the first event index from the precomputed lstchain method\n",
    "selected_event_index = 1\n",
    "method_selected = \"precomputed lstchain\"\n",
    "\n",
    "event_id = datasets[method_selected].unique_event_ids[selected_event_index]\n",
    "\n",
    "# find the image_id in the others datasets:\n",
    "image_ids = {}\n",
    "for method in methods:\n",
    "    image_ids[method] = np.where(datasets[method].unique_event_ids == event_id)[0][0]\n",
    "image_ids_simus[simu_type] = image_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select image (should be same event for all methods)\n",
    "images = {method: dataset.images[image_ids_simus[\"mc\"][method]] for method, dataset in datasets.items()}\n",
    "masks = {\n",
    "    method: dataset.images_masks[image_ids_simus[\"mc\"][method]]\n",
    "    for method, dataset in datasets.items()\n",
    "    if method != \"no mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(datasets, images, masks, save_fig=False, example_name=\"\") -> None:\n",
    "    fig, axes = plt.subplots(2, len(datasets.keys()), figsize=(10, 5))\n",
    "    for i, (method, image) in enumerate(images.items()):\n",
    "        CameraDisplay(datasets[method].original_geometry, image, ax=axes[0, i], title=method)\n",
    "        if method != \"no mask\":\n",
    "            CameraDisplay(\n",
    "                datasets[method].original_geometry,\n",
    "                masks[method],\n",
    "                ax=axes[1, i],\n",
    "                title=method,\n",
    "                show_frame=False,\n",
    "            )\n",
    "    for ax in axes.flatten():\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # save output\n",
    "    if save_fig:\n",
    "        output_dir = OUTPUT_DIR.as_posix()\n",
    "        fig_name = example_name + \"_image_\" + str(selected_event_index).zfill(3)\n",
    "        plt.savefig(output_dir + fig_name + \".pdf\", dpi=300)\n",
    "        plt.savefig(output_dir + fig_name + \".png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"no mask\"].images.sum(axis=(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "save_figure=False\n",
    "print_images(datasets, images, masks, save_fig=save_figure, example_name=example_name_mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Influence of `tailcut_clean` parameters\n",
    "\n",
    "**Important** : If you use the `share/MC_data/dl1_gamma.h5` file, the difference\n",
    "in the influence of the `min_number_picture_neighbors` parameter is very limited.\n",
    "I recommend using a real MC dl1 or a MC\\* (with extra noise) to observe the phenomenon with the classical cleaning parameters\n",
    "```python\n",
    "PICTURE_THRESH = 8\n",
    "BOUNDARY_THRESH = 4\n",
    "```\n",
    "\n",
    "In order to make the following study relevant, a super high cleaning thresholds are used. \n",
    "These values are never used in real case scenarii (even on MC) and have just been finetuned to show a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like to observe the impact on the last parameter of the tailcut method\n",
    "\n",
    "# take input images from no mask dataset\n",
    "# apply tailcut with diferent values\n",
    "from ctapipe.image import tailcuts_clean\n",
    "\n",
    "# Remark : as mentionned before, these value are really high to show the impact of the tailcut on clean data.\n",
    "# In practice, the calssic values are 8,4\n",
    "PICTURE_THRESH = 150\n",
    "BOUNDARY_THRESH = 120\n",
    "KEEP_ISOLATED_PIXELS = False\n",
    "min_number_picture_neighbors = [0, 1, 2, 3]\n",
    "\n",
    "NB_IMAGES_PLOT_TAILCUT = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image, apply tailcut with different min_number_picture_neighbors\n",
    "masks = {}\n",
    "offset_id_images = 5\n",
    "for i_image, image in enumerate(datasets[\"no mask\"].images[offset_id_images : offset_id_images + NB_IMAGES_PLOT_TAILCUT]):\n",
    "    masks[str(i_image)] = {}\n",
    "\n",
    "    for neighbour_param in min_number_picture_neighbors:\n",
    "        mask = tailcuts_clean(\n",
    "            datasets[\"no mask\"].original_geometry,\n",
    "            image,\n",
    "            picture_thresh=PICTURE_THRESH,\n",
    "            boundary_thresh=BOUNDARY_THRESH,\n",
    "            keep_isolated_pixels=KEEP_ISOLATED_PIXELS,\n",
    "            min_number_picture_neighbors=neighbour_param,\n",
    "        )\n",
    "        masks[str(i_image)][str(neighbour_param)] = mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot masks\n",
    "fig, axes = plt.subplots(1 + len(min_number_picture_neighbors), NB_IMAGES_PLOT_TAILCUT, figsize=(20, 10))\n",
    "# plot images\n",
    "for i in range(NB_IMAGES_PLOT_TAILCUT):\n",
    "    CameraDisplay(\n",
    "        datasets[\"no mask\"].original_geometry,\n",
    "        datasets[\"no mask\"].images[offset_id_images + i],\n",
    "        ax=axes[0, i],\n",
    "        title=f\"{i}\",\n",
    "    )\n",
    "for j, neighbour_param in enumerate(min_number_picture_neighbors):\n",
    "    for i in range(NB_IMAGES_PLOT_TAILCUT):\n",
    "        CameraDisplay(\n",
    "            datasets[\"no mask\"].original_geometry,\n",
    "            masks[str(i)][str(neighbour_param)],\n",
    "            ax=axes[1 + j, i],\n",
    "            title=f\"{i},{neighbour_param}\",\n",
    "            show_frame=False,\n",
    "        )\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_image_total = datasets[\"no mask\"].images.shape[0]\n",
    "\n",
    "nb_black = {str(param): 0 for param in min_number_picture_neighbors}\n",
    "info = {str(param): {\"dl1\": [], \"max_signal\": [], \"image_id\": []} for param in min_number_picture_neighbors}\n",
    "images = datasets[\"no mask\"].images\n",
    "for i in range(images.shape[0]):\n",
    "    for neighbour_param in min_number_picture_neighbors:\n",
    "        mask = tailcuts_clean(\n",
    "            datasets[\"no mask\"].original_geometry,\n",
    "            images[i],\n",
    "            picture_thresh=PICTURE_THRESH,\n",
    "            boundary_thresh=BOUNDARY_THRESH,\n",
    "            keep_isolated_pixels=KEEP_ISOLATED_PIXELS,\n",
    "            min_number_picture_neighbors=neighbour_param,\n",
    "        )\n",
    "        if mask.sum() == 0:\n",
    "            nb_black[str(neighbour_param)] += 1\n",
    "            info[str(neighbour_param)][\"dl1\"].append(datasets[\"no mask\"].dl1_params[i])\n",
    "            info[str(neighbour_param)][\"max_signal\"].append(images[i].max())\n",
    "            info[str(neighbour_param)][\"image_id\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_black_images = {}\n",
    "ratio_black_images = {key: elem / nb_image_total for key, elem in nb_black.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of black images for min_number neighbors thresholds\")\n",
    "for param, ratio, nb_black_image in zip(ratio_black_images.keys(), ratio_black_images.values(), nb_black.values()):\n",
    "    print(f\"{param} = {nb_black_image} ({ratio:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(datasets[\"no mask\"].images.max(axis=1))\n",
    "\n",
    "print(\"Mean max per image in the whole mc dataset : {:0.2f}\".format(mean_image))\n",
    "\n",
    "for neighbour_param in info.keys():\n",
    "    print(f\"neighbor parameter: {neighbour_param} -> {np.mean(info[neighbour_param]['max_signal']):0.2f}\")\n",
    "    # print(f\"dl1: {np.mean(images_infos[mc_type][neighbour_param]['dl1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
