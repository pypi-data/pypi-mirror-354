{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GammaLearn inference example\n",
    "\n",
    "In this notebook, we'll see how we can run inference interactively using a trained model.    \n",
    "If you want to process more data, please refer to the CLI program.\n",
    "\n",
    "## Setup\n",
    "For this example we'll use the toy model trained by integration tests.\n",
    "Start by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version as runtime_version\n",
    "print(runtime_version(\"gammalearn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# This command will train a network based on the setting file define below\n",
    "\n",
    "settings_file = \"../../gammalearn/configuration/examples/experiment_settings_train_MC.py\"\n",
    "subprocess.run([\"gammalearn\", settings_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an experiment from the settings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammalearn.experiment_runner import load_experiment\n",
    "experiment = load_experiment(settings_file)\n",
    "experiment.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is only here to load the camera geometry from the data.\n",
    "# It should be refactored to be simplified...\n",
    "\n",
    "from gammalearn.data.telescope_geometry import get_dataset_geom, inject_geometry_into_parameters\n",
    "\n",
    "gl_data_module_train = experiment.data_module_train[\"module\"](experiment)\n",
    "gl_data_module_train.setup_train()\n",
    "geometries = []\n",
    "get_dataset_geom(gl_data_module_train.train_set, geometries)\n",
    "experiment.net_parameters_dic = inject_geometry_into_parameters(experiment.net_parameters_dic, geometries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and its weight from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Here we take the checkpoint from previous training\n",
    "checkpoint_path = Path(experiment.main_directory) / experiment.experiment_name / 'last.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammalearn.gammalearn_lightning_module import LitGLearnModule\n",
    "\n",
    "model = LitGLearnModule.load_from_checkpoint(checkpoint_path, experiment=experiment, strict=False)\n",
    "model.eval()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_data_module_test = experiment.data_module_test[\"module\"](experiment)\n",
    "gl_data_module_test.setup_test()\n",
    "test_dataloaders = gl_data_module_test.test_dataloaders()\n",
    "dataloader = test_dataloaders[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a batch\n",
    "Let's get the first batch to play with.     \n",
    "A batch contains the images (2 channels), the true labels and the dl1 parameters of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ctapipe.visualization import CameraDisplay\n",
    "\n",
    "# If we take the first image sample, it contains two channels, the charges and the time map, that are the inputs for g-PhysNet\n",
    "sample = batch['image'][0]\n",
    "image = sample[0]\n",
    "time_map = sample[1]\n",
    "\n",
    "geom = geometries[0]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "display = CameraDisplay(geom, image, ax=axes[0])\n",
    "display.add_colorbar()\n",
    "display.axes.set_title('Image')\n",
    "\n",
    "display = CameraDisplay(geom, time_map, ax=axes[1])\n",
    "display.add_colorbar()\n",
    "display.axes.set_title('Time map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(batch['image'])\n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to true parameters\n",
    "\n",
    "This output is to compared to the true parameters from the MC simulation:    \n",
    "Note that we are here using a toy model with not much training, so the results will be far to be satisfying ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
