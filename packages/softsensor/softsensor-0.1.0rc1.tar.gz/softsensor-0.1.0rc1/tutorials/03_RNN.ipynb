{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa05875",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "In this tutorial we will use autoregressive approaches for virtual sensors to calculate the system response of an ESP System with external force from a shaker. The tutorial provides an introduction to virtual sensors for dynamic systems. This tutorial focusses on applying recurrent approaches, other models are discussed in the other two tutorials on linear models `linear_models.ipynb` and Autoregressive Neural Networks `ARNN.ipynb`. Recurrent Neural Networks are a modern approach to predict forced time series in multiple applications\n",
    "\n",
    "## Loading Data\n",
    "In a first step we load the already measured data and convert them into `pandas.DataFrames`. Our example Data consists of three individually Measured datasets. To load the data properly we need information about the specific sensors. In our case the sensor names are straight forward: \n",
    " * input_1-9 as our 9 input signals\n",
    " * output_1-3 as out 3 output signals\n",
    " \n",
    "Furthermore, (if not given as `time` in the mat file) we need the corrosponsing sampling rate `fs` of the data.In our case:\n",
    " * fs=50000\n",
    "\n",
    "Fixing the sampling rate will raise an Attention Message. We save the individual Measurments in a list of `pandas.DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e62779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(\"\"), 'data')\n",
    "\n",
    "input_sensors = [f'input_{i}' for i in range(1, 10)]\n",
    "output_sensors = [f'output_{i}' for i in range(1, 4)]\n",
    "\n",
    "file_names = [f for f in os.listdir(data_path) if\n",
    "                    os.path.isfile(os.path.join(data_path, f))]\n",
    "df_list = [pd.read_parquet(os.path.join(data_path, n)) for n in file_names]\n",
    "fs = 1/np.mean(df_list[0].index.diff().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c5c08",
   "metadata": {},
   "source": [
    "## Plot the Data\n",
    "Before we start with the actual preprocessing we want to plot the given data to get a feeling for the properties. These are high-frequency acceleration data recorded on a shaker. For convinience we just plot the first entry of our list of DataFrames\n",
    "<img src=\"./img/Mehrachspruefstand.jpg\" alt=\"\" width=\"600\"/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].plot(subplots=True, sharex=True, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1c640",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "When looking at the data, the high range in which the accelerations move is striking. For many machine learning models, preprocessing is therefore necessary. Our toolbox uses the class `Meas_handling` for the entire preprocessing. `Meas_handling` is used to transform the data into a normally distributed range. Furthermore, the entire frequency range is not relevant for our analysis. Therefore, we sample the data from 50000 Hz to 10000 Hz and then filter between 90 and 4000 Hz.\n",
    "\n",
    "Furtehrmore we split the data in training and evaluation data. We use the first two Measurments as training and the last one as evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b56a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from softsensor.meas_handling import Meas_handling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_handle = Meas_handling(df_list[:2], file_names[:2], input_sensors, output_sensors, fs,\n",
    "                            df_list[2:], file_names[2:])\n",
    "\n",
    "data_handle.Resample(fs=10000)\n",
    "freq_lim = (90, 4000)\n",
    "data_handle.Filter(freq_lim)\n",
    "data_handle.Scale(StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73638aa",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "We define two different Models in our example. \n",
    "First we define a Gated Recurrent Unit (GRU) Network to approximate the functional dependency between input and output as linear combinations. Compared to the autoregressive neural networks described in `ARNN.ipynb`, GRU models do not feed back the output directly but utilise a hidden state $h(t)$ which mimics the system state. In most applications it seems advantageous to utilise subsequent feed forward layers after the GRU cells.\n",
    "\n",
    "$y_i(t+1) = f(\\mathbf{x}_i(t, ..., t-w_x), h(t))$\n",
    "\n",
    "This RNN model take the following inputs:\n",
    " * number of input channels (`input_channels`)\n",
    " * number of output channels (`pred_size`)\n",
    " * window size (`window_size`)\n",
    " * number of parallel GRU cells (`blocks`)\n",
    " * depth of the GRU (`num_layers`)\n",
    " * blocktype (`GRU`)\n",
    " * neurons in the subsequent feed forward network (`hidden_size`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c86c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from softsensor.recurrent_models import RNN_DNN\n",
    "from torchinfo import summary\n",
    "\n",
    "gru = RNN_DNN(input_channels=9, pred_size=3, window_size=50, blocks=32, num_layers=1, hidden_size=[32, 16],\n",
    "               blocktype='GRU', activation='leaky_relu')\n",
    "print(gru)\n",
    "summary(gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e66355",
   "metadata": {},
   "source": [
    "After we have defined the model, the next step is to adapt the model to the data. The training and validation data can be extracted from the predefined `data_handle` class and then trained using the `train_model` function. For GRU the Input data needs to be defined differently. The time series have to be gone through individually in the correct order compared to the use of ARNN (`tutorials/02_ARNN`). We therefore need a list of loaders, each entry containing one of the training time series. The `Meas_handling` class provides a functionality for this. The method needs as input:\n",
    "\n",
    "* `window_size`: defines the length of the time window, needs to be the same as for the model\n",
    "* `keyword`: either `training` or `short`, training uses the whole training dataset, while short uses only a small subset\n",
    "* `batch_size`: batch size of the individual loaders in the list\n",
    "* `Add_zeros`: Adds zeros at the beginning of the time series to mimic start from idle state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_loader = data_handle.give_list(gru.window_size, keyword='training',\n",
    "                                          batch_size=128, Add_zeros=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0857206",
   "metadata": {},
   "source": [
    "Furthermore, some training parameters are needed, which have to be passed to the class `train_model`:\n",
    "\n",
    "* `model`: ARNN to be trained\n",
    "*  `train_loader`: training data (list of data loaders)\n",
    "* `max_epochs`: maximum number of epochs for training\n",
    "* `optimizer`: optimizer used  for optimization, check [Link](https://pytorch.org/docs/stable/optim.html) for different possibel optimizers\n",
    "* `device`: device for training\n",
    "* `criterion`: loss function to train against check [Link](https://pytorch.org/docs/stable/nn.html#loss-functions) for possibel criterions\n",
    "* `val_loader`: validation data (list of data loaders)\n",
    "* `print_results`: if True, results are printed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from softsensor.train_model import train_model\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "opt = optim.Adam(gru.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "results = train_model(gru, list_train_loader, max_epochs=30, optimizer=opt, device='cpu', criterion=crit,\n",
    "                      val_loader=None, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a8953",
   "metadata": {},
   "source": [
    "$\\textbf{Congratulation!!!}$ you have successfully fitted a Gated Recurrent Unit Network to the training data\n",
    "\n",
    "The linear transfer function is used as a benchmark in the following. A detailed explanation can be found in `tutorials\\linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fa93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from softsensor.arx import ARX\n",
    "arx = ARX(order=[50, 50])\n",
    "arx.fit(data_handle.train_df, input_sensors, output_sensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6ba07",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "To Evaluate our model on testing data we use the predefined functions `comp_pred`, which computes the prediction for a defined track in the data_handle class. As track we choose our testing track, which can be accessed using the internal variable `test_names`. Furthermore we compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from softsensor.eval_tools import comp_pred, comp_error\n",
    "track = data_handle.test_names[0]\n",
    "models = [gru, arx]\n",
    "pred_df = comp_pred(models, data_handle, track, names=['GRU', 'ARX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.filter(regex='output_1').plot(figsize=(12,4))\n",
    "pred_df.filter(regex='output_1')[1:1.01].plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6641658",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = comp_error(pred_df, output_sensors, fs, names=['GRU', 'ARX'], metrics=['MSE', 'MAE'], freq_range=freq_lim)\n",
    "for n in ['MSE', 'MAE']:\n",
    "    error.filter(regex=n, axis=0).plot.bar(ylabel=f'{n}', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b7f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6fcec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
