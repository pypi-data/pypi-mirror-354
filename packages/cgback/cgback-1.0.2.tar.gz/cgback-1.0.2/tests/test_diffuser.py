import pytest
import torch

from cgback.diffuser import DDPM
from cgback.dataloader import GraphDataloaderItem


@pytest.fixture
def sample_ddpm():
    num_timesteps = 10
    dim_features = 60
    dim_embedding = 64
    num_layers = 3
    scheduler_type = "cosine"

    return DDPM(
        num_timesteps=num_timesteps,
        dim_features=dim_features,
        dim_embedding=dim_embedding,
        num_layers=num_layers,
        scheduler_type=scheduler_type,
    )


@pytest.fixture
def sample_graph():
    data = {
        'hu': torch.tensor(
            [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,
              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]),
        'xw': torch.tensor(
            [[-2.9000e-02, 9.4500e-01, 1.1280e+00],
             [1.3960e+00, -1.8700e-01, -6.2900e-01],
             [2.4320e+00, 6.1000e-02, -1.0000e-03],
             [-9.6700e-01, 4.5700e-01, -1.1000e+00],
             [-4.7400e-01, 1.5900e+00, -2.0130e+00],
             [-1.2920e+00, 1.6340e+00, -3.2930e+00],
             [-5.0200e-01, 2.9220e+00, -1.2860e+00],
             [0.0000e+00, 0.0000e+00, 0.0000e+00],
             [-5.2200e-01, 1.7000e+00, 3.4290e+00],
             [2.6430e+00, -8.5800e-01, -2.6070e+00],
             [4.3670e+00, 1.6720e+00, -4.8660e+00],
             [-1.2370e+00, 2.0100e-01, 7.3500e-01],
             [1.5700e-01, 1.1370e+00, -1.0080e+00],
             [-8.2900e-01, 1.6750e+00, -1.5190e+00],
             [-1.0000e-02, -1.3550e+00, -7.0500e-01],
             [1.3510e+00, -1.7390e+00, -1.2530e+00],
             [1.9080e+00, -9.8800e-01, -2.0760e+00],
             [1.8660e+00, -2.8080e+00, -8.7500e-01],
             [0.0000e+00, 0.0000e+00, 0.0000e+00],
             [-2.6430e+00, 8.5800e-01, 2.6070e+00],
             [1.7240e+00, 2.5300e+00, -2.2590e+00],
             [-3.1650e+00, 2.5580e+00, 6.0360e+00],
             [4.4160e+00, 2.9000e+00, -5.0350e+00]]),
        'e': torch.tensor(
            [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,
              1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,
              3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,
              5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
              7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
              9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10,
              10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12,
              12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,
              14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15,
              15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17,
              17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,
              19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20,
              20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22,
              22, 22, 22, 22, 22, 22, 22, 22],
             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 2, 3, 4, 5, 6, 7, 8,
              9, 10, 0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 4, 5, 6,
              7, 8, 9, 10, 0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3,
              4, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 0, 1,
              2, 3, 4, 5, 6, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 9, 10,
              0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 0, 1, 2, 3, 4, 5, 6, 7,
              8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 11, 13, 14, 15, 16,
              17, 18, 19, 20, 21, 22, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 11,
              12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 11, 12, 13, 14, 16, 17, 18, 19,
              20, 21, 22, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 11, 12, 13, 14,
              15, 16, 18, 19, 20, 21, 22, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22,
              11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 11, 12, 13, 14, 15, 16, 17,
              18, 19, 21, 22, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 11, 12, 13,
              14, 15, 16, 17, 18, 19, 20, 21]], dtype=torch.int64),
        'num_h': torch.tensor([7, 7], dtype=torch.int64),
        'num_u': torch.tensor([4, 5], dtype=torch.int64),
        'mask': torch.tensor(
            [[1],
             [1],
             [1],
             [1],
             [1],
             [1],
             [1],
             [0],
             [0],
             [0],
             [0],
             [1],
             [1],
             [1],
             [1],
             [1],
             [1],
             [1],
             [0],
             [0],
             [0],
             [0],
             [0]],
            dtype=torch.int64
        )
    }

    return GraphDataloaderItem(data["hu"], data["xw"], data["e"], data["num_h"], data["num_u"], data["mask"])


def test_ddpm_initialization(sample_ddpm):
    ddpm = sample_ddpm

    assert ddpm.num_timesteps == 10
    assert ddpm.dim_features == 60
    assert ddpm.dim_embedding == 64
    assert ddpm.num_layers == 3
    assert ddpm.scheduler_type == "cosine"
    assert ddpm.scheduler is not None
    assert ddpm.egnn is not None


def test_ddpm_forward(sample_ddpm, sample_graph):
    ddpm = sample_ddpm
    graph = sample_graph

    loss, _ = ddpm(graph)

    assert isinstance(loss, torch.Tensor), "Loss should be a tensor."
    assert loss.ndim == 0, "Loss tensor should be a scalar."


def test_ddpm_sample(sample_ddpm, sample_graph):
    ddpm = sample_ddpm
    graph = sample_graph

    sampled_graph = ddpm.sample(graph, verbose=False)

    assert sampled_graph.xw.shape == graph.xw.shape, "Coordinates shapes must match."


def test_invalid_scheduler_type():
    with pytest.raises(ValueError):
        DDPM(
            num_timesteps=10,
            dim_features=32,
            dim_embedding=64,
            num_layers=3,
            scheduler_type="invalid_type",
        )


def test_gradient_numerical_stability(sample_ddpm, sample_graph):
    ddpm = sample_ddpm
    graph = sample_graph

    graph.xw.requires_grad_()

    # Compute loss and execute backpropagation
    loss, _ = ddpm(graph)
    loss.backward()

    # Check if gradients are finite
    assert torch.isfinite(graph.xw.grad).all(), "Gradients are unstable."
