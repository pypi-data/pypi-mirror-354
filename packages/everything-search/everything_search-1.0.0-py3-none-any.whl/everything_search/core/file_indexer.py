#!/usr/bin/env python3
"""
é«˜æ€§èƒ½æ–‡ä»¶ç´¢å¼•å™¨
ä¼˜åŒ–ç‰¹æ€§ï¼š
- å¤šçº¿ç¨‹å¹¶å‘æ‰«æ
- å¢é‡ç´¢å¼•å’Œå˜æ›´æ£€æµ‹
- å†…å­˜ä¼˜åŒ–çš„æ‰¹å¤„ç†
- æ™ºèƒ½è·³è¿‡å’Œè¿‡æ»¤
"""

import os
import time
import threading
from pathlib import Path
from typing import List, Set, Optional, Callable, Iterator
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
import hashlib

from .config_manager import ConfigManager, IndexConfig
from .database import DatabaseManager, FileRecord


@dataclass
class IndexProgress:
    """ç´¢å¼•è¿›åº¦ä¿¡æ¯"""
    total_files: int = 0
    processed_files: int = 0
    current_path: str = ""
    start_time: float = 0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []


class FileIndexer:
    """é«˜æ€§èƒ½æ–‡ä»¶ç´¢å¼•å™¨"""
    
    def __init__(self, config_manager: ConfigManager, db_manager: DatabaseManager):
        self.config_manager = config_manager
        self.db_manager = db_manager
        self._stop_event = threading.Event()
        self._progress_callback: Optional[Callable[[IndexProgress], None]] = None
        
    def set_progress_callback(self, callback: Callable[[IndexProgress], None]):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self._progress_callback = callback
    
    def _calculate_path_hash(self, path: str) -> str:
        """è®¡ç®—è·¯å¾„å“ˆå¸Œ"""
        return hashlib.md5(path.encode('utf-8')).hexdigest()
    
    def _should_exclude_directory(self, dir_name: str, exclude_dirs: Set[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤ç›®å½•"""
        return dir_name in exclude_dirs or dir_name.startswith('.')
    
    def _should_exclude_file(self, file_path: Path, config: IndexConfig) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤æ–‡ä»¶"""
        # æ£€æŸ¥éšè—æ–‡ä»¶
        if not config.index_hidden_files and file_path.name.startswith('.'):
            return True
        
        # æ£€æŸ¥æ‰©å±•å
        if file_path.suffix.lower() in config.exclude_extensions:
            return True
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        try:
            if file_path.is_file():
                size_mb = file_path.stat().st_size / (1024 * 1024)
                if size_mb > config.max_file_size_mb:
                    return True
        except (OSError, PermissionError):
            return True
        
        return False
    
    def _scan_directory_worker(self, root_path: str, config: IndexConfig) -> Iterator[FileRecord]:
        """å•ä¸ªç›®å½•æ‰«æå·¥ä½œå™¨"""
        exclude_dirs = set(config.exclude_dirs)
        
        try:
            root_path_obj = Path(root_path)
            if not root_path_obj.exists() or not root_path_obj.is_dir():
                return
            
            for current_path, dirs, files in os.walk(root_path):
                if self._stop_event.is_set():
                    break
                
                current_path_obj = Path(current_path)
                
                # è¿‡æ»¤ç›®å½•
                dirs[:] = [d for d in dirs if not self._should_exclude_directory(d, exclude_dirs)]
                
                # å¤„ç†å½“å‰ç›®å½•
                try:
                    stat_info = current_path_obj.stat()
                    parent_path = str(current_path_obj.parent)
                    
                    yield FileRecord(
                        id=None,
                        path=str(current_path_obj),
                        name=current_path_obj.name,
                        size=0,  # ç›®å½•å¤§å°è®¾ä¸º0
                        mtime=stat_info.st_mtime,
                        is_dir=True,
                        extension="",
                        parent_path=parent_path,
                        path_hash=self._calculate_path_hash(str(current_path_obj))
                    )
                except (OSError, PermissionError):
                    continue
                
                # å¤„ç†æ–‡ä»¶
                for file_name in files:
                    if self._stop_event.is_set():
                        break
                    
                    file_path = current_path_obj / file_name
                    
                    if self._should_exclude_file(file_path, config):
                        continue
                    
                    try:
                        stat_info = file_path.stat()
                        
                        yield FileRecord(
                            id=None,
                            path=str(file_path),
                            name=file_name,
                            size=stat_info.st_size,
                            mtime=stat_info.st_mtime,
                            is_dir=False,
                            extension=file_path.suffix.lower(),
                            parent_path=str(current_path_obj),
                            path_hash=self._calculate_path_hash(str(file_path))
                        )
                        
                    except (OSError, PermissionError):
                        continue
                        
        except (OSError, PermissionError) as e:
            if self._progress_callback:
                progress = IndexProgress()
                progress.errors.append(f"æ— æ³•è®¿é—®ç›®å½• {root_path}: {e}")
                self._progress_callback(progress)
    
    def _collect_files_batch(self, file_iterator: Iterator[FileRecord], 
                           batch_size: int) -> Iterator[List[FileRecord]]:
        """æ‰¹é‡æ”¶é›†æ–‡ä»¶è®°å½•"""
        batch = []
        for file_record in file_iterator:
            batch.append(file_record)
            if len(batch) >= batch_size:
                yield batch
                batch = []
        
        if batch:
            yield batch
    
    def build_full_index(self) -> IndexProgress:
        """æ„å»ºå®Œæ•´ç´¢å¼•"""
        config = self.config_manager.get_index_config()
        perf_config = self.config_manager.get_performance_config()
        
        progress = IndexProgress(start_time=time.time())
        
        print("ğŸ”„ å¼€å§‹æ„å»ºå®Œæ•´ç´¢å¼•...")
        
        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        self.db_manager.clear_all_files()
        
        # å¹¶å‘æ‰«ææ‰€æœ‰ç›®å½•
        with ThreadPoolExecutor(max_workers=perf_config.max_workers) as executor:
            # æäº¤æ‰«æä»»åŠ¡
            future_to_path = {
                executor.submit(self._scan_directory_worker, directory, config): directory
                for directory in config.directories
                if Path(directory).exists()
            }
            
            total_processed = 0
            
            for future in as_completed(future_to_path):
                directory = future_to_path[future]
                
                try:
                    file_iterator = future.result()
                    
                    # æ‰¹é‡å¤„ç†æ–‡ä»¶è®°å½•ï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡ä»¥æé«˜è¿›åº¦å›è°ƒé¢‘ç‡
                    progress_batch_size = min(perf_config.batch_size, 100)  # é™åˆ¶æœ€å¤§100ä¸ªæ–‡ä»¶ä¸€æ‰¹
                    for batch in self._collect_files_batch(file_iterator, progress_batch_size):
                        if self._stop_event.is_set():
                            break

                        self.db_manager.insert_files_batch(batch)
                        total_processed += len(batch)

                        progress.processed_files = total_processed
                        progress.current_path = directory

                        if self._progress_callback:
                            self._progress_callback(progress)
                
                except Exception as e:
                    error_msg = f"æ‰«æç›®å½• {directory} å¤±è´¥: {e}"
                    progress.errors.append(error_msg)
                    print(f"âš ï¸  {error_msg}")
        
        # æ›´æ–°ç´¢å¼•å…ƒæ•°æ®
        self.db_manager.set_metadata("last_full_index", time.time())
        self.db_manager.set_metadata("index_version", "1.0")
        
        progress.total_files = progress.processed_files
        elapsed_time = time.time() - progress.start_time

        print(f"\nâœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†æ–‡ä»¶: {progress.processed_files:,}")
        print(f"â±ï¸  è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"ğŸš€ é€Ÿåº¦: {progress.processed_files/elapsed_time:.0f} æ–‡ä»¶/ç§’")
        
        return progress
    
    def rebuild_index(self) -> IndexProgress:
        """é‡å»ºç´¢å¼•ï¼ˆåˆ é™¤æ‰€æœ‰ç´¢å¼•åé‡æ–°æ„å»ºï¼‰"""
        print("ğŸ”„ å¼€å§‹é‡å»ºç´¢å¼•...")
        print("âš ï¸  è¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰ç´¢å¼•æ•°æ®")
        
        # æ¸…ç©ºæ‰€æœ‰æ•°æ®
        self.db_manager.clear_all_files()
        
        # é‡æ–°æ„å»º
        return self.build_full_index()
    
    def update_incremental_index(self, paths: Optional[List[str]] = None, check_deletions: bool = True) -> IndexProgress:
        """å¢é‡æ›´æ–°ç´¢å¼•"""
        config = self.config_manager.get_index_config()
        perf_config = self.config_manager.get_performance_config()
        
        progress = IndexProgress(start_time=time.time())
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œä½¿ç”¨é…ç½®ä¸­çš„æ‰€æœ‰ç›®å½•
        if paths is None:
            paths = config.directories

        print(f"ğŸ”„ å¼€å§‹å¢é‡ç´¢å¼•æ›´æ–°...")

        for directory in paths:
            if not Path(directory).exists():
                print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {directory}")
                continue

            print(f"ğŸ“ æ‰«æç›®å½•: {directory}")
            
            # æ‰«æç›®å½•è·å–å½“å‰æ–‡ä»¶
            current_files = {}
            for file_record in self._scan_directory_worker(directory, config):
                if self._stop_event.is_set():
                    break
                current_files[file_record.path] = file_record
            
            # æ‰¹é‡æ›´æ–°
            updates = []
            deleted_paths = []

            # æ£€æŸ¥æ–°æ–‡ä»¶å’Œä¿®æ”¹çš„æ–‡ä»¶
            for path, file_record in current_files.items():
                existing = self.db_manager.get_file_by_path(path)

                if existing is None:
                    # æ–°æ–‡ä»¶
                    updates.append(file_record)
                elif existing.mtime != file_record.mtime or existing.size != file_record.size:
                    # æ–‡ä»¶å·²ä¿®æ”¹
                    updates.append(file_record)

            # å¯é€‰çš„åˆ é™¤æ£€æµ‹ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            if check_deletions:
                # è·å–æ•°æ®åº“ä¸­è¯¥ç›®å½•ä¸‹çš„ç°æœ‰æ–‡ä»¶
                existing_files = self.db_manager.get_files_in_directory(directory)

                # æ£€æŸ¥å·²åˆ é™¤çš„æ–‡ä»¶
                for path in existing_files:
                    if path not in current_files:
                        deleted_paths.append(path)

            # æ‰§è¡Œæ›´æ–°
            if updates:
                # æ‰¹é‡æ’å…¥/æ›´æ–°ï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹æ¬¡ä»¥æé«˜è¿›åº¦å›è°ƒé¢‘ç‡
                progress_batch_size = min(perf_config.batch_size, 100)  # é™åˆ¶æœ€å¤§100ä¸ªæ–‡ä»¶ä¸€æ‰¹
                for i in range(0, len(updates), progress_batch_size):
                    batch = updates[i:i + progress_batch_size]
                    self.db_manager.insert_files_batch(batch)

                    progress.processed_files += len(batch)
                    progress.current_path = directory

                    if self._progress_callback:
                        self._progress_callback(progress)

            # æ‰§è¡Œåˆ é™¤
            if deleted_paths:
                print(f"ğŸ—‘ï¸  åˆ é™¤ {len(deleted_paths)} ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶")
                self.db_manager.delete_files_by_paths(deleted_paths)
        
        # æ›´æ–°å…ƒæ•°æ®
        self.db_manager.set_metadata("last_incremental_index", time.time())
        
        elapsed_time = time.time() - progress.start_time
        print(f"\nâœ… å¢é‡ç´¢å¼•æ›´æ–°å®Œæˆï¼")
        print(f"ğŸ“Š æ›´æ–°æ–‡ä»¶: {progress.processed_files:,}")
        print(f"â±ï¸  è€—æ—¶: {elapsed_time:.2f} ç§’")
        
        return progress

    def cleanup_deleted_files(self) -> int:
        """æ¸…ç†å·²åˆ é™¤çš„æ–‡ä»¶ï¼ˆæ€§èƒ½ä¼˜åŒ–çš„ç‹¬ç«‹æ“ä½œï¼‰"""
        print("ğŸ§¹ å¼€å§‹æ¸…ç†å·²åˆ é™¤çš„æ–‡ä»¶...")

        config = self.config_manager.get_index_config()
        total_deleted = 0

        for directory in config.directories:
            if not Path(directory).exists():
                # å¦‚æœæ•´ä¸ªç›®å½•éƒ½ä¸å­˜åœ¨äº†ï¼Œåˆ é™¤è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
                existing_files = self.db_manager.get_files_in_directory(directory)
                if existing_files:
                    deleted_count = self.db_manager.delete_files_by_paths(list(existing_files.keys()))
                    total_deleted += deleted_count
                    print(f"ğŸ—‘ï¸  ç›®å½• {directory} ä¸å­˜åœ¨ï¼Œåˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶")
                continue

            print(f"ğŸ” æ£€æŸ¥ç›®å½•: {directory}")

            # è·å–æ•°æ®åº“ä¸­çš„æ–‡ä»¶
            existing_files = self.db_manager.get_files_in_directory(directory)
            deleted_paths = []

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿˜å­˜åœ¨
            for path in existing_files:
                if not Path(path).exists():
                    deleted_paths.append(path)

            if deleted_paths:
                deleted_count = self.db_manager.delete_files_by_paths(deleted_paths)
                total_deleted += deleted_count
                print(f"ğŸ—‘ï¸  åˆ é™¤ {deleted_count} ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶")

        print(f"âœ… æ¸…ç†å®Œæˆï¼Œæ€»å…±åˆ é™¤ {total_deleted} ä¸ªæ–‡ä»¶")
        return total_deleted

    def get_index_status(self) -> dict:
        """è·å–ç´¢å¼•çŠ¶æ€"""
        stats = self.db_manager.get_statistics()
        
        last_full = self.db_manager.get_metadata("last_full_index")
        last_incremental = self.db_manager.get_metadata("last_incremental_index")
        
        return {
            "total_files": stats["total_files"],
            "total_directories": stats["total_directories"],
            "total_regular_files": stats["total_regular_files"],
            "last_full_index": last_full,
            "last_incremental_index": last_incremental,
            "index_version": self.db_manager.get_metadata("index_version", "unknown")
        }
    
    def stop(self):
        """åœæ­¢ç´¢å¼•æ“ä½œ"""
        self._stop_event.set()
        print("ğŸ›‘ æ­£åœ¨åœæ­¢ç´¢å¼•æ“ä½œ...")
    
    def reset_stop(self):
        """é‡ç½®åœæ­¢æ ‡å¿—"""
        self._stop_event.clear()
