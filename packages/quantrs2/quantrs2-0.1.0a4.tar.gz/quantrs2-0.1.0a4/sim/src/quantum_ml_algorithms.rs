//! Quantum Machine Learning Algorithms with Hardware-Aware Optimization
//!
//! This module implements state-of-the-art quantum machine learning algorithms optimized
//! for different hardware architectures. It includes quantum neural networks, variational
//! quantum eigensolvers, quantum support vector machines, and quantum reinforcement learning
//! algorithms, all with hardware-specific optimizations for NISQ devices, fault-tolerant
//! quantum computers, and hybrid classical-quantum systems.
//!
//! Key features:
//! - Parameterized quantum circuits (PQCs) with efficient optimization
//! - Quantum convolutional neural networks (QCNNs)
//! - Variational quantum eigensolvers (VQE) with advanced ansÃ¤tze
//! - Quantum approximate optimization algorithms (QAOA)
//! - Quantum reinforcement learning with policy gradient methods
//! - Hardware-aware circuit compilation and optimization
//! - Noise-adaptive training strategies
//! - Efficient gradient estimation techniques

use ndarray::{Array1, Array2, Array3, Array4, ArrayView1, Axis};
use num_complex::Complex64;
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, VecDeque};
use std::sync::{Arc, Mutex};

use crate::circuit_interfaces::{
    CircuitInterface, InterfaceCircuit, InterfaceGate, InterfaceGateType,
};
use crate::device_noise_models::{DeviceNoiseModel, DeviceType};
use crate::error::{Result, SimulatorError};
use crate::statevector::StateVectorSimulator;

/// Hardware architecture types for optimization
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HardwareArchitecture {
    /// Noisy Intermediate-Scale Quantum devices
    NISQ,
    /// Fault-tolerant quantum computers
    FaultTolerant,
    /// Superconducting quantum processors
    Superconducting,
    /// Trapped ion systems
    TrappedIon,
    /// Photonic quantum computers
    Photonic,
    /// Neutral atom systems
    NeutralAtom,
    /// Classical simulation
    ClassicalSimulation,
}

/// Quantum machine learning algorithm types
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum QMLAlgorithmType {
    /// Variational Quantum Eigensolver
    VQE,
    /// Quantum Approximate Optimization Algorithm
    QAOA,
    /// Quantum Convolutional Neural Network
    QCNN,
    /// Quantum Support Vector Machine
    QSVM,
    /// Quantum Reinforcement Learning
    QRL,
    /// Quantum Generative Adversarial Network
    QGAN,
    /// Quantum Boltzmann Machine
    QBM,
}

/// Gradient estimation methods
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum GradientMethod {
    /// Parameter shift rule
    ParameterShift,
    /// Finite differences
    FiniteDifferences,
    /// Automatic differentiation
    AutomaticDifferentiation,
    /// Natural gradients
    NaturalGradients,
    /// Stochastic parameter shift
    StochasticParameterShift,
}

/// Optimization algorithms
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum OptimizerType {
    /// Adam optimizer
    Adam,
    /// Stochastic gradient descent
    SGD,
    /// RMSprop
    RMSprop,
    /// L-BFGS
    LBFGS,
    /// Quantum natural gradient
    QuantumNaturalGradient,
    /// SPSA (Simultaneous Perturbation Stochastic Approximation)
    SPSA,
}

/// QML configuration
#[derive(Debug, Clone)]
pub struct QMLConfig {
    /// Target hardware architecture
    pub hardware_architecture: HardwareArchitecture,
    /// Algorithm type
    pub algorithm_type: QMLAlgorithmType,
    /// Number of qubits
    pub num_qubits: usize,
    /// Circuit depth
    pub circuit_depth: usize,
    /// Number of parameters
    pub num_parameters: usize,
    /// Gradient estimation method
    pub gradient_method: GradientMethod,
    /// Optimizer type
    pub optimizer_type: OptimizerType,
    /// Learning rate
    pub learning_rate: f64,
    /// Batch size
    pub batch_size: usize,
    /// Maximum epochs
    pub max_epochs: usize,
    /// Convergence tolerance
    pub convergence_tolerance: f64,
    /// Enable hardware-aware optimization
    pub hardware_aware_optimization: bool,
    /// Enable noise adaptation
    pub noise_adaptive_training: bool,
    /// Shot budget for expectation value estimation
    pub shot_budget: usize,
}

impl Default for QMLConfig {
    fn default() -> Self {
        Self {
            hardware_architecture: HardwareArchitecture::NISQ,
            algorithm_type: QMLAlgorithmType::VQE,
            num_qubits: 4,
            circuit_depth: 3,
            num_parameters: 12,
            gradient_method: GradientMethod::ParameterShift,
            optimizer_type: OptimizerType::Adam,
            learning_rate: 0.01,
            batch_size: 32,
            max_epochs: 100,
            convergence_tolerance: 1e-6,
            hardware_aware_optimization: true,
            noise_adaptive_training: true,
            shot_budget: 8192,
        }
    }
}

/// Parameterized quantum circuit
#[derive(Debug, Clone)]
pub struct ParameterizedQuantumCircuit {
    /// Circuit structure
    pub circuit: InterfaceCircuit,
    /// Parameter vector
    pub parameters: Array1<f64>,
    /// Parameter names for identification
    pub parameter_names: Vec<String>,
    /// Gate-to-parameter mapping
    pub gate_parameter_map: HashMap<usize, Vec<usize>>,
    /// Hardware-specific optimizations
    pub hardware_optimizations: HardwareOptimizations,
}

/// Hardware-specific optimizations
#[derive(Debug, Clone)]
pub struct HardwareOptimizations {
    /// Connectivity graph
    pub connectivity_graph: Array2<bool>,
    /// Gate fidelities
    pub gate_fidelities: HashMap<String, f64>,
    /// Decoherence times
    pub decoherence_times: Array1<f64>,
    /// Gate times
    pub gate_times: HashMap<String, f64>,
    /// Crosstalk matrix
    pub crosstalk_matrix: Array2<f64>,
}

impl HardwareOptimizations {
    /// Create optimizations for specific hardware
    pub fn for_hardware(architecture: HardwareArchitecture, num_qubits: usize) -> Self {
        let connectivity_graph = match architecture {
            HardwareArchitecture::Superconducting => {
                // Linear connectivity typical of superconducting systems
                let mut graph = Array2::from_elem((num_qubits, num_qubits), false);
                for i in 0..num_qubits.saturating_sub(1) {
                    graph[[i, i + 1]] = true;
                    graph[[i + 1, i]] = true;
                }
                graph
            }
            HardwareArchitecture::TrappedIon => {
                // All-to-all connectivity for trapped ions
                Array2::from_elem((num_qubits, num_qubits), true)
            }
            HardwareArchitecture::Photonic => {
                // Limited connectivity for photonic systems
                let mut graph = Array2::from_elem((num_qubits, num_qubits), false);
                for i in 0..num_qubits {
                    for j in 0..num_qubits {
                        if (i as i32 - j as i32).abs() <= 2 {
                            graph[[i, j]] = true;
                        }
                    }
                }
                graph
            }
            _ => Array2::from_elem((num_qubits, num_qubits), true),
        };

        let gate_fidelities = match architecture {
            HardwareArchitecture::Superconducting => {
                let mut fidelities = HashMap::new();
                fidelities.insert("X".to_string(), 0.999);
                fidelities.insert("Y".to_string(), 0.999);
                fidelities.insert("Z".to_string(), 0.9999);
                fidelities.insert("H".to_string(), 0.998);
                fidelities.insert("CNOT".to_string(), 0.995);
                fidelities.insert("CZ".to_string(), 0.996);
                fidelities
            }
            HardwareArchitecture::TrappedIon => {
                let mut fidelities = HashMap::new();
                fidelities.insert("X".to_string(), 0.9999);
                fidelities.insert("Y".to_string(), 0.9999);
                fidelities.insert("Z".to_string(), 0.99999);
                fidelities.insert("H".to_string(), 0.9999);
                fidelities.insert("CNOT".to_string(), 0.999);
                fidelities.insert("CZ".to_string(), 0.999);
                fidelities
            }
            _ => {
                let mut fidelities = HashMap::new();
                fidelities.insert("X".to_string(), 0.99);
                fidelities.insert("Y".to_string(), 0.99);
                fidelities.insert("Z".to_string(), 0.999);
                fidelities.insert("H".to_string(), 0.99);
                fidelities.insert("CNOT".to_string(), 0.98);
                fidelities.insert("CZ".to_string(), 0.98);
                fidelities
            }
        };

        let decoherence_times = match architecture {
            HardwareArchitecture::Superconducting => {
                Array1::from_vec(vec![50e-6; num_qubits]) // 50 microseconds
            }
            HardwareArchitecture::TrappedIon => {
                Array1::from_vec(vec![100e-3; num_qubits]) // 100 milliseconds
            }
            _ => Array1::from_vec(vec![10e-6; num_qubits]),
        };

        let gate_times = match architecture {
            HardwareArchitecture::Superconducting => {
                let mut times = HashMap::new();
                times.insert("X".to_string(), 20e-9);
                times.insert("Y".to_string(), 20e-9);
                times.insert("Z".to_string(), 0.0);
                times.insert("H".to_string(), 20e-9);
                times.insert("CNOT".to_string(), 40e-9);
                times.insert("CZ".to_string(), 40e-9);
                times
            }
            HardwareArchitecture::TrappedIon => {
                let mut times = HashMap::new();
                times.insert("X".to_string(), 10e-6);
                times.insert("Y".to_string(), 10e-6);
                times.insert("Z".to_string(), 0.0);
                times.insert("H".to_string(), 10e-6);
                times.insert("CNOT".to_string(), 100e-6);
                times.insert("CZ".to_string(), 100e-6);
                times
            }
            _ => {
                let mut times = HashMap::new();
                times.insert("X".to_string(), 1e-6);
                times.insert("Y".to_string(), 1e-6);
                times.insert("Z".to_string(), 0.0);
                times.insert("H".to_string(), 1e-6);
                times.insert("CNOT".to_string(), 10e-6);
                times.insert("CZ".to_string(), 10e-6);
                times
            }
        };

        let crosstalk_matrix = Array2::zeros((num_qubits, num_qubits));

        Self {
            connectivity_graph,
            gate_fidelities,
            decoherence_times,
            gate_times,
            crosstalk_matrix,
        }
    }
}

/// Quantum machine learning trainer
pub struct QuantumMLTrainer {
    /// Configuration
    config: QMLConfig,
    /// Parameterized quantum circuit
    pqc: ParameterizedQuantumCircuit,
    /// Optimizer state
    optimizer_state: OptimizerState,
    /// Training history
    training_history: TrainingHistory,
    /// Device noise model
    noise_model: Option<Box<dyn DeviceNoiseModel>>,
    /// Circuit interface
    circuit_interface: CircuitInterface,
    /// Hardware-aware compiler
    hardware_compiler: HardwareAwareCompiler,
}

/// Optimizer state
#[derive(Debug, Clone)]
pub struct OptimizerState {
    /// Current parameter values
    pub parameters: Array1<f64>,
    /// Gradient estimate
    pub gradient: Array1<f64>,
    /// Momentum terms (for Adam, etc.)
    pub momentum: Array1<f64>,
    /// Velocity terms (for Adam, etc.)
    pub velocity: Array1<f64>,
    /// Learning rate schedule
    pub learning_rate: f64,
    /// Iteration counter
    pub iteration: usize,
}

/// Training history
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct TrainingHistory {
    /// Loss values over epochs
    pub loss_history: Vec<f64>,
    /// Gradient norms
    pub gradient_norms: Vec<f64>,
    /// Parameter norms
    pub parameter_norms: Vec<f64>,
    /// Training times per epoch
    pub epoch_times: Vec<f64>,
    /// Hardware utilization metrics
    pub hardware_metrics: Vec<HardwareMetrics>,
}

/// Hardware utilization metrics
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct HardwareMetrics {
    /// Circuit depth after compilation
    pub compiled_depth: usize,
    /// Number of two-qubit gates
    pub two_qubit_gates: usize,
    /// Total execution time
    pub execution_time: f64,
    /// Estimated fidelity
    pub estimated_fidelity: f64,
    /// Shot overhead
    pub shot_overhead: f64,
}

/// Hardware-aware compiler
#[derive(Debug, Clone)]
pub struct HardwareAwareCompiler {
    /// Target hardware architecture
    hardware_arch: HardwareArchitecture,
    /// Hardware optimizations
    hardware_opts: HardwareOptimizations,
    /// Compilation statistics
    compilation_stats: CompilationStats,
}

/// Compilation statistics
#[derive(Debug, Clone, Default)]
pub struct CompilationStats {
    /// Original circuit depth
    pub original_depth: usize,
    /// Compiled circuit depth
    pub compiled_depth: usize,
    /// Number of SWAP gates added
    pub swap_gates_added: usize,
    /// Compilation time
    pub compilation_time: f64,
    /// Estimated execution time
    pub estimated_execution_time: f64,
}

impl HardwareAwareCompiler {
    /// Create new hardware-aware compiler
    pub fn new(hardware_arch: HardwareArchitecture, num_qubits: usize) -> Self {
        let hardware_opts = HardwareOptimizations::for_hardware(hardware_arch, num_qubits);

        Self {
            hardware_arch,
            hardware_opts,
            compilation_stats: CompilationStats::default(),
        }
    }

    /// Compile circuit for target hardware
    pub fn compile_circuit(&mut self, circuit: &InterfaceCircuit) -> Result<InterfaceCircuit> {
        let start_time = std::time::Instant::now();

        let mut compiled_circuit = circuit.clone();
        self.compilation_stats.original_depth = circuit.calculate_depth();

        // Apply hardware-specific optimizations
        match self.hardware_arch {
            HardwareArchitecture::NISQ | HardwareArchitecture::Superconducting => {
                compiled_circuit = self.optimize_for_nisq(compiled_circuit)?;
            }
            HardwareArchitecture::TrappedIon => {
                compiled_circuit = self.optimize_for_trapped_ion(compiled_circuit)?;
            }
            HardwareArchitecture::Photonic => {
                compiled_circuit = self.optimize_for_photonic(compiled_circuit)?;
            }
            _ => {
                // Default optimizations
                compiled_circuit = self.apply_basic_optimizations(compiled_circuit)?;
            }
        }

        self.compilation_stats.compiled_depth = compiled_circuit.calculate_depth();
        self.compilation_stats.compilation_time = start_time.elapsed().as_secs_f64() * 1000.0;

        Ok(compiled_circuit)
    }

    /// Optimize circuit for NISQ devices
    fn optimize_for_nisq(&mut self, mut circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Gate fusion for reduced noise
        circuit = self.fuse_consecutive_gates(circuit)?;

        // Route for limited connectivity
        circuit = self.route_for_connectivity(circuit)?;

        // Minimize two-qubit gates
        circuit = self.minimize_two_qubit_gates(circuit)?;

        Ok(circuit)
    }

    /// Optimize for trapped ion systems
    fn optimize_for_trapped_ion(
        &mut self,
        mut circuit: InterfaceCircuit,
    ) -> Result<InterfaceCircuit> {
        // Take advantage of all-to-all connectivity
        circuit = self.optimize_for_all_to_all(circuit)?;

        // Optimize for native gate set
        circuit = self.decompose_to_native_gates(circuit, &["XX", "RX", "RY", "RZ"])?;

        Ok(circuit)
    }

    /// Optimize for photonic systems
    fn optimize_for_photonic(&mut self, mut circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Minimize measurement-based operations
        circuit = self.optimize_measurement_based(circuit)?;

        // Account for probabilistic gates
        circuit = self.handle_probabilistic_gates(circuit)?;

        Ok(circuit)
    }

    /// Apply basic circuit optimizations
    fn apply_basic_optimizations(
        &mut self,
        mut circuit: InterfaceCircuit,
    ) -> Result<InterfaceCircuit> {
        // Cancel adjacent inverse gates
        circuit = self.cancel_inverse_gates(circuit)?;

        // Commute gates through circuit
        circuit = self.commute_gates(circuit)?;

        Ok(circuit)
    }

    /// Fuse consecutive single-qubit gates
    fn fuse_consecutive_gates(&mut self, circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Simplified gate fusion - in practice this would be more sophisticated
        Ok(circuit)
    }

    /// Route circuit for limited connectivity
    fn route_for_connectivity(
        &mut self,
        mut circuit: InterfaceCircuit,
    ) -> Result<InterfaceCircuit> {
        let mut routed_gates = Vec::new();
        let mut swap_count = 0;

        for gate in &circuit.gates {
            match gate.gate_type {
                InterfaceGateType::CNOT | InterfaceGateType::CZ => {
                    if gate.qubits.len() >= 2 {
                        let q1 = gate.qubits[0];
                        let q2 = gate.qubits[1];

                        // Check if qubits are connected
                        if q1 < self.hardware_opts.connectivity_graph.nrows()
                            && q2 < self.hardware_opts.connectivity_graph.ncols()
                            && !self.hardware_opts.connectivity_graph[[q1, q2]]
                        {
                            // Need to add SWAP gates for routing
                            let route = self.find_shortest_route(q1, q2);
                            for &swap_qubit in &route {
                                routed_gates.push(InterfaceGate::new(
                                    InterfaceGateType::SWAP,
                                    vec![q1, swap_qubit],
                                ));
                                swap_count += 1;
                            }
                        }
                    }
                }
                _ => {}
            }
            routed_gates.push(gate.clone());
        }

        self.compilation_stats.swap_gates_added = swap_count;
        circuit.gates = routed_gates;
        Ok(circuit)
    }

    /// Find shortest routing path between qubits
    fn find_shortest_route(&self, q1: usize, q2: usize) -> Vec<usize> {
        // Simplified routing - BFS to find shortest path
        let mut visited = vec![false; self.hardware_opts.connectivity_graph.nrows()];
        let mut queue = VecDeque::new();
        let mut parent = vec![None; self.hardware_opts.connectivity_graph.nrows()];

        queue.push_back(q1);
        visited[q1] = true;

        while let Some(current) = queue.pop_front() {
            if current == q2 {
                break;
            }

            for (neighbor, &connected) in self
                .hardware_opts
                .connectivity_graph
                .row(current)
                .indexed_iter()
            {
                if connected && !visited[neighbor] {
                    visited[neighbor] = true;
                    parent[neighbor] = Some(current);
                    queue.push_back(neighbor);
                }
            }
        }

        // Reconstruct path (simplified)
        let mut path = Vec::new();
        let mut current = q2;
        while let Some(p) = parent[current] {
            if p != q1 {
                path.push(p);
            }
            current = p;
        }
        path.reverse();
        path
    }

    /// Minimize two-qubit gates
    fn minimize_two_qubit_gates(&mut self, circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // This would implement sophisticated gate count reduction
        Ok(circuit)
    }

    /// Optimize for all-to-all connectivity
    fn optimize_for_all_to_all(&mut self, circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Take advantage of full connectivity
        Ok(circuit)
    }

    /// Decompose to native gate set
    fn decompose_to_native_gates(
        &mut self,
        circuit: InterfaceCircuit,
        _native_gates: &[&str],
    ) -> Result<InterfaceCircuit> {
        // Decompose gates to native set
        Ok(circuit)
    }

    /// Optimize measurement-based operations
    fn optimize_measurement_based(
        &mut self,
        circuit: InterfaceCircuit,
    ) -> Result<InterfaceCircuit> {
        // Optimize for measurement-based quantum computing
        Ok(circuit)
    }

    /// Handle probabilistic gates
    fn handle_probabilistic_gates(
        &mut self,
        circuit: InterfaceCircuit,
    ) -> Result<InterfaceCircuit> {
        // Account for probabilistic nature of photonic gates
        Ok(circuit)
    }

    /// Cancel inverse gates
    fn cancel_inverse_gates(&mut self, circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Cancel adjacent inverse operations
        Ok(circuit)
    }

    /// Commute gates through circuit
    fn commute_gates(&mut self, circuit: InterfaceCircuit) -> Result<InterfaceCircuit> {
        // Commute gates to reduce depth
        Ok(circuit)
    }
}

impl QuantumMLTrainer {
    /// Create new quantum ML trainer
    pub fn new(config: QMLConfig) -> Result<Self> {
        let circuit_interface = CircuitInterface::new(Default::default())?;

        // Create parameterized quantum circuit based on algorithm type
        let pqc = Self::create_pqc(&config)?;

        // Initialize optimizer state
        let optimizer_state = OptimizerState {
            parameters: Array1::zeros(config.num_parameters),
            gradient: Array1::zeros(config.num_parameters),
            momentum: Array1::zeros(config.num_parameters),
            velocity: Array1::zeros(config.num_parameters),
            learning_rate: config.learning_rate,
            iteration: 0,
        };

        // Create hardware-aware compiler
        let hardware_compiler =
            HardwareAwareCompiler::new(config.hardware_architecture, config.num_qubits);

        // Initialize noise model if requested
        let noise_model = if config.noise_adaptive_training {
            // For now, use None as we need to properly implement DeviceNoiseModel
            None
        } else {
            None
        };

        Ok(Self {
            config,
            pqc,
            optimizer_state,
            training_history: TrainingHistory::default(),
            noise_model,
            circuit_interface,
            hardware_compiler,
        })
    }

    /// Create parameterized quantum circuit based on algorithm type
    fn create_pqc(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        match config.algorithm_type {
            QMLAlgorithmType::VQE => Self::create_vqe_ansatz(config),
            QMLAlgorithmType::QAOA => Self::create_qaoa_ansatz(config),
            QMLAlgorithmType::QCNN => Self::create_qcnn_ansatz(config),
            QMLAlgorithmType::QSVM => Self::create_qsvm_ansatz(config),
            QMLAlgorithmType::QRL => Self::create_qrl_ansatz(config),
            QMLAlgorithmType::QGAN => Self::create_qgan_ansatz(config),
            QMLAlgorithmType::QBM => Self::create_qbm_ansatz(config),
        }
    }

    /// Create VQE ansatz circuit
    fn create_vqe_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        let mut circuit = InterfaceCircuit::new(config.num_qubits, 0);
        let mut parameters = Vec::new();
        let mut parameter_names = Vec::new();
        let mut gate_parameter_map = HashMap::new();

        // Hardware-specific optimizations
        let hardware_optimizations =
            HardwareOptimizations::for_hardware(config.hardware_architecture, config.num_qubits);

        // Create layered ansatz
        for layer in 0..config.circuit_depth {
            // Single-qubit rotations
            for qubit in 0..config.num_qubits {
                let param_idx = parameters.len();

                // RY rotation
                circuit.add_gate(InterfaceGate::new(InterfaceGateType::RY(0.0), vec![qubit]));
                parameters.push(0.0);
                parameter_names.push(format!("ry_{}_{}", layer, qubit));
                gate_parameter_map.insert(circuit.gates.len() - 1, vec![param_idx]);

                // RZ rotation
                circuit.add_gate(InterfaceGate::new(InterfaceGateType::RZ(0.0), vec![qubit]));
                parameters.push(0.0);
                parameter_names.push(format!("rz_{}_{}", layer, qubit));
                gate_parameter_map.insert(circuit.gates.len() - 1, vec![param_idx + 1]);
            }

            // Entangling gates
            for qubit in 0..config.num_qubits.saturating_sub(1) {
                circuit.add_gate(InterfaceGate::new(
                    InterfaceGateType::CNOT,
                    vec![qubit, qubit + 1],
                ));
            }
        }

        Ok(ParameterizedQuantumCircuit {
            circuit,
            parameters: Array1::from_vec(parameters),
            parameter_names,
            gate_parameter_map,
            hardware_optimizations,
        })
    }

    /// Create QAOA ansatz circuit
    fn create_qaoa_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        let mut circuit = InterfaceCircuit::new(config.num_qubits, 0);
        let mut parameters = Vec::new();
        let mut parameter_names = Vec::new();
        let mut gate_parameter_map = HashMap::new();

        let hardware_optimizations =
            HardwareOptimizations::for_hardware(config.hardware_architecture, config.num_qubits);

        // Initial superposition
        for qubit in 0..config.num_qubits {
            circuit.add_gate(InterfaceGate::new(InterfaceGateType::Hadamard, vec![qubit]));
        }

        // QAOA layers
        for layer in 0..config.circuit_depth {
            // Problem Hamiltonian (ZZ interactions)
            for qubit in 0..config.num_qubits.saturating_sub(1) {
                let param_idx = parameters.len();

                circuit.add_gate(InterfaceGate::new(
                    InterfaceGateType::CNOT,
                    vec![qubit, qubit + 1],
                ));
                circuit.add_gate(InterfaceGate::new(
                    InterfaceGateType::RZ(0.0),
                    vec![qubit + 1],
                ));
                circuit.add_gate(InterfaceGate::new(
                    InterfaceGateType::CNOT,
                    vec![qubit, qubit + 1],
                ));

                parameters.push(0.0);
                parameter_names.push(format!("gamma_{}_{}", layer, qubit));
                gate_parameter_map.insert(circuit.gates.len() - 2, vec![param_idx]);
            }

            // Mixer Hamiltonian (X rotations)
            for qubit in 0..config.num_qubits {
                let param_idx = parameters.len();

                circuit.add_gate(InterfaceGate::new(InterfaceGateType::RX(0.0), vec![qubit]));

                parameters.push(0.0);
                parameter_names.push(format!("beta_{}_{}", layer, qubit));
                gate_parameter_map.insert(circuit.gates.len() - 1, vec![param_idx]);
            }
        }

        Ok(ParameterizedQuantumCircuit {
            circuit,
            parameters: Array1::from_vec(parameters),
            parameter_names,
            gate_parameter_map,
            hardware_optimizations,
        })
    }

    /// Create QCNN ansatz circuit
    fn create_qcnn_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        let mut circuit = InterfaceCircuit::new(config.num_qubits, 0);
        let mut parameters = Vec::new();
        let mut parameter_names = Vec::new();
        let mut gate_parameter_map = HashMap::new();

        let hardware_optimizations =
            HardwareOptimizations::for_hardware(config.hardware_architecture, config.num_qubits);

        // Convolutional layers
        let mut current_qubits = config.num_qubits;
        for layer in 0..config.circuit_depth {
            // Convolution operations
            for i in (0..current_qubits).step_by(2) {
                if i + 1 < current_qubits {
                    let param_idx = parameters.len();

                    // Parameterized two-qubit gate
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::RY(0.0), vec![i]));
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::RY(0.0), vec![i + 1]));
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::CNOT, vec![i, i + 1]));
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::RY(0.0), vec![i + 1]));

                    parameters.extend_from_slice(&[0.0, 0.0, 0.0]);
                    parameter_names.extend_from_slice(&[
                        format!("conv_{}_{}_0", layer, i),
                        format!("conv_{}_{}_1", layer, i),
                        format!("conv_{}_{}_2", layer, i),
                    ]);

                    gate_parameter_map.insert(circuit.gates.len() - 4, vec![param_idx]);
                    gate_parameter_map.insert(circuit.gates.len() - 3, vec![param_idx + 1]);
                    gate_parameter_map.insert(circuit.gates.len() - 1, vec![param_idx + 2]);
                }
            }

            // Pooling (reduce qubit count)
            current_qubits = current_qubits / 2;
        }

        Ok(ParameterizedQuantumCircuit {
            circuit,
            parameters: Array1::from_vec(parameters),
            parameter_names,
            gate_parameter_map,
            hardware_optimizations,
        })
    }

    /// Create QSVM ansatz circuit
    fn create_qsvm_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        // Feature map circuit for QSVM
        let mut circuit = InterfaceCircuit::new(config.num_qubits, 0);
        let mut parameters = Vec::new();
        let mut parameter_names = Vec::new();
        let mut gate_parameter_map = HashMap::new();

        let hardware_optimizations =
            HardwareOptimizations::for_hardware(config.hardware_architecture, config.num_qubits);

        // Feature encoding layers
        for layer in 0..config.circuit_depth {
            // Single-qubit feature encoding
            for qubit in 0..config.num_qubits {
                let param_idx = parameters.len();

                circuit.add_gate(InterfaceGate::new(InterfaceGateType::RZ(0.0), vec![qubit]));

                parameters.push(0.0);
                parameter_names.push(format!("feature_{}_{}", layer, qubit));
                gate_parameter_map.insert(circuit.gates.len() - 1, vec![param_idx]);
            }

            // Two-qubit feature interactions
            for i in 0..config.num_qubits {
                for j in i + 1..config.num_qubits {
                    let param_idx = parameters.len();

                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::CNOT, vec![i, j]));
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::RZ(0.0), vec![j]));
                    circuit.add_gate(InterfaceGate::new(InterfaceGateType::CNOT, vec![i, j]));

                    parameters.push(0.0);
                    parameter_names.push(format!("interaction_{}_{}_{}", layer, i, j));
                    gate_parameter_map.insert(circuit.gates.len() - 2, vec![param_idx]);
                }
            }
        }

        Ok(ParameterizedQuantumCircuit {
            circuit,
            parameters: Array1::from_vec(parameters),
            parameter_names,
            gate_parameter_map,
            hardware_optimizations,
        })
    }

    /// Create QRL ansatz circuit
    fn create_qrl_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        // Policy network for quantum reinforcement learning
        Self::create_vqe_ansatz(config) // Use VQE-like ansatz for simplicity
    }

    /// Create QGAN ansatz circuit
    fn create_qgan_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        // Generator circuit for QGAN
        Self::create_vqe_ansatz(config) // Use VQE-like ansatz for simplicity
    }

    /// Create QBM ansatz circuit
    fn create_qbm_ansatz(config: &QMLConfig) -> Result<ParameterizedQuantumCircuit> {
        // Quantum Boltzmann machine ansatz
        Self::create_vqe_ansatz(config) // Use VQE-like ansatz for simplicity
    }

    /// Train the quantum ML model
    pub fn train<F>(
        &mut self,
        loss_function: F,
        training_data: &[Array1<f64>],
    ) -> Result<TrainingResult>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        let start_time = std::time::Instant::now();

        for epoch in 0..self.config.max_epochs {
            let epoch_start = std::time::Instant::now();

            // Shuffle training data
            let mut shuffled_indices: Vec<usize> = (0..training_data.len()).collect();
            for i in 0..shuffled_indices.len() {
                let j = fastrand::usize(i..shuffled_indices.len());
                shuffled_indices.swap(i, j);
            }

            let mut epoch_loss = 0.0;
            let mut batch_count = 0;

            // Process in batches
            for batch_start in (0..training_data.len()).step_by(self.config.batch_size) {
                let batch_end = (batch_start + self.config.batch_size).min(training_data.len());
                let batch_indices = &shuffled_indices[batch_start..batch_end];

                // Compute gradient for batch
                let gradient = self.compute_gradient_batch(
                    &loss_function,
                    &batch_indices
                        .iter()
                        .map(|&i| &training_data[i])
                        .collect::<Vec<_>>(),
                )?;

                // Update parameters using optimizer
                self.update_parameters(&gradient)?;

                // Compute batch loss
                let batch_loss = batch_indices
                    .iter()
                    .map(|&i| {
                        let output = self
                            .forward_pass(&training_data[i])
                            .unwrap_or_else(|_| Array1::zeros(1));
                        loss_function(&output, &training_data[i])
                    })
                    .sum::<f64>()
                    / batch_indices.len() as f64;

                epoch_loss += batch_loss;
                batch_count += 1;
            }

            epoch_loss /= batch_count as f64;

            // Update training history
            let epoch_time = epoch_start.elapsed().as_secs_f64() * 1000.0;
            self.training_history.loss_history.push(epoch_loss);
            self.training_history.gradient_norms.push(
                (&self.optimizer_state.gradient * &self.optimizer_state.gradient)
                    .sum()
                    .sqrt(),
            );
            self.training_history.parameter_norms.push(
                (&self.optimizer_state.parameters * &self.optimizer_state.parameters)
                    .sum()
                    .sqrt(),
            );
            self.training_history.epoch_times.push(epoch_time);

            // Collect hardware metrics
            let hw_metrics = self.collect_hardware_metrics()?;
            self.training_history.hardware_metrics.push(hw_metrics);

            // Check convergence
            if epoch_loss < self.config.convergence_tolerance {
                break;
            }

            // Adaptive learning rate
            if epoch > 0 && epoch % 10 == 0 {
                self.optimizer_state.learning_rate *= 0.95;
            }
        }

        let total_time = start_time.elapsed().as_secs_f64() * 1000.0;

        Ok(TrainingResult {
            final_parameters: self.optimizer_state.parameters.clone(),
            final_loss: self
                .training_history
                .loss_history
                .last()
                .cloned()
                .unwrap_or(f64::INFINITY),
            training_history: self.training_history.clone(),
            total_training_time: total_time,
            convergence_achieved: self
                .training_history
                .loss_history
                .last()
                .unwrap_or(&f64::INFINITY)
                < &self.config.convergence_tolerance,
        })
    }

    /// Compute gradient for a batch of data
    fn compute_gradient_batch<F>(
        &mut self,
        loss_function: &F,
        batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        match self.config.gradient_method {
            GradientMethod::ParameterShift => {
                self.parameter_shift_gradient(loss_function, batch_data)
            }
            GradientMethod::FiniteDifferences => {
                self.finite_difference_gradient(loss_function, batch_data)
            }
            GradientMethod::AutomaticDifferentiation => {
                self.autodiff_gradient(loss_function, batch_data)
            }
            GradientMethod::NaturalGradients => self.natural_gradient(loss_function, batch_data),
            GradientMethod::StochasticParameterShift => {
                self.stochastic_parameter_shift_gradient(loss_function, batch_data)
            }
        }
    }

    /// Parameter shift rule gradient estimation
    fn parameter_shift_gradient<F>(
        &mut self,
        loss_function: &F,
        batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        let mut gradient = Array1::zeros(self.optimizer_state.parameters.len());
        let shift = std::f64::consts::PI / 2.0;

        // Compute gradient for each parameter
        gradient.par_mapv_inplace(|_| 0.0);

        for (param_idx, grad_elem) in gradient.iter_mut().enumerate() {
            let mut plus_loss = 0.0;
            let mut minus_loss = 0.0;

            // Forward pass with +shift
            self.optimizer_state.parameters[param_idx] += shift;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                plus_loss += loss_function(&output, data);
            }

            // Forward pass with -shift
            self.optimizer_state.parameters[param_idx] -= 2.0 * shift;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                minus_loss += loss_function(&output, data);
            }

            // Restore original parameter
            self.optimizer_state.parameters[param_idx] += shift;

            // Compute gradient using parameter shift rule
            *grad_elem = (plus_loss - minus_loss) / (2.0 * batch_data.len() as f64);
        }

        Ok(gradient)
    }

    /// Finite differences gradient estimation
    fn finite_difference_gradient<F>(
        &mut self,
        loss_function: &F,
        batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        let mut gradient = Array1::zeros(self.optimizer_state.parameters.len());
        let eps = 1e-6;

        for (param_idx, grad_elem) in gradient.iter_mut().enumerate() {
            let mut plus_loss = 0.0;
            let mut minus_loss = 0.0;

            // Forward pass with +eps
            self.optimizer_state.parameters[param_idx] += eps;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                plus_loss += loss_function(&output, data);
            }

            // Forward pass with -eps
            self.optimizer_state.parameters[param_idx] -= 2.0 * eps;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                minus_loss += loss_function(&output, data);
            }

            // Restore original parameter
            self.optimizer_state.parameters[param_idx] += eps;

            // Compute finite difference gradient
            *grad_elem = (plus_loss - minus_loss) / (2.0 * eps * batch_data.len() as f64);
        }

        Ok(gradient)
    }

    /// Automatic differentiation gradient (placeholder)
    fn autodiff_gradient<F>(
        &mut self,
        _loss_function: &F,
        _batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        // Placeholder for automatic differentiation
        // In practice, this would use a proper autodiff framework
        Ok(Array1::zeros(self.optimizer_state.parameters.len()))
    }

    /// Natural gradients (placeholder)
    fn natural_gradient<F>(
        &mut self,
        loss_function: &F,
        batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        // Use parameter shift rule as a fallback
        self.parameter_shift_gradient(loss_function, batch_data)
    }

    /// Stochastic parameter shift gradient
    fn stochastic_parameter_shift_gradient<F>(
        &mut self,
        loss_function: &F,
        batch_data: &[&Array1<f64>],
    ) -> Result<Array1<f64>>
    where
        F: Fn(&Array1<f64>, &Array1<f64>) -> f64 + Sync,
    {
        // Randomly sample subset of parameters for gradient estimation
        let num_sampled = (self.optimizer_state.parameters.len() / 2).max(1);
        let mut gradient = Array1::zeros(self.optimizer_state.parameters.len());

        for _ in 0..num_sampled {
            let param_idx = fastrand::usize(0..self.optimizer_state.parameters.len());
            let shift = std::f64::consts::PI / 2.0;

            let mut plus_loss = 0.0;
            let mut minus_loss = 0.0;

            // Forward pass with +shift
            self.optimizer_state.parameters[param_idx] += shift;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                plus_loss += loss_function(&output, data);
            }

            // Forward pass with -shift
            self.optimizer_state.parameters[param_idx] -= 2.0 * shift;
            for &data in batch_data {
                let output = self.forward_pass(data)?;
                minus_loss += loss_function(&output, data);
            }

            // Restore original parameter
            self.optimizer_state.parameters[param_idx] += shift;

            // Update gradient estimate
            gradient[param_idx] = (plus_loss - minus_loss) / (2.0 * batch_data.len() as f64);
        }

        Ok(gradient)
    }

    /// Forward pass through the parameterized quantum circuit
    fn forward_pass(&mut self, input_data: &Array1<f64>) -> Result<Array1<f64>> {
        // Update circuit parameters
        self.update_circuit_parameters()?;

        // Compile circuit for target hardware
        let compiled_circuit = self.hardware_compiler.compile_circuit(&self.pqc.circuit)?;

        // Execute circuit (simplified - would use actual quantum simulator)
        let mut simulator = StateVectorSimulator::new();

        // Apply gates from compiled circuit
        for gate in &compiled_circuit.gates {
            match gate.gate_type {
                // TODO: Implement proper gate application with circuit interface
                _ => {
                    // Placeholder - gates are not actually applied to the simulator
                }
            }
        }

        // Measure expectations (simplified)
        // TODO: Implement proper state retrieval with circuit interface
        let probabilities: Vec<f64> = vec![1.0; 1 << self.config.num_qubits];

        Ok(Array1::from_vec(probabilities))
    }

    /// Update circuit parameters from optimizer state
    fn update_circuit_parameters(&mut self) -> Result<()> {
        self.pqc.parameters = self.optimizer_state.parameters.clone();
        Ok(())
    }

    /// Update parameters using the chosen optimizer
    fn update_parameters(&mut self, gradient: &Array1<f64>) -> Result<()> {
        self.optimizer_state.gradient = gradient.clone();

        match self.config.optimizer_type {
            OptimizerType::Adam => self.adam_update(),
            OptimizerType::SGD => self.sgd_update(),
            OptimizerType::RMSprop => self.rmsprop_update(),
            OptimizerType::LBFGS => self.lbfgs_update(),
            OptimizerType::QuantumNaturalGradient => self.quantum_natural_gradient_update(),
            OptimizerType::SPSA => self.spsa_update(),
        }
    }

    /// Adam optimizer update
    fn adam_update(&mut self) -> Result<()> {
        let beta1 = 0.9;
        let beta2 = 0.999;
        let eps = 1e-8;

        self.optimizer_state.iteration += 1;
        let t = self.optimizer_state.iteration as f64;

        // Update momentum and velocity
        self.optimizer_state.momentum =
            beta1 * &self.optimizer_state.momentum + (1.0 - beta1) * &self.optimizer_state.gradient;
        self.optimizer_state.velocity = beta2 * &self.optimizer_state.velocity
            + (1.0 - beta2) * self.optimizer_state.gradient.mapv(|g| g * g);

        // Bias correction
        let momentum_corrected = &self.optimizer_state.momentum / (1.0 - beta1.powf(t));
        let velocity_corrected = &self.optimizer_state.velocity / (1.0 - beta2.powf(t));

        // Parameter update
        for i in 0..self.optimizer_state.parameters.len() {
            self.optimizer_state.parameters[i] -= self.optimizer_state.learning_rate
                * momentum_corrected[i]
                / (velocity_corrected[i].sqrt() + eps);
        }

        Ok(())
    }

    /// SGD optimizer update
    fn sgd_update(&mut self) -> Result<()> {
        self.optimizer_state.parameters = &self.optimizer_state.parameters
            - self.optimizer_state.learning_rate * &self.optimizer_state.gradient;
        Ok(())
    }

    /// RMSprop optimizer update
    fn rmsprop_update(&mut self) -> Result<()> {
        let decay_rate = 0.9;
        let eps = 1e-8;

        // Update velocity
        self.optimizer_state.velocity = decay_rate * &self.optimizer_state.velocity
            + (1.0 - decay_rate) * self.optimizer_state.gradient.mapv(|g| g * g);

        // Parameter update
        for i in 0..self.optimizer_state.parameters.len() {
            self.optimizer_state.parameters[i] -= self.optimizer_state.learning_rate
                * self.optimizer_state.gradient[i]
                / (self.optimizer_state.velocity[i].sqrt() + eps);
        }

        Ok(())
    }

    /// L-BFGS optimizer update (simplified)
    fn lbfgs_update(&mut self) -> Result<()> {
        // Simplified L-BFGS - in practice would need history storage
        self.sgd_update()
    }

    /// Quantum natural gradient update (simplified)
    fn quantum_natural_gradient_update(&mut self) -> Result<()> {
        // Simplified quantum natural gradient
        self.sgd_update()
    }

    /// SPSA optimizer update
    fn spsa_update(&mut self) -> Result<()> {
        let a = 0.16;
        let c = 0.1;
        let alpha = 0.602;
        let gamma = 0.101;

        self.optimizer_state.iteration += 1;
        let k = self.optimizer_state.iteration as f64;

        let ak = a / (k + 1.0).powf(alpha);
        let ck = c / k.powf(gamma);

        // Generate random perturbation
        let mut perturbation = Array1::zeros(self.optimizer_state.parameters.len());
        for elem in perturbation.iter_mut() {
            *elem = if fastrand::bool() { 1.0 } else { -1.0 };
        }

        // Estimate gradient using SPSA
        let spsa_gradient = &self.optimizer_state.gradient / &perturbation * ck;

        // Update parameters
        self.optimizer_state.parameters = &self.optimizer_state.parameters - ak * &spsa_gradient;

        Ok(())
    }

    /// Collect hardware utilization metrics
    fn collect_hardware_metrics(&self) -> Result<HardwareMetrics> {
        let compiled_depth = self.hardware_compiler.compilation_stats.compiled_depth;
        let two_qubit_gates = self
            .pqc
            .circuit
            .gates
            .iter()
            .filter(|gate| {
                matches!(
                    gate.gate_type,
                    InterfaceGateType::CNOT | InterfaceGateType::CZ
                )
            })
            .count();

        let execution_time = self
            .hardware_compiler
            .compilation_stats
            .estimated_execution_time;

        // Estimate fidelity based on gate count and hardware parameters
        let mut estimated_fidelity = 1.0;
        for gate in &self.pqc.circuit.gates {
            let gate_name = format!("{:?}", gate.gate_type);
            if let Some(&fidelity) = self
                .pqc
                .hardware_optimizations
                .gate_fidelities
                .get(&gate_name)
            {
                estimated_fidelity *= fidelity;
            } else {
                estimated_fidelity *= 0.99; // Default fidelity
            }
        }

        let shot_overhead = if self.config.shot_budget > 1000 {
            1.0
        } else {
            2.0
        };

        Ok(HardwareMetrics {
            compiled_depth,
            two_qubit_gates,
            execution_time,
            estimated_fidelity,
            shot_overhead,
        })
    }

    /// Get training history
    pub fn get_training_history(&self) -> &TrainingHistory {
        &self.training_history
    }

    /// Get current parameters
    pub fn get_parameters(&self) -> &Array1<f64> {
        &self.optimizer_state.parameters
    }

    /// Set parameters
    pub fn set_parameters(&mut self, parameters: Array1<f64>) -> Result<()> {
        if parameters.len() != self.optimizer_state.parameters.len() {
            return Err(SimulatorError::InvalidInput(
                "Parameter dimension mismatch".to_string(),
            ));
        }
        self.optimizer_state.parameters = parameters;
        Ok(())
    }
}

/// Training result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingResult {
    /// Final optimized parameters
    pub final_parameters: Array1<f64>,
    /// Final loss value
    pub final_loss: f64,
    /// Training history
    pub training_history: TrainingHistory,
    /// Total training time in milliseconds
    pub total_training_time: f64,
    /// Whether convergence was achieved
    pub convergence_achieved: bool,
}

/// Benchmark quantum ML algorithms
pub fn benchmark_quantum_ml_algorithms() -> Result<HashMap<String, f64>> {
    let mut results = HashMap::new();

    // Test different QML algorithms
    let algorithms = vec![
        QMLAlgorithmType::VQE,
        QMLAlgorithmType::QAOA,
        QMLAlgorithmType::QCNN,
        QMLAlgorithmType::QSVM,
    ];

    let hardware_archs = vec![
        HardwareArchitecture::NISQ,
        HardwareArchitecture::Superconducting,
        HardwareArchitecture::TrappedIon,
    ];

    for &algorithm in &algorithms {
        for &hardware in &hardware_archs {
            let start = std::time::Instant::now();

            let config = QMLConfig {
                algorithm_type: algorithm,
                hardware_architecture: hardware,
                num_qubits: 4,
                circuit_depth: 2,
                num_parameters: 8,
                max_epochs: 5,
                batch_size: 4,
                ..Default::default()
            };

            let mut trainer = QuantumMLTrainer::new(config)?;

            // Generate dummy training data
            let training_data: Vec<Array1<f64>> = (0..20)
                .map(|_| {
                    Array1::from_vec(vec![
                        fastrand::f64(),
                        fastrand::f64(),
                        fastrand::f64(),
                        fastrand::f64(),
                    ])
                })
                .collect();

            // Simple quadratic loss function
            let loss_fn = |output: &Array1<f64>, target: &Array1<f64>| {
                output
                    .iter()
                    .zip(target.iter())
                    .map(|(o, t)| (o - t).powi(2))
                    .sum::<f64>()
                    / output.len() as f64
            };

            let _result = trainer.train(loss_fn, &training_data)?;

            let time = start.elapsed().as_secs_f64() * 1000.0;
            results.insert(format!("{:?}_{:?}", algorithm, hardware), time);
        }
    }

    Ok(results)
}

#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_abs_diff_eq;

    #[test]
    fn test_qml_trainer_creation() {
        let config = QMLConfig::default();
        let trainer = QuantumMLTrainer::new(config);
        assert!(trainer.is_ok());
    }

    #[test]
    fn test_hardware_optimizations() {
        let num_qubits = 4;
        let hardware_opts =
            HardwareOptimizations::for_hardware(HardwareArchitecture::Superconducting, num_qubits);

        assert_eq!(hardware_opts.connectivity_graph.nrows(), num_qubits);
        assert!(hardware_opts.gate_fidelities.contains_key("CNOT"));
        assert_eq!(hardware_opts.decoherence_times.len(), num_qubits);
    }

    #[test]
    fn test_pqc_creation() {
        let config = QMLConfig {
            algorithm_type: QMLAlgorithmType::VQE,
            num_qubits: 3,
            circuit_depth: 2,
            ..Default::default()
        };

        let pqc = QuantumMLTrainer::create_vqe_ansatz(&config);
        assert!(pqc.is_ok());

        let circuit = pqc.unwrap();
        assert!(!circuit.circuit.gates.is_empty());
        assert!(!circuit.parameters.is_empty());
    }

    #[test]
    fn test_optimizer_state_initialization() {
        let config = QMLConfig::default();
        let trainer = QuantumMLTrainer::new(config).unwrap();

        assert_eq!(
            trainer.optimizer_state.parameters.len(),
            trainer.config.num_parameters
        );
        assert_eq!(
            trainer.optimizer_state.gradient.len(),
            trainer.config.num_parameters
        );
        assert_abs_diff_eq!(
            trainer.optimizer_state.learning_rate,
            trainer.config.learning_rate,
            epsilon = 1e-10
        );
    }

    #[test]
    fn test_hardware_aware_compiler() {
        let mut compiler = HardwareAwareCompiler::new(HardwareArchitecture::NISQ, 4);

        let mut circuit = InterfaceCircuit::new(4, 0);
        circuit.add_gate(InterfaceGate::new(InterfaceGateType::H, vec![0]));
        circuit.add_gate(InterfaceGate::new(InterfaceGateType::CNOT, vec![0, 1]));

        let compiled = compiler.compile_circuit(&circuit);
        assert!(compiled.is_ok());
    }

    #[test]
    fn test_different_algorithm_types() {
        let algorithms = vec![
            QMLAlgorithmType::VQE,
            QMLAlgorithmType::QAOA,
            QMLAlgorithmType::QCNN,
            QMLAlgorithmType::QSVM,
        ];

        for algorithm in algorithms {
            let config = QMLConfig {
                algorithm_type: algorithm,
                num_qubits: 3,
                circuit_depth: 1,
                ..Default::default()
            };

            let trainer = QuantumMLTrainer::new(config);
            assert!(trainer.is_ok(), "Failed for algorithm: {:?}", algorithm);
        }
    }

    #[test]
    fn test_parameter_updates() {
        let config = QMLConfig::default();
        let mut trainer = QuantumMLTrainer::new(config).unwrap();

        // Use the correct number of parameters (12 for default config)
        let new_params = Array1::from_vec(vec![
            0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2,
        ]);
        trainer.set_parameters(new_params.clone()).unwrap();

        assert_abs_diff_eq!(trainer.get_parameters()[0], 0.1, epsilon = 1e-10);
        assert_abs_diff_eq!(trainer.get_parameters()[1], 0.2, epsilon = 1e-10);
        assert_abs_diff_eq!(trainer.get_parameters()[11], 1.2, epsilon = 1e-10);
    }

    #[test]
    fn test_gradient_computation() {
        let config = QMLConfig {
            num_qubits: 2,
            circuit_depth: 1,
            num_parameters: 4,
            gradient_method: GradientMethod::FiniteDifferences,
            ..Default::default()
        };

        let mut trainer = QuantumMLTrainer::new(config).unwrap();

        let data = vec![Array1::from_vec(vec![0.5, 0.5])];
        let batch_refs: Vec<&Array1<f64>> = data.iter().collect();

        let loss_fn = |output: &Array1<f64>, _target: &Array1<f64>| {
            output.iter().map(|&x| x * x).sum::<f64>()
        };

        let gradient = trainer.compute_gradient_batch(&loss_fn, &batch_refs);
        assert!(gradient.is_ok());

        let grad = gradient.unwrap();
        assert_eq!(grad.len(), 4);
    }

    #[test]
    fn test_training_simple_case() {
        let config = QMLConfig {
            num_qubits: 2,
            circuit_depth: 1,
            num_parameters: 4,
            max_epochs: 2,
            batch_size: 2,
            ..Default::default()
        };

        let mut trainer = QuantumMLTrainer::new(config).unwrap();

        let training_data = vec![
            Array1::from_vec(vec![0.0, 1.0]),
            Array1::from_vec(vec![1.0, 0.0]),
        ];

        let loss_fn = |output: &Array1<f64>, target: &Array1<f64>| {
            output
                .iter()
                .zip(target.iter())
                .map(|(o, t)| (o - t).powi(2))
                .sum::<f64>()
                / output.len() as f64
        };

        let result = trainer.train(loss_fn, &training_data);
        assert!(result.is_ok());

        let training_result = result.unwrap();
        assert_eq!(training_result.training_history.loss_history.len(), 2);
    }
}
