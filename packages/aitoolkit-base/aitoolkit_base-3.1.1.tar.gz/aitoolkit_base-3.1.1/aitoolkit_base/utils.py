# ä¼˜å…ˆå±è”½æ‰€æœ‰å¯èƒ½çš„æ—¥å¿—è¾“å‡º
import os
import sys
import warnings
import logging

# æœ€é«˜ä¼˜å…ˆçº§ï¼šå±è”½TensorFlowæ—¥å¿—
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # å¼ºåˆ¶ä½¿ç”¨CPUï¼Œæé«˜ç¨³å®šæ€§

# å±è”½æ‰€æœ‰è­¦å‘Š
warnings.simplefilter('ignore')
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

# è®¾ç½®æ‰€æœ‰å¯èƒ½çš„ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
for logger_name in ['tensorflow', 'mediapipe', 'absl', 'h5py', 'PIL']:
    logging.getLogger(logger_name).setLevel(logging.ERROR)

# é™é»˜æ¨¡å¼å¯åŠ¨
def silent_import():
    """é™é»˜å¯¼å…¥æ¨¡å¼ï¼Œå±è”½å¯åŠ¨æ—¶çš„æ‰€æœ‰è¾“å‡º"""
    # ä¸´æ—¶é‡å®šå‘stderr
    original_stderr = sys.stderr
    original_stdout = sys.stdout
    
    try:
        # åˆ›å»ºç©ºçš„è¾“å‡º
        from io import StringIO
        sys.stderr = StringIO()
        sys.stdout = StringIO()
        
        # å¯¼å…¥MediaPipeå’ŒTensorFlowç›¸å…³æ¨¡å—
        import mediapipe as mp
        import cv2
        
        # æ¢å¤è¾“å‡º
        sys.stderr = original_stderr
        sys.stdout = original_stdout
        
        return True
    except Exception as e:
        # æ¢å¤è¾“å‡º
        sys.stderr = original_stderr  
        sys.stdout = original_stdout
        print(f"é™é»˜å¯¼å…¥å¤±è´¥: {e}")
        return False

# åœ¨æ¨¡å—åŠ è½½æ—¶æ‰§è¡Œé™é»˜å¯¼å…¥
# silent_import()

import cv2
import numpy as np
import time
import threading
import pathlib
from typing import Optional, Union, List, Tuple
import requests
from urllib.parse import urlparse

# MediaPipeç›¸å…³å¯¼å…¥
try:
    import mediapipe as mp
    from mediapipe.tasks.python.components.containers.bounding_box import BoundingBox
    from mediapipe.python.solutions import drawing_utils as mp_drawing
    from mediapipe.python.solutions import drawing_styles as mp_drawing_styles
    from mediapipe.tasks.python.components.containers.landmark import NormalizedLandmark
    from mediapipe.framework.formats import landmark_pb2
    MEDIAPIPE_AVAILABLE = True
except ImportError as e:
    print(f"MediaPipeå¯¼å…¥å¤±è´¥: {e}")
    # åˆ›å»ºå ä½ç¬¦ç±»
    class BoundingBox:
        def __init__(self):
            self.origin_x = 0
            self.origin_y = 0
            self.width = 0
            self.height = 0
    
    class NormalizedLandmark:
        def __init__(self):
            self.x = 0.0
            self.y = 0.0
            self.z = 0.0
            
    MEDIAPIPE_AVAILABLE = False

# æ¨¡å‹æ–‡ä»¶æ˜ å°„è¡¨
MODEL_MAPPING = {
    "face_detector.tflite": "face_detector.tflite",
    "face_landmarker.task": "face_landmarker.task", 
    "hand_landmarker.task": "hand_landmarker.task",
    "pose_landmarker.task": "pose_landmarker.task",
    "gesture_recognizer.task": "gesture_recognizer.task",
    "selfie_segmenter.tflite": "selfie_segmenter.tflite",
    "selfie_segmenter_landscape.tflite": "selfie_segmenter_landscape.tflite",
    "deeplab_v3.tflite": "deeplab_v3.tflite",
}

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - å¤„ç†æ¨¡å‹æ–‡ä»¶çš„ä¸‹è½½å’Œè·¯å¾„ç®¡ç†"""
    
    BASE_URL = "https://storage.googleapis.com/mediapipe-models"
    MODELS_DIR = pathlib.Path(__file__).parent / "models"
    
    @classmethod
    def ensure_models_dir(cls):
        """ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨"""
        cls.MODELS_DIR.mkdir(exist_ok=True)
        return cls.MODELS_DIR
    
    @classmethod 
    def get_model_path(cls, model_name: str) -> str:
        """è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        models_dir = cls.ensure_models_dir()
        
        # è§„èŒƒåŒ–æ¨¡å‹åç§°
        if model_name in MODEL_MAPPING:
            actual_name = MODEL_MAPPING[model_name]
        else:
            actual_name = model_name
            
        model_path = models_dir / actual_name
        
        if model_path.exists():
            return str(model_path)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä¸‹è½½
        success = cls.download_model(model_name, str(model_path))
        if success:
            return str(model_path)
        else:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ä¸”ä¸‹è½½å¤±è´¥: {model_name}")
    
    @classmethod
    def download_model(cls, model_name: str, save_path: str) -> bool:
        """ä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
        try:
            # MediaPipeæ¨¡å‹çš„æ ‡å‡†ä¸‹è½½URLæ„å»º
            model_urls = {
                "face_detector.tflite": f"{cls.BASE_URL}/face_detection/face_detection_short_range/float16/1/face_detection_short_range.tflite",
                "face_landmarker.task": f"{cls.BASE_URL}/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                "hand_landmarker.task": f"{cls.BASE_URL}/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
                "pose_landmarker.task": f"{cls.BASE_URL}/pose_landmarker/pose_landmarker/float16/1/pose_landmarker.task",
                "gesture_recognizer.task": f"{cls.BASE_URL}/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
            }
            
            actual_name = MODEL_MAPPING.get(model_name, model_name)
            if actual_name not in model_urls:
                print(f"æœªçŸ¥çš„æ¨¡å‹: {model_name}")
                return False
            
            url = model_urls[actual_name]
            print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
            
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            print(f"æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_name}")
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹ä¸‹è½½å¤±è´¥ {model_name}: {e}")
            return False

class ImageUtils:
    """å›¾åƒå¤„ç†å·¥å…·ç±»"""
    
    @staticmethod
    def resize_image(image, max_size=1024):
        """
        è°ƒæ•´å›¾åƒå¤§å°ï¼Œä¿æŒå®½é«˜æ¯”
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            max_size: æœ€å¤§è¾¹é•¿
        è¿”å›:
            è°ƒæ•´åçš„å›¾åƒ
        """
        height, width = image.shape[:2]
        
        # å¦‚æœå›¾åƒå°ºå¯¸å·²ç»å°äºæœ€å¤§å°ºå¯¸ï¼Œç›´æ¥è¿”å›
        if max(height, width) <= max_size:
            return image
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = max_size / max(height, width)
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        # è°ƒæ•´å›¾åƒå¤§å°
        resized = cv2.resize(image, (new_width, new_height))
        return resized
    
    @staticmethod
    def draw_fps(image, fps):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶FPS
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            fps: FPSå€¼
        è¿”å›:
            æ·»åŠ FPSæ˜¾ç¤ºçš„å›¾åƒ
        """
        # åœ¨å·¦ä¸Šè§’ç»˜åˆ¶FPS
        cv2.putText(image, f"FPS: {fps:.1f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        return image

class VisUtil:
    """å¯è§†åŒ–å·¥å…·ç±»"""
    
    @staticmethod
    def draw_bounding_box(image: np.ndarray, box: BoundingBox, label: str = "", color: Tuple[int, int, int] = (0, 255, 0), thickness: int = 2) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            box: è¾¹ç•Œæ¡†å¯¹è±¡
            label: æ ‡ç­¾æ–‡æœ¬
            color: è¾¹ç•Œæ¡†é¢œè‰²
            thickness: çº¿æ¡ç²—ç»†
        è¿”å›:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        if not MEDIAPIPE_AVAILABLE:
            return image
            
        # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
        start_point = (int(box.origin_x), int(box.origin_y))
        end_point = (int(box.origin_x + box.width), int(box.origin_y + box.height))
        
        # ç»˜åˆ¶çŸ©å½¢
        cv2.rectangle(image, start_point, end_point, color, thickness)
        
        # å¦‚æœæœ‰æ ‡ç­¾ï¼Œç»˜åˆ¶æ ‡ç­¾
        if label:
            cv2.putText(image, label, (start_point[0], start_point[1] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)
        
        return image
    
    @staticmethod 
    def draw_landmarks(image: np.ndarray, landmarks: List[NormalizedLandmark], connections=None, 
                      landmark_color: Tuple[int, int, int] = (0, 255, 0), 
                      connection_color: Tuple[int, int, int] = (255, 255, 255),
                      thickness: int = 2) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶å…³é”®ç‚¹
        å‚æ•°:
            image: è¾“å…¥å›¾åƒ
            landmarks: å…³é”®ç‚¹åˆ—è¡¨
            connections: è¿æ¥å…³ç³»
            landmark_color: å…³é”®ç‚¹é¢œè‰²
            connection_color: è¿æ¥çº¿é¢œè‰²
            thickness: çº¿æ¡ç²—ç»†
        è¿”å›:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        if not MEDIAPIPE_AVAILABLE or not landmarks:
            return image
            
        h, w = image.shape[:2]
        
        # ç»˜åˆ¶è¿æ¥çº¿
        if connections:
            for connection in connections:
                start_idx, end_idx = connection
                if start_idx < len(landmarks) and end_idx < len(landmarks):
                    start_point = (int(landmarks[start_idx].x * w), int(landmarks[start_idx].y * h))
                    end_point = (int(landmarks[end_idx].x * w), int(landmarks[end_idx].y * h))
                    cv2.line(image, start_point, end_point, connection_color, thickness)
        
        # ç»˜åˆ¶å…³é”®ç‚¹
        for landmark in landmarks:
            point = (int(landmark.x * w), int(landmark.y * h))
            cv2.circle(image, point, thickness + 1, landmark_color, -1)
        
        return image

# è¿è¡Œæµ‹è¯•å’Œå®‰è£…æŒ‡å—çš„å‘½ä»¤è¡Œå‡½æ•°
def run_tests():
    """è¿è¡Œæµ‹è¯•å¥—ä»¶"""
    print("ğŸ§ª è¿è¡ŒAIToolkit Baseæµ‹è¯•å¥—ä»¶...")
    # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æµ‹è¯•é€»è¾‘
    
def run_install_guide():
    """è¿è¡Œå®‰è£…æŒ‡å—"""
    print("ğŸ“¦ AIToolkit Base å®‰è£…æŒ‡å—")
    print("ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…:")
    print("pip install aitoolkit-base")
    print("æˆ–å®‰è£…æ‰€æœ‰åŠŸèƒ½:")
    print("pip install aitoolkit-base[all]") 