"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
åŸºäºMediaPipe Model Makerå®ç°åˆ†ç±»å’Œæ£€æµ‹æ¨¡å‹è®­ç»ƒ
ä¸€é”®å¼è®­ç»ƒï¼Œç”¨æˆ·10è¡Œä»£ç å®Œæˆæ¨¡å‹è®­ç»ƒ
"""

import os
import cv2
import numpy as np
from typing import List, Dict, Optional, Tuple, Any
import pandas as pd
from pathlib import Path

try:
    import mediapipe_model_maker as mm
    from mediapipe_model_maker import image_classifier
    from mediapipe_model_maker import object_detector
    MODEL_MAKER_AVAILABLE = True
except ImportError:
    MODEL_MAKER_AVAILABLE = False
    # ç§»é™¤è¿™é‡Œçš„è­¦å‘Šï¼Œåªåœ¨ç”¨æˆ·å°è¯•ä½¿ç”¨è®­ç»ƒåŠŸèƒ½æ—¶æ‰æ˜¾ç¤º
    # print("MediaPipe Model Makeræœªå®‰è£…ï¼Œè®­ç»ƒåŠŸèƒ½ä¸å¯ç”¨")


# ä¸€é”®å¼è®­ç»ƒå‡½æ•°
def train_image_classifier(data_dir: str, 
                          output_dir: str = "./trained_models",
                          epochs: int = 10,
                          model_name: str = "my_classifier") -> bool:
    """ä¸€é”®è®­ç»ƒå›¾åƒåˆ†ç±»å™¨
    
    ç”¨æˆ·åªéœ€è°ƒç”¨è¿™ä¸€ä¸ªå‡½æ•°å³å¯å®Œæˆè®­ç»ƒ
    
    Args:
        data_dir: è®­ç»ƒæ•°æ®ç›®å½•(åŒ…å«æŒ‰ç±»åˆ«åˆ†ç±»çš„å­æ–‡ä»¶å¤¹)
        output_dir: æ¨¡å‹è¾“å‡ºç›®å½•
        epochs: è®­ç»ƒè½®æ•°
        model_name: æ¨¡å‹åç§°
        
    Returns:
        è®­ç»ƒæ˜¯å¦æˆåŠŸ
        
    ç¤ºä¾‹ä½¿ç”¨:
        # åªéœ€2è¡Œä»£ç è®­ç»ƒåˆ†ç±»å™¨!
        from aitoolkit_base import train_image_classifier
        train_image_classifier("./my_data", epochs=5)
    """
    if not MODEL_MAKER_AVAILABLE:
        print("âŒ éœ€è¦å®‰è£… mediapipe-model-maker æ‰èƒ½ä½¿ç”¨è®­ç»ƒåŠŸèƒ½")
        return False
    
    try:
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒå›¾åƒåˆ†ç±»å™¨...")
        
        # 1. åŠ è½½æ•°æ®
        print("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
        data = image_classifier.Dataset.from_folder(data_dir)
        train_data, validation_data = data.split(0.2)
        print(f"âœ… è®­ç»ƒé›†: {len(train_data)} å¼ , éªŒè¯é›†: {len(validation_data)} å¼ ")
        
        # 2. åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        print("ğŸ¤– å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        model = image_classifier.create(
            train_data,
            model_spec=image_classifier.SupportedModels.MOBILENET_V2,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=32,
            learning_rate=0.001
        )
        
        # 3. è¯„ä¼°æ¨¡å‹
        print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        loss, accuracy = model.evaluate(validation_data)
        print(f"âœ… è®­ç»ƒå®Œæˆ! å‡†ç¡®ç‡: {accuracy:.3f}, æŸå¤±: {loss:.3f}")
        
        # 4. å¯¼å‡ºæ¨¡å‹
        print("ğŸ’¾ å¯¼å‡ºæ¨¡å‹...")
        os.makedirs(output_dir, exist_ok=True)
        model_path = os.path.join(output_dir, f"{model_name}.tflite")
        model.export_model(model_path)
        
        # 5. ä¿å­˜æ ‡ç­¾
        labels_path = os.path.join(output_dir, f"{model_name}_labels.txt")
        with open(labels_path, 'w', encoding='utf-8') as f:
            for label in data.label_names:
                f.write(f"{label}\n")
        
        print(f"ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"ğŸ“ æ ‡ç­¾æ–‡ä»¶: {labels_path}")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return False


def train_object_detector(data_dir: str,
                         annotations_dir: str,
                         output_dir: str = "./trained_models", 
                         epochs: int = 20,
                         model_name: str = "my_detector") -> bool:
    """ä¸€é”®è®­ç»ƒç›®æ ‡æ£€æµ‹å™¨
    
    Args:
        data_dir: å›¾åƒç›®å½•
        annotations_dir: æ ‡æ³¨æ–‡ä»¶ç›®å½•(PASCAL VOCæ ¼å¼)
        output_dir: æ¨¡å‹è¾“å‡ºç›®å½•  
        epochs: è®­ç»ƒè½®æ•°
        model_name: æ¨¡å‹åç§°
        
    Returns:
        è®­ç»ƒæ˜¯å¦æˆåŠŸ
        
    ç¤ºä¾‹ä½¿ç”¨:
        # åªéœ€2è¡Œä»£ç è®­ç»ƒæ£€æµ‹å™¨!
        from aitoolkit_base import train_object_detector
        train_object_detector("./images", "./annotations", epochs=10)
    """
    if not MODEL_MAKER_AVAILABLE:
        print("âŒ éœ€è¦å®‰è£… mediapipe-model-maker")
        return False
    
    try:
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒç›®æ ‡æ£€æµ‹å™¨...")
        
        # 1. åŠ è½½æ•°æ®
        print("ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®...")
        data = object_detector.Dataset.from_pascal_voc_folder(
            data_dir, annotations_dir
        )
        train_data, validation_data = data.split(0.2)
        print(f"âœ… è®­ç»ƒé›†: {len(train_data)} å¼ , éªŒè¯é›†: {len(validation_data)} å¼ ")
        
        # 2. åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        print("ğŸ¤– å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        model = object_detector.create(
            train_data,
            model_spec=object_detector.SupportedModels.MOBILENET_V2,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=8,
            learning_rate=0.3
        )
        
        # 3. è¯„ä¼°æ¨¡å‹
        print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        loss = model.evaluate(validation_data)
        print(f"âœ… è®­ç»ƒå®Œæˆ! æŸå¤±: {loss:.3f}")
        
        # 4. å¯¼å‡ºæ¨¡å‹
        print("ğŸ’¾ å¯¼å‡ºæ¨¡å‹...")
        os.makedirs(output_dir, exist_ok=True)
        model_path = os.path.join(output_dir, f"{model_name}.tflite")
        model.export_model(model_path)
        
        print(f"ğŸ‰ æ£€æµ‹å™¨è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_path}")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return False


# å¿«é€Ÿæ•°æ®å‡†å¤‡å·¥å…·
def prepare_classification_data(source_dir: str, target_dir: str, image_size: int = 224) -> bool:
    """å¿«é€Ÿå‡†å¤‡åˆ†ç±»è®­ç»ƒæ•°æ®
    
    Args:
        source_dir: åŸå§‹æ•°æ®ç›®å½•
        target_dir: å¤„ç†åæ•°æ®ç›®å½•
        image_size: å›¾åƒå¤§å°
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        print("ğŸ“‚ å‡†å¤‡åˆ†ç±»è®­ç»ƒæ•°æ®...")
        
        os.makedirs(target_dir, exist_ok=True)
        
        # éå†æºç›®å½•ä¸­çš„ç±»åˆ«æ–‡ä»¶å¤¹
        for class_name in os.listdir(source_dir):
            class_path = os.path.join(source_dir, class_name)
            if not os.path.isdir(class_path):
                continue
            
            # åˆ›å»ºç›®æ ‡ç±»åˆ«æ–‡ä»¶å¤¹
            target_class_path = os.path.join(target_dir, class_name)
            os.makedirs(target_class_path, exist_ok=True)
            
            # å¤„ç†å›¾åƒ
            image_count = 0
            for filename in os.listdir(class_path):
                if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                    source_img_path = os.path.join(class_path, filename)
                    target_img_path = os.path.join(target_class_path, filename)
                    
                    # è¯»å–å¹¶è°ƒæ•´å›¾åƒå¤§å°
                    img = cv2.imread(source_img_path)
                    if img is not None:
                        img_resized = cv2.resize(img, (image_size, image_size))
                        cv2.imwrite(target_img_path, img_resized)
                        image_count += 1
            
            print(f"âœ… ç±»åˆ« '{class_name}': {image_count} å¼ å›¾åƒ")
        
        print(f"ğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆ! è¾“å‡ºç›®å½•: {target_dir}")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        return False


class ImageClassifierTrainer:
    """å›¾åƒåˆ†ç±»å™¨è®­ç»ƒå™¨ (é«˜çº§ç”¨æ³•)"""
    
    def __init__(self, 
                 data_dir: str,
                 validation_split: float = 0.2,
                 model_spec: str = 'mobilenet_v2'):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        if not MODEL_MAKER_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… mediapipe-model-maker")
        
        self.data_dir = data_dir
        self.validation_split = validation_split
        self.model_spec = model_spec
        self.model = None
        self.train_data = None
        self.validation_data = None
        
    def prepare_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            data = image_classifier.Dataset.from_folder(self.data_dir)
            self.train_data, self.validation_data = data.split(self.validation_split)
            print(f"è®­ç»ƒæ•°æ®: {len(self.train_data)} å¼ ")
            print(f"éªŒè¯æ•°æ®: {len(self.validation_data)} å¼ ")
            return True
        except Exception as e:
            print(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return False
    
    def create_model_spec(self):
        """åˆ›å»ºæ¨¡å‹è§„æ ¼"""
        try:
            if self.model_spec == 'mobilenet_v2':
                return image_classifier.SupportedModels.MOBILENET_V2
            elif self.model_spec == 'efficientnet_lite0':
                return image_classifier.SupportedModels.EFFICIENTNET_LITE0
            elif self.model_spec == 'efficientnet_lite2':
                return image_classifier.SupportedModels.EFFICIENTNET_LITE2
            else:
                return image_classifier.SupportedModels.MOBILENET_V2
        except Exception as e:
            print(f"åˆ›å»ºæ¨¡å‹è§„æ ¼å¤±è´¥: {e}")
            return image_classifier.SupportedModels.MOBILENET_V2
    
    def train(self, 
              epochs: int = 10,
              batch_size: int = 32,
              learning_rate: float = 0.001,
              shuffle: bool = True) -> bool:
        """è®­ç»ƒæ¨¡å‹"""
        if self.train_data is None:
            if not self.prepare_data():
                return False
        
        try:
            spec = self.create_model_spec()
            
            self.model = image_classifier.create(
                self.train_data,
                model_spec=spec,
                validation_data=self.validation_data,
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                shuffle=shuffle
            )
            
            print("æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def evaluate(self) -> Optional[Dict[str, float]]:
        """è¯„ä¼°æ¨¡å‹"""
        if self.model is None or self.validation_data is None:
            print("æ¨¡å‹æˆ–éªŒè¯æ•°æ®æœªå‡†å¤‡å¥½")
            return None
        
        try:
            loss, accuracy = self.model.evaluate(self.validation_data)
            results = {
                'loss': loss,
                'accuracy': accuracy
            }
            
            print(f"æ¨¡å‹è¯„ä¼°ç»“æœ:")
            print(f"æŸå¤±: {loss:.4f}")
            print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
            
            return results
            
        except Exception as e:
            print(f"æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def export_model(self, export_dir: str, model_name: str = "classifier") -> bool:
        """å¯¼å‡ºæ¨¡å‹"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return False
        
        try:
            os.makedirs(export_dir, exist_ok=True)
            export_path = os.path.join(export_dir, f"{model_name}.tflite")
            
            self.model.export_model(export_path)
            print(f"æ¨¡å‹å·²å¯¼å‡ºåˆ°: {export_path}")
            
            # å¯¼å‡ºæ ‡ç­¾æ–‡ä»¶
            labels_path = os.path.join(export_dir, f"{model_name}_labels.txt")
            with open(labels_path, 'w', encoding='utf-8') as f:
                for label in self.model.model_spec.config.label_names:
                    f.write(f"{label}\n")
            print(f"æ ‡ç­¾æ–‡ä»¶å·²å¯¼å‡ºåˆ°: {labels_path}")
            
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹å¯¼å‡ºå¤±è´¥: {e}")
            return False


class ObjectDetectorTrainer:
    """ç›®æ ‡æ£€æµ‹å™¨è®­ç»ƒå™¨ (é«˜çº§ç”¨æ³•)"""
    
    def __init__(self, 
                 data_dir: str,
                 annotations_dir: str,
                 validation_split: float = 0.2,
                 model_spec: str = 'mobilenet_v2'):
        """åˆå§‹åŒ–è®­ç»ƒå™¨"""
        if not MODEL_MAKER_AVAILABLE:
            raise ImportError("éœ€è¦å®‰è£… mediapipe-model-maker")
        
        self.data_dir = data_dir
        self.annotations_dir = annotations_dir
        self.validation_split = validation_split
        self.model_spec = model_spec
        self.model = None
        self.train_data = None
        self.validation_data = None
    
    def prepare_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            # åŠ è½½PASCAL VOCæ ¼å¼çš„æ•°æ®
            data = object_detector.Dataset.from_pascal_voc_folder(
                self.data_dir, 
                self.annotations_dir
            )
            
            # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
            self.train_data, self.validation_data = data.split(self.validation_split)
            
            print(f"è®­ç»ƒæ•°æ®: {len(self.train_data)} å¼ ")
            print(f"éªŒè¯æ•°æ®: {len(self.validation_data)} å¼ ")
            
            return True
            
        except Exception as e:
            print(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return False
    
    def create_model_spec(self):
        """åˆ›å»ºæ¨¡å‹è§„æ ¼"""
        try:
            if self.model_spec == 'mobilenet_v2':
                return object_detector.SupportedModels.MOBILENET_V2
            else:
                return object_detector.SupportedModels.MOBILENET_V2
        except Exception as e:
            print(f"åˆ›å»ºæ¨¡å‹è§„æ ¼å¤±è´¥: {e}")
            return object_detector.SupportedModels.MOBILENET_V2
    
    def train(self, 
              epochs: int = 50,
              batch_size: int = 8,
              learning_rate: float = 0.3) -> bool:
        """è®­ç»ƒæ¨¡å‹"""
        if self.train_data is None:
            if not self.prepare_data():
                return False
        
        try:
            # åˆ›å»ºæ¨¡å‹è§„æ ¼
            spec = self.create_model_spec()
            
            # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
            self.model = object_detector.create(
                self.train_data,
                model_spec=spec,
                validation_data=self.validation_data,
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate
            )
            
            print("ç›®æ ‡æ£€æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def evaluate(self) -> Optional[Dict[str, float]]:
        """è¯„ä¼°æ¨¡å‹"""
        if self.model is None or self.validation_data is None:
            print("æ¨¡å‹æˆ–éªŒè¯æ•°æ®æœªå‡†å¤‡å¥½")
            return None
        
        try:
            loss = self.model.evaluate(self.validation_data)
            results = {'loss': loss}
            
            print(f"æ¨¡å‹è¯„ä¼°ç»“æœ:")
            print(f"æŸå¤±: {loss:.4f}")
            
            return results
            
        except Exception as e:
            print(f"æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def export_model(self, export_dir: str, model_name: str = "detector") -> bool:
        """å¯¼å‡ºæ¨¡å‹"""
        if self.model is None:
            print("æ¨¡å‹æœªè®­ç»ƒ")
            return False
        
        try:
            os.makedirs(export_dir, exist_ok=True)
            export_path = os.path.join(export_dir, f"{model_name}.tflite")
            
            self.model.export_model(export_path)
            print(f"ç›®æ ‡æ£€æµ‹æ¨¡å‹å·²å¯¼å‡ºåˆ°: {export_path}")
            
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹å¯¼å‡ºå¤±è´¥: {e}")
            return False


class DatasetPreprocessor:
    """æ•°æ®é›†é¢„å¤„ç†å™¨
    
    ç”¨äºå‡†å¤‡å’Œé¢„å¤„ç†è®­ç»ƒæ•°æ®
    """
    
    @staticmethod
    def create_classification_dataset(source_dir: str, 
                                    target_dir: str,
                                    image_size: Tuple[int, int] = (224, 224),
                                    valid_extensions: List[str] = ['.jpg', '.jpeg', '.png']) -> bool:
        """åˆ›å»ºåˆ†ç±»æ•°æ®é›†
        
        Args:
            source_dir: æºæ•°æ®ç›®å½•
            target_dir: ç›®æ ‡æ•°æ®ç›®å½•
            image_size: å›¾åƒå°ºå¯¸
            valid_extensions: æœ‰æ•ˆçš„å›¾åƒæ‰©å±•å
            
        Returns:
            å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            os.makedirs(target_dir, exist_ok=True)
            
            for class_name in os.listdir(source_dir):
                class_path = os.path.join(source_dir, class_name)
                if not os.path.isdir(class_path):
                    continue
                
                target_class_path = os.path.join(target_dir, class_name)
                os.makedirs(target_class_path, exist_ok=True)
                
                for filename in os.listdir(class_path):
                    if any(filename.lower().endswith(ext) for ext in valid_extensions):
                        source_file = os.path.join(class_path, filename)
                        target_file = os.path.join(target_class_path, filename)
                        
                        # è¯»å–å¹¶è°ƒæ•´å›¾åƒå¤§å°
                        image = cv2.imread(source_file)
                        if image is not None:
                            resized_image = cv2.resize(image, image_size)
                            cv2.imwrite(target_file, resized_image)
            
            print(f"åˆ†ç±»æ•°æ®é›†å·²åˆ›å»ºåˆ°: {target_dir}")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºåˆ†ç±»æ•°æ®é›†å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def validate_dataset_structure(data_dir: str, min_images_per_class: int = 10) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®é›†ç»“æ„
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            min_images_per_class: æ¯ä¸ªç±»åˆ«çš„æœ€å°‘å›¾åƒæ•°
            
        Returns:
            éªŒè¯ç»“æœ
        """
        results = {
            'valid': True,
            'classes': [],
            'image_counts': {},
            'warnings': [],
            'errors': []
        }
        
        try:
            if not os.path.exists(data_dir):
                results['valid'] = False
                results['errors'].append(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
                return results
            
            for class_name in os.listdir(data_dir):
                class_path = os.path.join(data_dir, class_name)
                if not os.path.isdir(class_path):
                    continue
                
                results['classes'].append(class_name)
                
                # ç»Ÿè®¡å›¾åƒæ•°é‡
                image_count = 0
                for filename in os.listdir(class_path):
                    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                        image_count += 1
                
                results['image_counts'][class_name] = image_count
                
                if image_count < min_images_per_class:
                    results['warnings'].append(
                        f"ç±»åˆ« '{class_name}' åªæœ‰ {image_count} å¼ å›¾åƒï¼Œå°‘äºæ¨èçš„ {min_images_per_class} å¼ "
                    )
            
            if len(results['classes']) < 2:
                results['valid'] = False
                results['errors'].append("è‡³å°‘éœ€è¦2ä¸ªç±»åˆ«è¿›è¡Œåˆ†ç±»è®­ç»ƒ")
            
            print(f"æ‰¾åˆ° {len(results['classes'])} ä¸ªç±»åˆ«")
            for class_name, count in results['image_counts'].items():
                print(f"  {class_name}: {count} å¼ å›¾åƒ")
            
        except Exception as e:
            results['valid'] = False
            results['errors'].append(f"éªŒè¯æ•°æ®é›†ç»“æ„å¤±è´¥: {e}")
        
        return results


class TrainingPipeline:
    """è®­ç»ƒæµæ°´çº¿
    
    æ•´åˆæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹
    """
    
    def __init__(self, project_name: str, base_dir: str = "./training_projects"):
        """åˆå§‹åŒ–è®­ç»ƒæµæ°´çº¿
        
        Args:
            project_name: é¡¹ç›®åç§°
            base_dir: åŸºç¡€ç›®å½•
        """
        self.project_name = project_name
        self.project_dir = os.path.join(base_dir, project_name)
        self.data_dir = os.path.join(self.project_dir, "data")
        self.models_dir = os.path.join(self.project_dir, "models")
        self.logs_dir = os.path.join(self.project_dir, "logs")
        
        # åˆ›å»ºé¡¹ç›®ç›®å½•
        for dir_path in [self.project_dir, self.data_dir, self.models_dir, self.logs_dir]:
            os.makedirs(dir_path, exist_ok=True)
    
    def run_classification_training(self, 
                                  source_data_dir: str,
                                  model_spec: str = 'mobilenet_v2',
                                  epochs: int = 10,
                                  validation_split: float = 0.2) -> Dict[str, Any]:
        """è¿è¡Œåˆ†ç±»æ¨¡å‹è®­ç»ƒæµç¨‹
        
        Args:
            source_data_dir: æºæ•°æ®ç›®å½•
            model_spec: æ¨¡å‹è§„æ ¼
            epochs: è®­ç»ƒè½®æ•°
            validation_split: éªŒè¯é›†æ¯”ä¾‹
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        results = {'success': False, 'model_path': None, 'metrics': None}
        
        try:
            # 1. éªŒè¯æ•°æ®é›†
            print("1. éªŒè¯æ•°æ®é›†ç»“æ„...")
            validation_results = DatasetPreprocessor.validate_dataset_structure(source_data_dir)
            if not validation_results['valid']:
                results['errors'] = validation_results['errors']
                return results
            
            # 2. é¢„å¤„ç†æ•°æ®
            print("2. é¢„å¤„ç†æ•°æ®...")
            processed_data_dir = os.path.join(self.data_dir, "processed")
            DatasetPreprocessor.create_classification_dataset(source_data_dir, processed_data_dir)
            
            # 3. è®­ç»ƒæ¨¡å‹
            print("3. è®­ç»ƒæ¨¡å‹...")
            trainer = ImageClassifierTrainer(
                processed_data_dir, 
                validation_split=validation_split,
                model_spec=model_spec
            )
            
            if trainer.train(epochs=epochs):
                # 4. è¯„ä¼°æ¨¡å‹
                print("4. è¯„ä¼°æ¨¡å‹...")
                metrics = trainer.evaluate()
                
                # 5. å¯¼å‡ºæ¨¡å‹
                print("5. å¯¼å‡ºæ¨¡å‹...")
                model_name = f"{self.project_name}_{model_spec}"
                if trainer.export_model(self.models_dir, model_name):
                    results['success'] = True
                    results['model_path'] = os.path.join(self.models_dir, f"{model_name}.tflite")
                    results['metrics'] = metrics
            
        except Exception as e:
            results['error'] = str(e)
            print(f"è®­ç»ƒæµç¨‹å¤±è´¥: {e}")
        
        return results 