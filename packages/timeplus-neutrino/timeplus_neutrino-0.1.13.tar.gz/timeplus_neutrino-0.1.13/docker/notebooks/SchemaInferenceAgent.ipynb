{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9785cb1-f65d-42b6-95e5-d09fe0eff8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in /opt/conda/lib/python3.11/site-packages (0.8.1)\n",
      "Requirement already satisfied: pyautogen==0.8.1 in /opt/conda/lib/python3.11/site-packages (from autogen) (0.8.1)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (7.1.0)\n",
      "Requirement already satisfied: fast-depends<3,>=2.4.12 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (2.4.12)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.8.1->autogen) (0.9.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from asyncer==0.0.8->pyautogen==0.8.1->autogen) (4.0.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.28.1->pyautogen==0.8.1->autogen) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.28.1->pyautogen==0.8.1->autogen) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.28.1->pyautogen==0.8.1->autogen) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen==0.8.1->autogen) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.1->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.1->autogen) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.8.1->autogen) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.8.1->autogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.8.1->autogen) (2.0.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->pyautogen==0.8.1->autogen) (2024.11.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.8.1->autogen) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker->pyautogen==0.8.1->autogen) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e6cbef-8ab5-4a4b-90e7-120adbf9f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "\n",
    "class DataOnboardingAgent:\n",
    "    data_onboarding_system_message = \"you are a helpful data processing agent\"\n",
    "\n",
    "    schema_inference_system_message = \"\"\"please generate DDL based on input data\n",
    "    here are the rules to follow\n",
    "    * the DDL grammar follows ClickHouse style\n",
    "    * the Table keyword MUST be replaced with Stream\n",
    "    * all datatypes MUST be in lowercase, such uint32\n",
    "    * all keywords MUST be in lowercase, such as nullable\n",
    "    * all field names MUST keep same as in the json\n",
    "    * composite types such as array, tuple, map cannot be nullable\n",
    "    * should use composite types like array, map or tuple to represent complex structure in the json\n",
    "    * if the data value is null, field type MUST be set as 'unknown'\n",
    "    * return the result as a markdown sql code\n",
    "\n",
    "\n",
    "    here is a sample of output DDL:\n",
    "    ```sql\n",
    "    CREATE STREAM car_live_data\n",
    "    (\n",
    "      `cid` string,\n",
    "      `gas_percent` float64,\n",
    "      `in_use` bool,\n",
    "      `latitude` float64,\n",
    "      `longitude` float64,\n",
    "      `locked` bool,\n",
    "      `speed_kmh` float64,\n",
    "      `time` string,\n",
    "      `total_km` float64\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    schema_to_table_system_message = \"\"\"based on generated DDL, please convert it into a json objec\n",
    "    Rules:\n",
    "    * for type string, it MUST be a single line for string\n",
    "    \n",
    "    for example, if the input DDL is:\n",
    "    CREATE STREAM car_live_data\n",
    "    (\n",
    "      `cid` string,\n",
    "      `gas_percent` float64,\n",
    "      `in_use` bool,\n",
    "      `composite` tuple(\n",
    "          'x' int\n",
    "          ),\n",
    "    )\n",
    "    \n",
    "    the output of the json description of the DDL should be:\n",
    "    ```json\n",
    "    \n",
    "    [\n",
    "        {\n",
    "            \"name\" : \"cid\", \"type\" : \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\" : \"gas_percent\", \"type\" : \"float64\"\n",
    "        },\n",
    "        {\n",
    "            \"name\" : \"in_use\", \"type\" : \"bool\"\n",
    "        },\n",
    "        {\n",
    "            \"name\" : \"composite\", \"type\" : \"tuple('x' int)\"\n",
    "        }\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    field_summary_system_message = \"\"\" please generate a report to explain each fields of the schema,\n",
    "    turn the hierachy into flatten when generating this report for each field,\n",
    "    use '.' to connect the parents and children names\n",
    "    output the result into a json object\n",
    "    here is a sample of the output:\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"eventversion\",\n",
    "            \"type\": \"uint32\",\n",
    "            \"description\": \"The version of the current event.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"open_24h\",\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The price of the asset at the beginning of the last 24-hour period.\"\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    analysis_recommendations_system_message = \"\"\" please propose what kind an analysis we can do based on input data and schema\n",
    "    output into a json object which is an array\n",
    "    \"\"\"\n",
    "\n",
    "    analysis_sql_generation_system_message = \"\"\" please generate 10 analysis SQL based on input schema and analysis recommendations\n",
    "    output into a json object which is an array\n",
    "    note, you need escape newlines if the output contains multiple lines string\n",
    "\n",
    "    The generate SQL should follow these rules\n",
    "    * the SQL follows the ClickHouse grammar\n",
    "    * all method name MUST be in lower cases, following snake cases, for example : array_sum\n",
    "    * no CROSS JOIN is supported\n",
    "\n",
    "    As timeplus is a streaming processing platform, there are three different types of query regarding how to scan the data\n",
    "    please randomly select one of these three patterns to generate SQL\n",
    "\n",
    "    1 temperal window based analysis tumble window with 5 second window size\n",
    "    following query return analysis result in a continously streaming query for every 5 second window\n",
    "    select window_start, window_end, count(*) as count, max(c1) as max_c1\n",
    "    from tumble(my_stream, 5s) group by window_start, window_end\n",
    "\n",
    "    2 global aggregration which Global aggregation will start the aggregation for all incoming events since the query is submitted, and never ends.\n",
    "    select count(*) as count, id as id\n",
    "    from my_stream group by id\n",
    "\n",
    "    3 historical aggreation, using table function, the query will just run traditional SQL that scan all historical data and return after query end\n",
    "    select count(*) as count, id as id\n",
    "    from table(my_stream) group by id\n",
    "\n",
    "\n",
    "    #########\n",
    "    here is a sample output:\n",
    "    [\n",
    "      {\n",
    "        \"sql\": \"select eventVersion, sum(videoSourceBandwidthBytesPerEvent + videoFecBandwidthBytesPerEvent + audioSourceBandwidthBytesPerEvent + audioFecBandwidthBytesPerEvent) as total_bandwidth_bytes from xray_stream group by eventVersion\",\n",
    "        \"description\": \"Calculate the total bandwidth used per event version by summing up video, audio, and FEC bandwidths.\",\n",
    "        \"name\" : \"Bandwidth Utilization Analysis\"\n",
    "      }\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._llm_config = {\n",
    "            \"config_list\": [\n",
    "                {\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}\n",
    "            ],\n",
    "            \"temperature\": 0,\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "        self._llm_config = {\n",
    "            \"config_list\": [\n",
    "                {\n",
    "                    \"model\": \"gemma2:9b\",\n",
    "                    \"base_url\": \"http://localhost:11434/v1\",\n",
    "                    \"api_key\": \"ollama\",\n",
    "                }\n",
    "            ]}\n",
    "        \"\"\"\n",
    "\n",
    "        self.data_onboarding_agent = ConversableAgent(\n",
    "            \"data_onboarding_agent\",\n",
    "            system_message=self.data_onboarding_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.schema_inference_agent = ConversableAgent(\n",
    "            \"schema_inference_agent\",\n",
    "            system_message=self.schema_inference_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.schema_to_table_agent = ConversableAgent(\n",
    "            \"schema_to_table_agent\",\n",
    "            system_message=self.schema_to_table_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.field_summary_agent = ConversableAgent(\n",
    "            \"field_summary_agent\",\n",
    "            system_message=self.field_summary_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.analysis_recommendations_agent = ConversableAgent(\n",
    "            \"analysis_recommendations_agent\",\n",
    "            system_message=self.analysis_recommendations_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.analysis_sql_generation_agent = ConversableAgent(\n",
    "            \"analysis_sql_generation_agent\",\n",
    "            system_message=self.analysis_sql_generation_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "    def process(self):\n",
    "        message = (\n",
    "            f\"based on input data : {self.data}, and stream name : {self.stream_name}\"\n",
    "        )\n",
    "        self.data_onboarding_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": self.schema_inference_agent,\n",
    "                    \"message\": message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.field_summary_agent,\n",
    "                    \"message\": \"based on input DDL, add field summary\",\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.analysis_recommendations_agent,\n",
    "                    \"message\": f\"based on input data : {self.data}, and field summary\",\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.analysis_sql_generation_agent,\n",
    "                    \"message\": \"based on input schema and recommandations, generate analysis SQL, those metric seems like some video network package quality related data.\",\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def inference(self, data, stream_name):\n",
    "        message = f\"based on input data : {data}, and stream name : {stream_name}\"\n",
    "        self.data_onboarding_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": self.schema_inference_agent,\n",
    "                    \"message\": message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.schema_to_table_agent,\n",
    "                    \"message\": \"please generate json expression for the schema\",\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.schema_inference_agent.last_message()[\"content\"], self.schema_to_table_agent.last_message()[\"content\"]\n",
    "\n",
    "    def summary(self, data, columns):\n",
    "        message = f\"based on input data : {data}, and columns : {columns}\"\n",
    "        self.data_onboarding_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": self.field_summary_agent,\n",
    "                    \"message\": message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.field_summary_agent.last_message()[\"content\"]\n",
    "\n",
    "    def recommendations(self, data, columns, stream_name):\n",
    "        message = f\"based on input data : {data}, and columns : {columns} and stream name : {stream_name}\"\n",
    "        self.data_onboarding_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": self.analysis_sql_generation_agent,\n",
    "                    \"message\": message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return self.analysis_sql_generation_agent.last_message()[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c37c1bd-3faa-4f5f-96c9-6906983bbbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_onboarding_agent\u001b[0m (to schema_inference_agent):\n",
      "\n",
      "based on input data : \n",
      "{\n",
      "    \"customer_id\": 56,\n",
      "    \"name\": \"Emily Taylor\",\n",
      "    \"email\": \"brianpeters@example.org\",\n",
      "    \"phone\": \"522.227.0958x8414\",\n",
      "    \"address\": \"231 Brown Orchard\n",
      "North Kristafurt, NC 05498\",\n",
      "    \"home\": null\n",
      "}\n",
      ", and stream name : customer\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mschema_inference_agent\u001b[0m (to data_onboarding_agent):\n",
      "\n",
      "```sql\n",
      "CREATE STREAM customer\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string,\n",
      "  `home` unknown\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_onboarding_agent\u001b[0m (to schema_to_table_agent):\n",
      "\n",
      "please generate json expression for the schema\n",
      "Context: \n",
      "```sql\n",
      "CREATE STREAM customer\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string,\n",
      "  `home` unknown\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mschema_to_table_agent\u001b[0m (to data_onboarding_agent):\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"customer_id\",\n",
      "        \"type\": \"uint32\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"name\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"email\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"phone\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"address\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"home\",\n",
      "        \"type\": \"unknown\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "```sql\n",
      "CREATE STREAM customer\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string,\n",
      "  `home` unknown\n",
      ")\n",
      "```\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"customer_id\",\n",
      "        \"type\": \"uint32\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"name\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"email\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"phone\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"address\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"home\",\n",
      "        \"type\": \"unknown\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "data_customer = '''\n",
    "{\n",
    "    \"customer_id\": 56,\n",
    "    \"name\": \"Emily Taylor\",\n",
    "    \"email\": \"brianpeters@example.org\",\n",
    "    \"phone\": \"522.227.0958x8414\",\n",
    "    \"address\": \"231 Brown Orchard\\nNorth Kristafurt, NC 05498\",\n",
    "    \"home\": null\n",
    "}\n",
    "'''\n",
    "agent = DataOnboardingAgent()\n",
    "\n",
    "ddl, ddl_json = agent.inference(data_customer, 'customer')\n",
    "\n",
    "print(ddl)\n",
    "\n",
    "print(ddl_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900df0f7-83bf-4a00-b41b-a5601f50ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_onboarding_agent\u001b[0m (to schema_inference_agent):\n",
      "\n",
      "based on input data : \n",
      "{\n",
      "    \"history_id\": 49,\n",
      "    \"customer_id\": 49,\n",
      "    \"bank_name\": \"Montgomery Inc\",\n",
      "    \"credit_score\": 485,\n",
      "    \"outstanding_debt\": 26706.08,\n",
      "    \"last_updated\": 19674\n",
      "}\n",
      ", and stream name : credit_history\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mschema_inference_agent\u001b[0m (to data_onboarding_agent):\n",
      "\n",
      "```sql\n",
      "CREATE STREAM credit_history\n",
      "(\n",
      "  `history_id` uint32,\n",
      "  `customer_id` uint32,\n",
      "  `bank_name` string,\n",
      "  `credit_score` uint32,\n",
      "  `outstanding_debt` float64,\n",
      "  `last_updated` uint32\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```sql\\nCREATE STREAM credit_history\\n(\\n  `history_id` uint32,\\n  `customer_id` uint32,\\n  `bank_name` string,\\n  `credit_score` uint32,\\n  `outstanding_debt` float64,\\n  `last_updated` uint32\\n)\\n```'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_credit_history = '''\n",
    "{\n",
    "    \"history_id\": 49,\n",
    "    \"customer_id\": 49,\n",
    "    \"bank_name\": \"Montgomery Inc\",\n",
    "    \"credit_score\": 485,\n",
    "    \"outstanding_debt\": 26706.08,\n",
    "    \"last_updated\": 19674\n",
    "}\n",
    "'''\n",
    "agent = DataOnboardingAgent()\n",
    "\n",
    "agent.inference(data_credit_history, 'credit_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3424e020-0f84-44f9-8e13-9c8c0bf45234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_onboarding_agent\u001b[0m (to schema_inference_agent):\n",
      "\n",
      "based on input data : \n",
      "{\n",
      "\t\"_id\": {\n",
      "\t\t\"$oid\": \"67bc078e18939cdcb051732a\"\n",
      "\t},\n",
      "\t\"customer_id\": 49,\n",
      "\t\"raw_data\": {\n",
      "\t\t\"transaction_history\": [\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1738368000000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 391.05\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1738540800000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 923.33\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1738972800000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 541.95\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1736208000000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 116.17\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1736899200000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 399.86\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1739577600000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 625.11\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1738195200000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 668.96\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1736294400000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 472.46\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"date\": {\n",
      "\t\t\t\t\t\"$date\": 1737072000000\n",
      "\t\t\t\t},\n",
      "\t\t\t\t\"amount\": 17.49\n",
      "\t\t\t}\n",
      "\t\t],\n",
      "\t\t\"social_media_activity\": {\n",
      "\t\t\t\"platform\": \"Twitter\",\n",
      "\t\t\t\"activity_score\": 34\n",
      "\t\t},\n",
      "\t\t\"miscellaneous\": {\n",
      "\t\t\t\"notes\": \"Policy wish success begin candidate raise state.\",\n",
      "\t\t\t\"risk_flags\": \"Medium\"\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      ", and stream name : unstructure\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mschema_inference_agent\u001b[0m (to data_onboarding_agent):\n",
      "\n",
      "```sql\n",
      "CREATE STREAM unstructure\n",
      "(\n",
      "  `_id` string,\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(tuple(\n",
      "      `date` uint64,\n",
      "      `amount` float64\n",
      "    )),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_onboarding_agent\u001b[0m (to schema_to_table_agent):\n",
      "\n",
      "please generate json expression for the schema\n",
      "Context: \n",
      "```sql\n",
      "CREATE STREAM unstructure\n",
      "(\n",
      "  `_id` string,\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(tuple(\n",
      "      `date` uint64,\n",
      "      `amount` float64\n",
      "    )),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mschema_to_table_agent\u001b[0m (to data_onboarding_agent):\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"_id\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"customer_id\",\n",
      "        \"type\": \"uint32\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"raw_data\",\n",
      "        \"type\": \"tuple(`transaction_history` array(tuple(`date` uint64, `amount` float64)), `social_media_activity` tuple(`platform` string, `activity_score` uint32), `miscellaneous` tuple(`notes` string, `risk_flags` string))\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "```sql\n",
      "CREATE STREAM unstructure\n",
      "(\n",
      "  `_id` string,\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(tuple(\n",
      "      `date` uint64,\n",
      "      `amount` float64\n",
      "    )),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"_id\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"customer_id\",\n",
      "        \"type\": \"uint32\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"raw_data\",\n",
      "        \"type\": \"tuple(`transaction_history` array(tuple(`date` uint64, `amount` float64)), `social_media_activity` tuple(`platform` string, `activity_score` uint32), `miscellaneous` tuple(`notes` string, `risk_flags` string))\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "data_unstructure = '''\n",
    "{\n",
    "\t\"_id\": {\n",
    "\t\t\"$oid\": \"67bc078e18939cdcb051732a\"\n",
    "\t},\n",
    "\t\"customer_id\": 49,\n",
    "\t\"raw_data\": {\n",
    "\t\t\"transaction_history\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1738368000000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 391.05\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1738540800000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 923.33\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1738972800000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 541.95\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1736208000000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 116.17\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1736899200000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 399.86\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1739577600000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 625.11\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1738195200000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 668.96\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1736294400000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 472.46\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"date\": {\n",
    "\t\t\t\t\t\"$date\": 1737072000000\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"amount\": 17.49\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"social_media_activity\": {\n",
    "\t\t\t\"platform\": \"Twitter\",\n",
    "\t\t\t\"activity_score\": 34\n",
    "\t\t},\n",
    "\t\t\"miscellaneous\": {\n",
    "\t\t\t\"notes\": \"Policy wish success begin candidate raise state.\",\n",
    "\t\t\t\"risk_flags\": \"Medium\"\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "'''\n",
    "agent = DataOnboardingAgent()\n",
    "\n",
    "ddl, ddl_json = agent.inference(data_unstructure, 'unstructure')\n",
    "\n",
    "print(ddl)\n",
    "\n",
    "print(ddl_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
