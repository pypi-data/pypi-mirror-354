{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be249b5-e85c-4b0f-9b5d-dbc681e75bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /opt/conda/lib/python3.11/site-packages (0.3.25)\n",
      "Requirement already satisfied: llama-index in /opt/conda/lib/python3.11/site-packages (0.12.20)\n",
      "Collecting proton_driver\n",
      "  Downloading proton_driver-0.2.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.17 in /opt/conda/lib/python3.11/site-packages (from llama-index-llms-openai) (0.12.21)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /opt/conda/lib/python3.11/site-packages (from llama-index-llms-openai) (1.64.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.6.8)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from proton_driver) (2023.3.post1)\n",
      "Collecting tzlocal (from proton_driver)\n",
      "  Downloading tzlocal-5.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2023.9.2)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.24.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (10.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /opt/conda/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.13)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.1.1)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.2 in /opt/conda/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2023.3)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from llama-cloud-services>=0.6.2->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.16.0)\n",
      "Downloading proton_driver-0.2.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (979 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.4/979.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: tzlocal, proton_driver\n",
      "Successfully installed proton_driver-0.2.13 tzlocal-5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-llms-openai llama-index proton_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0f2a0e-b212-44a6-8a61-f5b07450a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from proton_driver import client\n",
    "\n",
    "timeplus_host = os.getenv(\"TIMEPLUS_HOST\") or \"localhost\"\n",
    "timeplus_user = os.getenv(\"TIMEPLUS_USER\") or \"proton\"\n",
    "timeplus_password = os.getenv(\"TIMEPLUS_PASSWORD\") or \"timeplus@t+\"\n",
    "\n",
    "class Tools:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = client.Client(host=timeplus_host, port=8463, user=timeplus_user,password=timeplus_password)\n",
    "\n",
    "    def list_table(self, *args):\n",
    "        result = []\n",
    "        rows = self.client.execute_iter(\"SHOW STREAMS\")\n",
    "        for row in rows:\n",
    "            result.append(row[0])\n",
    "        return result\n",
    "    \n",
    "    def describe_table(self, *args):\n",
    "        name = args[0]\n",
    "        result = []\n",
    "        rows = self.client.execute_iter(f\"DESCRIBE {name.strip()}\")\n",
    "        for row in rows:\n",
    "            col = {}\n",
    "            col[\"name\"] =  row[0]\n",
    "            col[\"type\"] =  row[1]\n",
    "            result.append(col)\n",
    "        return result\n",
    "\n",
    "    def run(self, tool_name, *args):\n",
    "        result = getattr(self, tool_name)(*args)\n",
    "        return result\n",
    "\n",
    "    def list(self):\n",
    "        return [\"list_table\", \"describe_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d79af9-d7d1-46ec-8da8-7c9eb3de6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "tool = Tools()\n",
    "\n",
    "def list_table() -> str:\n",
    "    return tool.list_table()\n",
    "\n",
    "def describe_table(name: str) -> str:\n",
    "    return tool.describe_table(name)\n",
    "\n",
    "list_table_tool = FunctionTool.from_defaults(fn=list_table)\n",
    "describe_table_tool = FunctionTool.from_defaults(fn=describe_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b13a33-a3e4-452c-a7d3-de43963e23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c7c774d-8764-407b-acc9-6c38eceb8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "react_system_header_str = \"\"\"\\\n",
    "\n",
    "You are a asistent help generating SQL based on input questions. \n",
    "Please stop when you have the SQL, no need to execute the SQL\n",
    "To generate SQL, here are rules:\n",
    "* the grammar follows ClickHouse style\n",
    "* all datatypes MUST be in lowercase, such uint32\n",
    "* all keywords MUST be in lowercase, such as nullable\n",
    "* for real time query, where continously return new result to the user, append a time range, for example\n",
    "  select count(*) from table_name where _tp_time > now() -1h\n",
    "* for non real time query, add table() function to the table name, for example select count(*) from table(table_name)\n",
    "  which will return the number of event received in the past 1 hour\n",
    "\n",
    "## Tools\n",
    "You have access to a wide variety of tools. You are responsible for using\n",
    "the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "This may require breaking the task into subtasks and using different tools\n",
    "to complete each subtask.\n",
    "\n",
    "You have access to the following tools:\n",
    "{tool_desc}\n",
    "\n",
    "## Output Format\n",
    "To answer the question, please use the following format.\n",
    "\n",
    "```\n",
    "Thought: I need to use a tool to help me answer the question.\n",
    "Action: tool name (one of {tool_names}) if using a tool.\n",
    "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
    "```\n",
    "\n",
    "Please ALWAYS start with a Thought.\n",
    "\n",
    "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "\n",
    "If this format is used, the user will respond in the following format:\n",
    "\n",
    "```\n",
    "Observation: tool response\n",
    "```\n",
    "\n",
    "You should keep repeating the above format until you have enough information\n",
    "to answer the question without using any more tools. At that point, you MUST respond\n",
    "in the one of the following two formats:\n",
    "\n",
    "```\n",
    "Thought: I can answer without using any more tools.\n",
    "Answer: [your answer here]\n",
    "```\n",
    "\n",
    "```\n",
    "Thought: I cannot answer the question with the provided tools.\n",
    "Answer: Sorry, I cannot answer your query.\n",
    "```\n",
    "\n",
    "## Additional Rules\n",
    "- The answer MUST contain a sequence of bullet points that explain how you arrived at the answer. This can include aspects of the previous conversation history.\n",
    "- You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\n",
    "\n",
    "## Current Conversation\n",
    "Below is the current conversation consisting of interleaving human and assistant messages.\n",
    "\n",
    "\"\"\"\n",
    "react_system_prompt = PromptTemplate(react_system_header_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ef9bc04-d502-466e-ae28-a18922f18012",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "agent = ReActAgent.from_tools([list_table_tool, describe_table_tool], llm=llm, verbose=True)\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48f4853c-cbc0-4fa4-8c17-dbdc02dc8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 798a84e9-95a9-4f6c-830d-b7414165ac32. Step input: how many customers are there in past three days\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: ```\n",
      "select count(*) from table(kafka_cdc_postgres_customers) where _tp_time > now() - 3d\n",
      "```\n",
      "- I used the same table 'kafka_cdc_postgres_customers' as it contains customer data.\n",
      "- I constructed a non-real-time SQL query to count the customers over the past three days by using the table() function.\n",
      "- I specified the time range to filter the results to the last three days.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"how many customers are there in past three days\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
