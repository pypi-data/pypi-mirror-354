Metadata-Version: 2.4
Name: timeplus-neutrino
Version: 0.1.14
Summary: Timeplus neutrino is a python library for Timeplus AI agent
Home-page: https://github.com/timeplus-io/neutrino
Author: Gang Tao
Author-email: gang@timeplus.io
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3.9
Description-Content-Type: text/markdown
Requires-Dist: urllib3>=1.15
Requires-Dist: six>=1.10
Requires-Dist: certifi
Requires-Dist: sseclient-py>=1.7.2
Requires-Dist: openai>=1.61.1
Requires-Dist: setuptools_scm>=6.0.0
Requires-Dist: proton_driver
Requires-Dist: confluent-kafka
Requires-Dist: autogen-core==0.6.1
Requires-Dist: autogen-ext==0.6.1
Requires-Dist: autogen-agentchat==0.6.1
Requires-Dist: cryptography
Requires-Dist: mcp>=1.3.0
Requires-Dist: mcp[cli]>=1.3.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: uvicorn>=0.34.0
Requires-Dist: timeplus-connect>=0.8.16
Requires-Dist: confluent-kafka
Requires-Dist: pip-system-certs>=4.0
Requires-Dist: anthropic>=0.49.0
Requires-Dist: fastapi
Requires-Dist: jinja2
Requires-Dist: websockets
Requires-Dist: fastapi-mcp==0.3.3

# neutrino
Neutrinos are nearly massless and can pass through matter effortlessly, representing smooth and efficient data onboarding.


# pipeline build

install neutrino 'pip install timeplus-neutrino'

1. run timeplus enterprise
2. export following environment
  
```sh
export TIMEPLUS_HOST=localhost
export TIMEPLUS_AISERVICE_USER=user
export TIMEPLUS_AISERVICE_PASSWORD=password
export TIMEPLUS_AISERVICE_DB=aiservice
```

3. run following python code

```python
import os
import json
from neutrino.conf import TimeplusAgentConfig
from neutrino.pipeline.cdc import build_debezium_pipeline_sync

from neutrino.utils.tools import extract_code_blocks_with_type

agent_config = TimeplusAgentConfig()
# config open ai compatible model
#agent_config.config("default", "https://generativelanguage.googleapis.com/v1beta/openai/", os.environ["GEMINI_API_KEY"], "gemini-2.5-pro-preview-06-05")
agent_config.config("default", "https://api.openai.com/v1", os.environ["OPENAI_API_KEY"], "gpt-4o")

# config kafka
kafka_topic = "mongodb.lumi_data.unstructured_data"
kafka_config = {
    "security.protocol": 'PLAINTEXT',
    "bootstrap.servers":'localhost:19092'
}

# config kafka with SASL
'''

kafka_topic = "demo.cdc.mysql.retailer.orders"
kafka_config = {
    "security.protocol": 'SASL_SSL',
    "bootstrap.servers":'kafka.demo.timeplus.com:9092',
    "sasl.mechanism": 'PLAIN',
    "sasl.username":  'demo',
    "sasl.password":  'demo123',
    "enable.ssl.certificate.verification": 'false'
}
'''

# external stream settings
settings = {
	"type" :'s3',
    "access_key_id" : 'minioadmin',
    "secret_access_key" : 'minioadmin',
    "region" : 'us-east-1',
    "bucket" : 'timeplus',
    "data_format" : 'JSONEachRow',
    "endpoint" : 'http://minio:9000',
    "write_to" : 'lumi/data.json',
    "use_environment_credentials" : False
}

result = build_debezium_pipeline_sync(kafka_topic, kafka_config, database="test", target_stream_settings=settings)

print(f"the pipeline building for topic {kafka_topic} result is: {result}")

extracted_codes =extract_code_blocks_with_type(result)
extracted_code_type, extracted_code_content = extracted_codes[0]
print(f"the extracted code type is: {extracted_code_type}")

extracted_code_content_obj = json.loads(extracted_code_content)
print(f"the extracted code content is: {json.dumps(extracted_code_content_obj, indent=2)}")  

print(f"the extracted source_stream is: {extracted_code_content_obj["source_stream"]}")
print(f"the extracted target_stream is: {extracted_code_content_obj["target_stream"]}")
print(f"the extracted extraction_mv is: {extracted_code_content_obj["extraction_mv"]}")
```
