{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728d6eca-cb56-480a-9a14-86e5170fc9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent-kafka in /opt/conda/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Collecting grpcio\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_aarch64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (4.24.3)\n",
      "Collecting grpcio-tools\n",
      "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_aarch64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_aarch64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from grpcio-tools) (68.2.2)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_aarch64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_aarch64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_aarch64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.6/319.6 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, grpcio, grpcio-tools\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.3\n",
      "    Uninstalling protobuf-4.24.3:\n",
      "      Successfully uninstalled protobuf-4.24.3\n",
      "Successfully installed grpcio-1.70.0 grpcio-tools-1.70.0 protobuf-5.29.3\n"
     ]
    }
   ],
   "source": [
    "! pip install confluent-kafka requests grpcio protobuf grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2e3a84-a233-4dc1-8917-dfaeafcca836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Waiting for messages...\n",
      "\n",
      "üîπ Received: query: \"protobuf\"\n",
      "page_number: 5\n",
      "results_per_page: 33\n",
      "\n",
      "üîπ Received: query: \"redpanda\"\n",
      "page_number: 1\n",
      "results_per_page: 43\n",
      "\n",
      "üîπ Received: query: \"redpanda\"\n",
      "page_number: 7\n",
      "results_per_page: 44\n",
      "\n",
      "üîπ Received: query: \"kafka\"\n",
      "page_number: 9\n",
      "results_per_page: 44\n",
      "\n",
      "üîπ Received: query: \"redpanda\"\n",
      "page_number: 2\n",
      "results_per_page: 50\n",
      "\n",
      "üîπ Received: query: \"streaming\"\n",
      "page_number: 10\n",
      "results_per_page: 21\n",
      "\n",
      "üîπ Received: query: \"protobuf\"\n",
      "page_number: 7\n",
      "results_per_page: 50\n",
      "\n",
      "üîπ Received: query: \"redpanda\"\n",
      "page_number: 9\n",
      "results_per_page: 39\n",
      "\n",
      "üîπ Received: query: \"kafka\"\n",
      "page_number: 7\n",
      "results_per_page: 18\n",
      "\n",
      "üîπ Received: query: \"protobuf\"\n",
      "page_number: 4\n",
      "results_per_page: 11\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müöÄ Waiting for messages...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Poll for messages\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1740105785.172|MAXPOLL|rdkafka#consumer-5| [thrd:main]: Application maximum poll interval (300000ms) exceeded by 405ms (adjust max.poll.interval.ms for long-running message processing): leaving group\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import importlib.util\n",
    "from google.protobuf.descriptor_pb2 import FileDescriptorSet\n",
    "from google.protobuf import descriptor_pb2\n",
    "from google.protobuf.message_factory import GetMessageClass\n",
    "from google.protobuf.descriptor_pool import DescriptorPool\n",
    "from google.protobuf.descriptor_pb2 import FileDescriptorProto\n",
    "from confluent_kafka import Consumer\n",
    "\n",
    "# Configuration\n",
    "KAFKA_BROKER = \"redpanda:9092\"\n",
    "SCHEMA_REGISTRY_URL = \"http://redpanda:8081\"\n",
    "TOPIC_NAME = \"search_requests\"\n",
    "GROUP_ID = \"search-consumer-2\"\n",
    "\n",
    "# Kafka Consumer Config\n",
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": KAFKA_BROKER,\n",
    "    \"group.id\": GROUP_ID,\n",
    "    \"auto.offset.reset\": \"earliest\",\n",
    "})\n",
    "\n",
    "consumer.subscribe([TOPIC_NAME])\n",
    "\n",
    "\n",
    "def fetch_schema_from_registry():\n",
    "    \"\"\"Fetches the latest Protobuf schema from the Redpanda Schema Registry.\"\"\"\n",
    "    schema_subject = f\"{TOPIC_NAME}-value\"\n",
    "    schema_url = f\"{SCHEMA_REGISTRY_URL}/subjects/{schema_subject}/versions/latest\"\n",
    "    \n",
    "    response = requests.get(schema_url)\n",
    "    if response.status_code == 200:\n",
    "        schema_data = response.json()\n",
    "        return schema_data[\"schema\"]\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch schema: {response.text}\")\n",
    "\n",
    "\n",
    "def compile_proto_from_schema(proto_schema):\n",
    "    \"\"\"Compiles the Protobuf schema dynamically and loads the message class.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        proto_file_path = os.path.join(temp_dir, \"dynamic.proto\")\n",
    "        \n",
    "        # Write the schema to a .proto file\n",
    "        with open(proto_file_path, \"w\") as f:\n",
    "            f.write(proto_schema)\n",
    "\n",
    "        # Compile the .proto file\n",
    "        os.system(f\"protoc --python_out={temp_dir} --proto_path={temp_dir} {proto_file_path}\")\n",
    "\n",
    "        # Import the compiled Python module dynamically\n",
    "        generated_file = os.path.join(temp_dir, \"dynamic_pb2.py\")\n",
    "        spec = importlib.util.spec_from_file_location(\"dynamic_pb2\", generated_file)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        # Return the dynamically loaded Protobuf class (assuming first message is the one we need)\n",
    "        message_class_name = list(module.DESCRIPTOR.message_types_by_name.keys())[0]\n",
    "        return getattr(module, message_class_name)\n",
    "\n",
    "\n",
    "# Fetch schema and compile\n",
    "proto_schema = fetch_schema_from_registry()\n",
    "DynamicMessageClass = compile_proto_from_schema(proto_schema)\n",
    "\n",
    "# Start consuming messages\n",
    "print(\"\\nüöÄ Waiting for messages...\\n\")\n",
    "while True:\n",
    "    msg = consumer.poll(1.0)  # Poll for messages\n",
    "\n",
    "    if msg is None:\n",
    "        continue\n",
    "    if msg.error():\n",
    "        print(f\"‚ùå Consumer error: {msg.error()}\")\n",
    "        continue\n",
    "\n",
    "    # Deserialize the Protobuf message using the dynamically loaded class\n",
    "    dynamic_message = DynamicMessageClass()\n",
    "    dynamic_message.ParseFromString(msg.value())\n",
    "\n",
    "    # Print the received message as a dictionary\n",
    "    print(f\"üîπ Received: {dynamic_message}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
