{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb3045d-231d-4f42-8590-b1d6d6a965cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent-kafka in /opt/conda/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: avro-python3 in /opt/conda/lib/python3.11/site-packages (1.10.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (5.29.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "! pip install confluent-kafka avro-python3 requests protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c0fb20-5a60-4228-891a-19fe074c3488",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 79 (2719455921.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"‚ö†Ô∏è Received message too short: {msg.value()}\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1740161126.379|MAXPOLL|rdkafka#consumer-2| [thrd:main]: Application maximum poll interval (300000ms) exceeded by 271ms (adjust max.poll.interval.ms for long-running message processing): leaving group\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import requests\n",
    "import tempfile\n",
    "import importlib.util\n",
    "from confluent_kafka import Consumer\n",
    "from google.protobuf.message import DecodeError\n",
    "from google.protobuf.internal.decoder import _DecodeVarint32\n",
    "\n",
    "# Configuration\n",
    "KAFKA_BROKER = \"redpanda:9092\"\n",
    "SCHEMA_REGISTRY_URL = \"http://redpanda:8081\"\n",
    "TOPIC_NAME = \"search_requests_with_schema\"\n",
    "GROUP_ID = \"search-consumer-4\"\n",
    "\n",
    "# Kafka Consumer Config\n",
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": KAFKA_BROKER,\n",
    "    \"group.id\": GROUP_ID,\n",
    "    \"auto.offset.reset\": \"earliest\",\n",
    "})\n",
    "\n",
    "consumer.subscribe([TOPIC_NAME])\n",
    "\n",
    "\n",
    "def fetch_schema_by_id(schema_id):\n",
    "    \"\"\"Fetches the Protobuf schema from the Schema Registry by schema ID.\"\"\"\n",
    "    schema_url = f\"{SCHEMA_REGISTRY_URL}/schemas/ids/{schema_id}\"\n",
    "    \n",
    "    response = requests.get(schema_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"schema\"]\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch schema ID {schema_id}: {response.text}\")\n",
    "\n",
    "\n",
    "def compile_proto_from_schema(proto_schema):\n",
    "    \"\"\"Compiles the Protobuf schema dynamically and loads the message class.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        proto_file_path = os.path.join(temp_dir, \"dynamic.proto\")\n",
    "        \n",
    "        # Write the schema to a .proto file\n",
    "        with open(proto_file_path, \"w\") as f:\n",
    "            f.write(proto_schema)\n",
    "\n",
    "        # Compile the .proto file\n",
    "        os.system(f\"protoc --python_out={temp_dir} --proto_path={temp_dir} {proto_file_path}\")\n",
    "\n",
    "        # Import the compiled Python module dynamically\n",
    "        generated_file = os.path.join(temp_dir, \"dynamic_pb2.py\")\n",
    "        spec = importlib.util.spec_from_file_location(\"dynamic_pb2\", generated_file)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        # Return the dynamically loaded Protobuf class (assuming first message is the one we need)\n",
    "        message_class_name = list(module.DESCRIPTOR.message_types_by_name.keys())[0]\n",
    "        return getattr(module, message_class_name)\n",
    "\n",
    "\n",
    "# Start consuming messages\n",
    "print(\"\\nüöÄ Waiting for messages...\\n\")\n",
    "schema_cache = {}\n",
    "\n",
    "while True:\n",
    "    msg = consumer.poll(1.0)  # Poll for messages\n",
    "\n",
    "    if msg is None:\n",
    "        continue\n",
    "    if msg.error():\n",
    "        print(f\"‚ùå Consumer error: {msg.error()}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Ensure message is long enough\n",
    "    if len(msg.value()) < 5:\n",
    "        print(f\"‚ö†Ô∏è Received message too short: {msg.value()}\")\n",
    "        continue\n",
    "\n",
    "    if len(msg.value()) < 5:\n",
    "    print(f\"‚ö†Ô∏è Received message too short: {msg.value()}\")\n",
    "    continue\n",
    "\n",
    "    # Extract Schema ID (skip first byte for magic byte)\n",
    "    schema_id = struct.unpack(\">I\", msg.value()[1:5])[0]  # Read bytes 1-4 (Schema ID)\n",
    "    \n",
    "    # Decode the message indexes (varint array)\n",
    "    message_index_start = 5\n",
    "    message_indexes = []\n",
    "    offset = message_index_start\n",
    "    \n",
    "    while offset < len(msg.value()):\n",
    "        index, index_size = _DecodeVarint32(msg.value(), offset)\n",
    "        message_indexes.append(index)\n",
    "        offset += index_size\n",
    "        if index_size == 0:  # Stop if decoding fails (prevents infinite loops)\n",
    "            break\n",
    "    \n",
    "    # Extract the Protobuf payload after the last message index\n",
    "    payload = msg.value()[offset:]\n",
    "    \n",
    "    print(f\"üìå Extracted Schema ID: {schema_id}, Message Indexes: {message_indexes}\")\n",
    "\n",
    "    # Fetch schema if not cached\n",
    "    if schema_id not in schema_cache:\n",
    "        try:\n",
    "            proto_schema = fetch_schema_by_id(schema_id)\n",
    "            schema_cache[schema_id] = compile_proto_from_schema(proto_schema)\n",
    "            print(f\"üîÑ Loaded schema ID {schema_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to load schema ID {schema_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Parse the Protobuf message\n",
    "    DynamicMessageClass = schema_cache[schema_id]\n",
    "    dynamic_message = DynamicMessageClass()\n",
    "\n",
    "    # Deserialize Protobuf message (assuming first message type is the one used)\n",
    "    if message_indexes:\n",
    "        try:\n",
    "            dynamic_message = DynamicMessageClass()\n",
    "            dynamic_message.ParseFromString(payload)\n",
    "            print(f\"üîπ Received: {dynamic_message}\")\n",
    "        except DecodeError:\n",
    "            print(\"‚ùå Failed to decode Protobuf message.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No valid message indexes found.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
