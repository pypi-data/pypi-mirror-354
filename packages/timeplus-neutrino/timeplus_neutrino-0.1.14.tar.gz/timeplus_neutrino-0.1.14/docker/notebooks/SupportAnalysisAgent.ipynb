{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d612c0-1f7a-4069-8411-3009e21a5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install autogen-core autogen-ext autogen-ext[ollama] autogen-ext[openai] proton_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b77bc6-a1be-424a-a1ea-692b32e3cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from proton_driver import client\n",
    "\n",
    "timeplus_host = os.getenv(\"TIMEPLUS_HOST\") or \"localhost\"\n",
    "timeplus_user = os.getenv(\"TIMEPLUS_USER\") or \"proton\"\n",
    "timeplus_password = os.getenv(\"TIMEPLUS_PASSWORD\") or \"timeplus@t+\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9844d39f-5d5e-4f5a-ba53-ef5bf5ed0270",
   "metadata": {},
   "source": [
    "timeplus_client = client.Client(host=timeplus_host, port=8463, user=timeplus_user,password=timeplus_password)\n",
    "rows = timeplus_client.execute_iter(f\"select * from v_clearstreet_support_merged_threads\")\n",
    "row = next(rows)\n",
    "\n",
    "print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61aa2911-86db-43a9-9969-4c2e0cb608b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "\n",
    "from autogen_core import (\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    TopicId,\n",
    "    message_handler,\n",
    "    type_subscription,\n",
    "    AgentId,\n",
    ")\n",
    "from autogen_core.models import ChatCompletionClient, SystemMessage, UserMessage\n",
    "\n",
    "from autogen_ext.models.cache import ChatCompletionCache, CHAT_CACHE_VALUE_TYPE\n",
    "from autogen_ext.cache_store.diskcache import DiskCacheStore\n",
    "from diskcache import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e94936e-88d8-49f7-8f29-c25a2975e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelInfo\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "support_analysis_agent_topic = \"SupportAnalysisAgent\"\n",
    "\n",
    "@type_subscription(topic_type=support_analysis_agent_topic)\n",
    "class SupportAnalysisAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"A support analysis agent.\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"  you are an agent help to anlysis the support communications,\n",
    "please analysis the communitcation, and return analysis result in a json object, which contains following information\n",
    "\n",
    "* category\n",
    "  based on the first message send from the customer, give the communication a category\n",
    "  question - when customer is asking for support with a question\n",
    "  issue - when customer is reporting an issue\n",
    "  development request - customer is looking for new features that timeplus does not support yet\n",
    "  information - when customer is just sharing some information\n",
    "  \n",
    "* brief\n",
    "  give a simple sentense to describe what is happening in this conversation\n",
    "  \n",
    "* result\n",
    "  was the problem resolved? return resolved or unresolved\n",
    "\n",
    "* summary\n",
    "  provide a summary of the who conversation\n",
    "\n",
    "* start_time\n",
    "  when the conversation started, it is at the beging of the first message\n",
    "\n",
    "* serverity\n",
    "  how series the issue is, could be high, medium, low\n",
    "\n",
    "sample output here\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"category\":\"\",\n",
    "  \"brief\" : \"\",\n",
    "  \"result\" : \"\",\n",
    "  \"summary\" : \"\",\n",
    "  ... ...\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "        self._result = None\n",
    "\n",
    "    @message_handler\n",
    "    async def inference(self, message: Message, ctx: MessageContext) -> None:\n",
    "        prompt = f\"{message.content}, please analysis\"\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[\n",
    "                self._system_message,\n",
    "                UserMessage(content=prompt, source=self.id.key),\n",
    "            ],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        self._result = response\n",
    "\n",
    "\n",
    "class SupportAgent:\n",
    "    def __init__(self):\n",
    "        cache_dir = os.path.join(os.getcwd(), \".neutrino_cache\")\n",
    "        os.makedirs(cache_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "        \"\"\"\n",
    "        model_info = ModelInfo(\n",
    "            family=\"llama3.2:1b\",\n",
    "            function_calling=False,\n",
    "            json_output=False,\n",
    "            vision=False,\n",
    "        )\n",
    "        \n",
    "        model_client =  OllamaChatCompletionClient(\n",
    "            model=\"llama3.2:1b\",\n",
    "            host=\"http://host.docker.internal:11434/\",\n",
    "            model_info=model_info\n",
    "            \n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        model_client =  OpenAIChatCompletionClient(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        \n",
    "        cache_store = DiskCacheStore[CHAT_CACHE_VALUE_TYPE](Cache(cache_dir))\n",
    "        self.client = ChatCompletionCache(model_client, cache_store)\n",
    "        self.runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "    async def _analysis(self, message):\n",
    "\n",
    "        await SupportAnalysisAgent.register(\n",
    "            self.runtime,\n",
    "            type=support_analysis_agent_topic,\n",
    "            factory=lambda: SupportAnalysisAgent(model_client=self.client),\n",
    "        )\n",
    "\n",
    "        self.runtime.start()\n",
    "\n",
    "        await self.runtime.publish_message(\n",
    "            Message(content=message),\n",
    "            topic_id=TopicId(support_analysis_agent_topic, source=\"default\"),\n",
    "        )\n",
    "\n",
    "        await self.runtime.stop_when_idle()\n",
    "        \n",
    "        inference_agent_id = AgentId(support_analysis_agent_topic, \"default\")\n",
    "        inference_agent = await self.runtime.try_get_underlying_agent_instance(\n",
    "            inference_agent_id\n",
    "        )\n",
    "\n",
    "        inference_result = inference_agent._result\n",
    "        return inference_result\n",
    "\n",
    "    async def analysis(self, data):\n",
    "        message = f\"based on input data : {data}\"\n",
    "        return  await self._analysis(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0d2b27-a144-41bf-8450-f26b2f2963df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 36 conversations\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer reported an urgent issue with the slowness of remote lookup in TimePlus.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Salah Alkhwlani reported an urgent issue regarding the slowness of remote lookup in TimePlus. The team discussed the issue, with Ibrahim Bakhsh performing a patch update to address it. There was a conversation about the remote lookup not pushing down to ClickHouse, and the team planned to have a meeting to further investigate the issue.\",\n",
      "  \"start_time\": \"2025-01-02 22:12:26\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer reports a significant disk space issue related to the write-ahead log and seeks assistance.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh reported that 1 TB of information was consumed in the write-ahead log, suspecting it to be a bug. The team discussed potential causes, including a query that filled the disk to 100%. They explored commands to flush unnecessary data and confirmed that dropping certain streams reduced the disk usage significantly. The issue was resolved after identifying and addressing the root cause.\",\n",
      "  \"start_time\": \"2025-01-07 14:37:58\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"Mohammed Junaid is inquiring about the use of StatefulSets in Timeplus and seeking a solution for upsizing PVCs via Helm.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"The conversation revolves around the challenges faced by Mohammed Junaid when trying to upsize PersistentVolumeClaims (PVCs) in a StatefulSet configuration using Helm. He expresses concerns about the immutability of StatefulSets and the potential for mismatches between Helm configurations and actual PVC sizes. Ken Chen and Gang Tao provide insights and suggestions, but a definitive solution is not reached.\",\n",
      "  \"start_time\": \"2025-01-07 15:16:39\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"Ussama Rafique is asking for examples of loading data from S3 into TimePlus and inquiring about the process.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ussama Rafique initiated the conversation by asking for examples of loading data from S3 into TimePlus and whether to load directly from S3 or copy files locally first. Gang Tao provided an example of an S3 external stream and answered Ussama's questions regarding data format and AWS credentials. Ussama further inquired about loading multiple files and Gang Tao clarified that a pattern can be specified to load files in bulk. The conversation concluded with Gang Tao providing additional examples.\",\n",
      "  \"start_time\": \"2025-01-07 17:05:53\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"Customer is seeking assistance in creating a user-defined function to push data from Timeplus to Algolia.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"The conversation began with Ibrahim Bakhsh requesting help to create a user-defined function for pushing data from Timeplus to Algolia. Sarwar Bhuiyan suggested using Timeplus Connect instead of the initial approach. Various team members provided code examples and configurations for using Timeplus Connect and the Algolia API. After some back and forth regarding the correct approach and configurations, Ibrahim confirmed that the provided solution worked. He also inquired about a validator for the mapping part, to which Gang Tao mentioned an issue that has been fixed in a new app server version.\",\n",
      "  \"start_time\": \"2025-01-13 08:41:32\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"Ussama Rafique is asking multiple questions regarding the use of secondary indexes and joins with mutable streams.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique inquires about the capabilities and limitations of secondary indexes and joins with mutable streams, while Ken Chen provides insights and clarifications. The conversation covers complex SQL queries, performance considerations, and the handling of large data sets. Ussama expresses a need for further understanding and experimentation with hybrid hash tables and mutable streams for data enrichment.\",\n",
      "  \"start_time\": \"2025-01-13T14:33:59\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Ussama Rafique is experiencing issues with dictionary joins and is discussing potential solutions with Ken Chen.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reported an issue related to dictionary joins in a SQL query and shared the settings used for creating dictionaries. Ken Chen engaged in the conversation by asking clarifying questions and suggesting a quick meeting to discuss the issue further. They agreed to meet in 20 minutes to continue troubleshooting.\",\n",
      "  \"start_time\": \"2025-01-14 17:35:05\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Ussama Rafique reports issues with direct joins in the system, and Ken Chen acknowledges the problems and offers to investigate further.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique outlines multiple issues with direct joins involving mutable streams and dictionaries, including specific error messages encountered. Ken Chen responds by confirming that some issues are being worked on and requests logs for further analysis. The conversation indicates ongoing problems that have not yet been resolved.\",\n",
      "  \"start_time\": \"2025-01-14 21:09:09\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer is experiencing issues with dropping a dictionary and encountering filesystem errors.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh reported an issue with dropping a dictionary before an upgrade, receiving filesystem errors indicating that certain files do not exist. Alan Yu suggested that the error might be safe to ignore and recommended checking the filesystem. Ussama Rafique confirmed that the files were missing and suggested that a rolling restart might resolve the issue. However, after attempting a restart, the problem persisted. The conversation also touched on other issues related to joins and dictionary metadata.\",\n",
      "  \"start_time\": \"2025-01-16 08:23:41\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer is reporting multiple issues related to stream joins and storage management.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ussama Rafique reported several high-priority issues regarding multi mutable stream direct joins, WAL/metastore GC issues, and dictionary problems. Ken Chen requested logs and additional information to help reproduce the issues. After some discussion, Ken confirmed that he was able to reproduce the issue and is working on a fix, indicating that the problem is being addressed.\",\n",
      "  \"start_time\": \"2025-01-19T21:00:58\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is reporting an ongoing issue with size increase in the write ahead log.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh is inquiring about the size increase issue related to the write ahead log, which has significantly increased after an upgrade. Ken Chen is still investigating the matter and promises to provide findings later.\",\n",
      "  \"start_time\": \"2025-01-22 18:52:49\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer reports an issue with renaming a stream causing a timeout error.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reports that after attempting to rename a stream, they are unable to create a new stream due to a timeout error. They also mention seeing numerous related errors in the Grafana logs. Ken Chen expresses a desire to revert the change and suggests a huddle for a quick fix.\",\n",
      "  \"start_time\": \"2025-01-22 19:48:43\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is inquiring about a bug fix and requesting a script to manage logs.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh is concerned about a bug that prevents the deletion of old logs and asks Ken Chen when it will be fixed. Ken provides information about safely removing logs and shares a script. They agree to work together to manage the logs and plan to meet the next day to finalize the process.\",\n",
      "  \"start_time\": \"2025-01-22T22:21:49\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer reported errors related to node replication and WAL disk space consumption after a recent upgrade.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reported multiple errors occurring on node-2 after a recent upgrade, including issues with request parsing and WAL disk space consumption. After restarting node-2, some errors were resolved, but concerns about increasing disk space usage were raised. Ken Chen suggested a cleanup and offered a fix, and they agreed to meet to address the WAL space issue.\",\n",
      "  \"start_time\": \"2025-01-23 09:37:44\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is experiencing errors related to data type changes in an external table and seeks a solution.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ussama Rafique reported issues with data type changes in an external table in TimePlus, leading to errors when querying. Alan Yu suggested restarting TimePlus to refresh the external table columns, but this did not resolve the issue. Ussama eventually recreated the external table and materialized view, which resolved the problem. Lisen YL provided additional context about the behavior of datetime parsing in TimePlus and ClickHouse.\",\n",
      "  \"start_time\": \"2025-01-23 11:28:56\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer reports an issue with node version discrepancies after an upgrade.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reports an issue where one node has a different image version than the others after an upgrade, causing it to be isolated from the cluster. Restarting the node did not resolve the issue. Ken Chen suggests switching to a new tag to fix the problem, and Ussama confirms the tag to be used. Ibrahim Bakhsh inquires about which tag to use, and Ussama provides the necessary information. The issue remains unresolved as they are still analyzing the deployment problem.\",\n",
      "  \"start_time\": \"2025-01-24 17:56:24\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer reported a bug causing garbage collection not to trigger after a cluster upgrade.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reported an issue with garbage collection not functioning after a cluster upgrade, leading to space issues. He temporarily resolved the problem by dropping a large mutable stream. Ken Chen provided a potential solution by suggesting a modification to the retention policy for mutable streams and mentioned a future update to address the default retention behavior.\",\n",
      "  \"start_time\": \"2025-01-24 22:02:28\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer is facing issues with a group by clause in their query and also reports a node failure.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reports issues with a group by clause in a query that returns 0 rows. After some troubleshooting with Ken Chen, it is discovered that removing the limit allows rows to be returned, but the behavior is different than expected. Ussama also reports a node failure and potential corruption of stream metadata due to an alter table setting. Ken acknowledges the issue and promises to come up with a fix.\",\n",
      "  \"start_time\": \"2025-01-25 16:53:29\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"The customer is seeking assistance to expose query-related metrics to Grafana via Prometheus/VictoriaMetrics and is discussing improvements to the current chart.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Mohammed Junaid requested help to expose query-related metrics to Grafana using VictoriaMetrics. Calvin Zhang provided initial guidance on collecting metrics, and after some back-and-forth, Junaid successfully exported the metrics. They discussed the need for specific labels for better metric scraping and the limitations of the current chart. Junaid offered to share his local chart modifications, and Calvin acknowledged the need for improvements in the public chart. The conversation concluded with Junaid planning to test the provided dashboards and implement fixes.\",\n",
      "  \"start_time\": \"2025-01-27T07:54:35\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"The customer is asking for guidance on monitoring sink progress and handling sink deletion issues.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh inquired about monitoring sink progress, safely deleting sinks, and adding a processing layer. He also reported an issue with editing sinks after a recent upgrade. Gang Tao provided guidance on monitoring and acknowledged the deletion issue as a limitation. Ken Chen mentioned they would replicate the issue. Ibrahim requested equivalent queries for the provided guidance.\",\n",
      "  \"start_time\": \"2025-01-28 02:00:14\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer reports a crash issue with Timeplus after creating a new stream.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh reports that Timeplus is crashing for two nodes after creating a new stream and inserting data into it. Ken Chen mentions a fix is in the new build and asks for confirmation on how to create the stream and materialized view. Ussama Rafique provides details about the error encountered during the data load. Ken Chen is working on a new build to address the issue, but Ibrahim reports CPU spiking and additional materialized view failures. A huddle is suggested to discuss the issues further.\",\n",
      "  \"start_time\": \"2025-01-28 11:26:40\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"The customer is asking for clarification on how to retrieve committed and applied SN for each shard of a stream.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique is confused about the changes in the `system.stream_state_log` regarding how committed and applied SN are displayed for shards in a stream. He notes that previously it showed SN for each shard on each node, but now it only shows SN per node. Ken Chen responds by mentioning that there is a `dimension` column in the log that indicates the shard, but also notes that there is a bug in the Timeplus Console that needs fixing.\",\n",
      "  \"start_time\": \"2025-01-29T12:25:32\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Ussama Rafique reported errors in Timeplus while loading data, but later indicated the issue was resolved.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ussama Rafique encountered errors while trying to load data into Timeplus, specifically a timeout error. Ken Chen engaged in troubleshooting by asking for logs and suggesting checks on the network and disk IOPS. After some discussion, Ussama confirmed that the issue seemed to be resolved.\",\n",
      "  \"start_time\": \"2025-01-29 15:57:51\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"The customer is requesting a way to create an incremental count of customers per store in a mutable stream.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Mahmoud Elhalwany is looking for a solution to create an incremental count of customers associated with each store. Sarwar Bhuiyan and Ken Chen provide technical guidance on how to achieve this using SQL commands for creating mutable streams and materialized views, discussing considerations like memory footprint and latency. However, the conversation does not conclude with a clear resolution to Mahmoud's request.\",\n",
      "  \"start_time\": \"2025-02-13 12:28:18\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Ussama Rafique reports discrepancies in data processing between two tables in Kafka.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique raises concerns about discrepancies in orders data processed by multiple materialized views in Kafka. Ken Chen summarizes the situation, noting a backfill reprocessing issue and the need for further validation. The team discusses potential solutions, including the implementation of a version column in ClickHouse to improve data integrity and alerting mechanisms to catch issues earlier. The conversation highlights the need for better monitoring and the challenges faced due to missing logs.\",\n",
      "  \"start_time\": \"2025-02-16 16:01:16\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"Mahmoud Elhalwany is seeking support on how aggregation works and is coordinating a meeting for assistance.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Mahmoud Elhalwany requested a meeting for support on aggregation. Ken Chen agreed to meet the next morning, and they successfully scheduled a meeting to discuss the topic. The conversation concluded with Ken expressing eagerness to discuss and onboard Mahmoud's use cases and feedback.\",\n",
      "  \"start_time\": \"2025-02-24 07:33:18\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"question\",\n",
      "  \"brief\": \"The customer is asking for the equivalent of a ClickHouse query in Timeplus.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh inquired about how to convert a ClickHouse map function to Timeplus. Lisen YL suggested using `map_cast` as an alternative, but the conversation does not indicate if the customer found this solution satisfactory.\",\n",
      "  \"start_time\": \"2025-02-25 13:50:24\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer is reporting an issue with deleting a sink and is also requesting a feature for checkpoint tracking.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh reported an issue with the inability to delete a sink without restarting the pod and mentioned waiting for checkpoint tracking ability when editing sinks. Ken Chen responded that a release with fixes and enhancements is scheduled for tomorrow, and Calvin Zhang provided details about enhancements made to sinks, including metrics viewing and patching capabilities.\",\n",
      "  \"start_time\": \"2025-02-26 09:52:36\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is facing an issue with the map_cast function in SQL queries.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Ussama Rafique reported an issue with the map_cast function when comparing modified columns in a SQL query. Lisen YL provided insights into the problem, explaining that map_cast requires arrays of the same length. After discussing potential workarounds, Lisen suggested using array_map instead of map_cast, which Ussama confirmed worked for their needs.\",\n",
      "  \"start_time\": \"2025-03-02 12:31:38\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"The customer reported a problem with the Timeplus connector pod crashing due to a query involving map types.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"The conversation began with Mahmoud reporting a crash in the Timeplus connector pod due to a specific SQL query involving map types. The team discussed the issue, identified it as a bug in the Go driver, and provided steps to recover the pod by deleting the problematic sink. After following the instructions and upgrading the connector, the issue was resolved.\",\n",
      "  \"start_time\": \"2025-03-04T12:31:07\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"Customer is seeking guidance on optimizing the use of multiple materialized views in mutable streams for better performance.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Mahmoud Elhalwany inquires about the best way to handle multiple materialized views for calculating customer metrics in mutable streams without compromising performance. The team discusses various approaches, including the need for a different data model and the possibility of using separate calculations in different mutable streams. They explore the implications of using timestamps and versioning for managing data updates. The conversation ends with a suggestion to schedule a follow-up call for further discussion.\",\n",
      "  \"start_time\": \"2025-03-05 11:24:47\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"development request\",\n",
      "  \"brief\": \"The team is discussing the need for a meeting to address multiple aggregation and stream-related feature requests.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ibrahim Bakhsh initiated a conversation to schedule a meeting to discuss various issues related to aggregation and stream functionalities. Ussama Rafique highlighted the need for a feature to add new columns to existing streams, explaining the challenges faced with current limitations. Sarwar Bhuiyan provided some insights on the existing capabilities and ongoing work regarding adding columns to materialized views (MVs). The conversation indicates a need for further discussion and resolution on these feature requests.\",\n",
      "  \"start_time\": \"2025-03-08 03:35:03\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer inquires about a fix for an issue in Timeplus.\",\n",
      "  \"result\": \"resolved\",\n",
      "  \"summary\": \"Mahmoud Elhalwany asked about the status of a fix for an issue in Timeplus. Ken Chen informed him about a new patch release that could resolve the issue and suggested upgrading. Mohammed Junaid confirmed the upgrade was completed successfully, and Ken clarified that the web component did not require an upgrade as it had no changes in the patch. The conversation concluded with acknowledgments.\",\n",
      "  \"start_time\": \"2025-03-11 09:42:00\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is experiencing an issue with data output stopping after a certain number of rows in a query.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Ussama Rafique reports an issue with a query in the CLI where the output stops after 10,000 rows despite data continuously coming in. Sarwar Bhuiyan and Ken Chen provide suggestions and inquire about the specifics of the issue, but the problem remains unresolved as they seek further clarification and potential solutions.\",\n",
      "  \"start_time\": \"2025-03-12T18:07:07\",\n",
      "  \"severity\": \"medium\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is experiencing a memory error while trying to join two streams.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"Mahmoud Elhalwany reported an error related to memory limits while joining two streams. Lisen YL suggested increasing the join buffer size and provided alternative solutions like hybrid hash joins. The conversation included further clarifications and suggestions from Ken Chen and Ibrahim Bakhsh, but the issue remains unresolved as the customer is still seeking a solution.\",\n",
      "  \"start_time\": \"2025-03-19 09:10:25\",\n",
      "  \"severity\": \"high\"\n",
      "}\n",
      "{\n",
      "  \"category\": \"issue\",\n",
      "  \"brief\": \"Customer is experiencing errors in the sink and needs assistance in identifying the problematic rows.\",\n",
      "  \"result\": \"unresolved\",\n",
      "  \"summary\": \"The customer, Mahmoud, reports errors in the sink and requests help in identifying the rows that caused the errors. Calvin provides guidance on upgrading the helm chart to access logs and suggests methods to handle errors. Ibrahim emphasizes the urgency due to its impact on their Q1 delivery. The conversation includes technical details about configurations and modifications to the helm chart, with Mohammed suggesting changes and requesting a test version of the chart. The issue remains unresolved as they plan to test the changes later.\",\n",
      "  \"start_time\": \"2025-03-19T10:09:02\",\n",
      "  \"severity\": \"high\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "###### import re\n",
    "def extract_code_blocks_with_type(markdown_text):\n",
    "    \"\"\"\n",
    "    Extract code blocks and their types from a Markdown string.\n",
    "\n",
    "    Parameters:\n",
    "        markdown_text (str): The Markdown content as a string.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing (code_type, code_content).\n",
    "              If no type is specified, code_type will be an empty string.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match code blocks with or without a code type\n",
    "    pattern = r\"```(\\w+)?\\n(.*?)```\"\n",
    "\n",
    "    # Use re.DOTALL to capture code content spanning multiple lines\n",
    "    matches = re.findall(pattern, markdown_text, re.DOTALL)\n",
    "\n",
    "    # Normalize the results\n",
    "    return [\n",
    "        (code_type if code_type else \"\", code_content.strip())\n",
    "        for code_type, code_content in matches\n",
    "    ]\n",
    "\n",
    "\n",
    "timeplus_client = client.Client(host=timeplus_host, port=8463, user=timeplus_user,password=timeplus_password)\n",
    "\n",
    "analysis_result_stream = \"slack_support_analysis_salla\"\n",
    "## create the analysis stream\n",
    "try:\n",
    "    timeplus_client.execute(\n",
    "        f\"\"\"CREATE STREAM IF NOT EXISTS {analysis_result_stream} (\n",
    "        raw string\n",
    "    )\n",
    "    \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "rows = timeplus_client.execute_iter(f\"select * from v_salla_support_merged_threads\")\n",
    "count = 0\n",
    "\n",
    "results = []\n",
    "for row in rows:\n",
    "    input = row[0]\n",
    "    results.append(input)\n",
    "\n",
    "print(f'there are {len(results)} conversations')\n",
    "    \n",
    "\n",
    "for r in results:\n",
    "    agent = SupportAgent()\n",
    "    result = await agent.analysis(r)\n",
    "    code = extract_code_blocks_with_type(result)\n",
    "    if len(code) > 0:\n",
    "        analaysis_result = code[0][1]\n",
    "        print(analaysis_result)\n",
    "        try:\n",
    "            timeplus_client.execute(\n",
    "                f\"INSERT INTO {analysis_result_stream} (raw) VALUES\",\n",
    "                [\n",
    "                    [\n",
    "                        analaysis_result\n",
    "                    ]\n",
    "                ],\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    else:\n",
    "        print(f\"failed to parse , input is {input }\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac3f38-d61e-47d0-9b75-4b08d697d223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
