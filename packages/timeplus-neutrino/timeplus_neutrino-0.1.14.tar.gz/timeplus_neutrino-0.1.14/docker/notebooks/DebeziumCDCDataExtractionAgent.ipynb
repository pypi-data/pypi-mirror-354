{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e96c3e-e312-46e7-944d-c5510af2b4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in /opt/conda/lib/python3.11/site-packages (0.7.5)\n",
      "Requirement already satisfied: pyautogen==0.7.5 in /opt/conda/lib/python3.11/site-packages (from autogen) (0.7.5)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (5.6.3)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (7.1.0)\n",
      "Requirement already satisfied: fast-depends<3,>=2.4.12 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (2.4.12)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.58 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (1.64.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (0.9.0)\n",
      "Requirement already satisfied: websockets<15,>=14 in /opt/conda/lib/python3.11/site-packages (from pyautogen==0.7.5->autogen) (14.2)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from asyncer==0.0.8->pyautogen==0.7.5->autogen) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.11/site-packages (from openai>=1.58->pyautogen==0.7.5->autogen) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.5->autogen) (2.27.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.7.5->autogen) (2.31.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from docker->pyautogen==0.7.5->autogen) (2.0.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->pyautogen==0.7.5->autogen) (2024.11.6)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.5->autogen) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.5->autogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker->pyautogen==0.7.5->autogen) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7755a88a-7d79-46a8-ba74-28b8c7f6ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_code_blocks_with_type(markdown_text):\n",
    "    \"\"\"\n",
    "    Extract code blocks and their types from a Markdown string.\n",
    "\n",
    "    Parameters:\n",
    "        markdown_text (str): The Markdown content as a string.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing (code_type, code_content).\n",
    "              If no type is specified, code_type will be an empty string.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match code blocks with or without a code type\n",
    "    pattern = r\"```(\\w+)?\\n(.*?)```\"\n",
    "\n",
    "    # Use re.DOTALL to capture code content spanning multiple lines\n",
    "    matches = re.findall(pattern, markdown_text, re.DOTALL)\n",
    "\n",
    "    # Normalize the results\n",
    "    return [(code_type if code_type else \"\", code_content.strip()) for code_type, code_content in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78a5736b-b313-4886-bb92-b9869b51bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "\n",
    "class DataExtractionAgent:\n",
    "    data_extraction_system_message = \"you are a helpful data processing agent, help to extract useful information to unstrcuture data\"\n",
    "\n",
    "    payload_extraction_system_message = \"\"\"\n",
    "    the input data is a debezium CDC data payload, our target is to extract the payload in after or payload:after into a new stream\n",
    "    the source stream has just one string field with name raw\n",
    "    \n",
    "    here is are sample queries to extrac the after payload based on different types of debezium payload\n",
    "    case1. when the after payload is in root layer\n",
    "    select raw:after from source_stream_name where _tp_time > earliest_ts()\n",
    "    case2. when the after payload is in field of payload\n",
    "    select raw:payload:after from source_stream_name where _tp_time > earliest_ts()\n",
    "\n",
    "    return which extract query should be used in markdown code with sql\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    target_schema_inference_system_message = \"\"\"please generate DDL based on debezium payload\n",
    "    case1. when the after payload is in root layer, using json object in the after field as input\n",
    "    case2. when the after payload is in field of payload, \n",
    "     using the json string in the after field and only in the after field of payload as input\n",
    "     No other fields should be considered, such as source, or schema etc\n",
    "    \n",
    "    here are the rules to follow\n",
    "    * the DDL grammar follows ClickHouse style\n",
    "    * the Table keyword MUST be replaced with Stream\n",
    "    * all datatypes MUST be in lowercase, such uint32\n",
    "    * all keywords MUST be in lowercase, such as nullable\n",
    "    * all field names MUST keep same as in the json\n",
    "    * composite types such as array, tuple, map cannot be nullable \n",
    "    * should use composite types like array, map or tuple to represent complex structure in the json\n",
    "    * output should be put into markdown of sql\n",
    "    * bool type is supported\n",
    "    * available composite types are\n",
    "        * array\n",
    "        * tuple\n",
    "        * map\n",
    "    * for composite type, using tuple over map, as tulpe is more generic\n",
    "    \n",
    "    here is a sample of output DDL:\n",
    "    ```sql\n",
    "    CREATE STREAM target_stream\n",
    "    (\n",
    "      `cid` string,\n",
    "      `gas_percent` float64,\n",
    "      `in_use` bool,\n",
    "      `latitude` float64,\n",
    "      `longitude` float64,\n",
    "      `locked` bool,\n",
    "      `speed_kmh` float64,\n",
    "      `time` string,\n",
    "      `total_km` float64\n",
    "    )\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    mv_extraction_system_message = \"\"\"please create a materialized view to extraction information from source stream into target stream\n",
    "    the source stream has just one string field with name raw\n",
    "    here are the rules to following\n",
    "    * the grammar follows ClickHouse style\n",
    "    * all function name follows snake case, such as json_extract_array\n",
    "    * all keywords MUST be in lowercase, such as nullable\n",
    "    * using tuple for hierarchy case which is generic\n",
    "    \n",
    "    \n",
    "    here is the grammar of materialized view\n",
    "    CREATE MATERIALIZED VIEW [IF NOT EXISTS] <view_name>\n",
    "    INTO <target_stream> AS <SELECT ...>\n",
    "\n",
    "    NOTE, to extrat json with hierarchy, \n",
    "    this one is WRONG : json_extract_uint(raw, 'after.customer_id') AS customer_id\n",
    "    extract target field does not support hierarchy\n",
    "    SHOULD BE : json_extract_uint(raw:after, 'customer_id') AS customer_id,\n",
    "\n",
    "    this one is WRONG : tuple_cast(json_extract_string(raw:payload:after, '_id.$oid')) AS _id,\n",
    "    SHOULD BE : tuple_cast(json_extract_string(raw:payload:after:_id, '$oid')) AS _id,\n",
    "\n",
    "    to construct or convert tuple type , call tuple_cast, for example:\n",
    "    tuple_cast(a, b) AS tuple_field,\n",
    "    there is no tuple() function, NEVER call tuple() function\n",
    "\n",
    "    In case the payload contains complex composition and hierarchy, you should provide the conversion layer by layer, do not miss any middle layer\n",
    "    here is a sample that one of the target field is a map, using array_map function to help\n",
    "    array_map(\n",
    "        x -> (\n",
    "            (json_extract_string(x, 'date'), json_extract_float(x, 'amount'))\n",
    "        ),\n",
    "        json_extract_array(after:raw_data, 'transaction_history')\n",
    "    ) as transaction_history\n",
    "\n",
    "    please only use following available json extraction functions if required:\n",
    "    * json_extract_int\n",
    "    * json_extract_uint\n",
    "    * json_extract_float\n",
    "    * json_extract_bool\n",
    "    * json_extract_string\n",
    "    * json_extract_array\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._llm_config = {\n",
    "            \"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}], \"temperature\": 0\n",
    "        }\n",
    "        \n",
    "\n",
    "        self.data_extraction_agent = ConversableAgent(\n",
    "            \"data_extraction_agent\",\n",
    "            system_message=self.data_extraction_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.payload_extraction_agent = ConversableAgent(\n",
    "            \"payload_extraction_agent\",\n",
    "            system_message=self.payload_extraction_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.target_schema_inference_agent = ConversableAgent(\n",
    "            \"target_schema_inference_agent\",\n",
    "            system_message=self.target_schema_inference_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "        self.mv_extraction_agent = ConversableAgent(\n",
    "            \"mv_extraction_agent\",\n",
    "            system_message=self.mv_extraction_system_message,\n",
    "            llm_config=self._llm_config,\n",
    "            code_execution_config=False,\n",
    "            max_consecutive_auto_reply=1,\n",
    "            human_input_mode=\"NEVER\",\n",
    "        )\n",
    "\n",
    "    def pipeline(self, data, source_stream_name, target_stream_name):\n",
    "        message = f'based on input data : {data} and source stream name {source_stream_name}'\n",
    "        self.data_extraction_agent.initiate_chats(\n",
    "            [\n",
    "                {\n",
    "                    \"recipient\": self.payload_extraction_agent,\n",
    "                    \"message\": message,\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.target_schema_inference_agent,\n",
    "                    \"message\": f'based on input data : {data} and target stream name {target_stream_name}',\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                },\n",
    "                {\n",
    "                    \"recipient\": self.mv_extraction_agent,\n",
    "                    \"message\": f'please create materialized view to extrat information from source stream to target stream',\n",
    "                    \"max_turns\": 1,\n",
    "                    \"summary_method\": \"last_msg\",\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return self.payload_extraction_agent.last_message()['content'], self.target_schema_inference_agent.last_message()['content'], self.mv_extraction_agent.last_message()['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fab71972-d535-4435-ab8d-f721eb8f4552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to payload_extraction_agent):\n",
      "\n",
      "based on input data : {\n",
      "\t\"before\": null,\n",
      "\t\"after\": {\n",
      "\t\t\"customer_id\": 9,\n",
      "\t\t\"name\": \"Johnathan Rodriguez\",\n",
      "\t\t\"email\": \"thomasramirez@example.org\",\n",
      "\t\t\"phone\": \"001-845-290-8721x77863\",\n",
      "\t\t\"address\": \"743 Cervantes Causeway Apt. 762\n",
      "Port Lauren, NY 12698\"\n",
      "\t},\n",
      "\t\"source\": {\n",
      "\t\t\"version\": \"3.0.6.Final\",\n",
      "\t\t\"connector\": \"postgresql\",\n",
      "\t\t\"name\": \"postgres\",\n",
      "\t\t\"ts_ms\": 1740183762305,\n",
      "\t\t\"snapshot\": \"false\",\n",
      "\t\t\"db\": \"lumi_credit\",\n",
      "\t\t\"sequence\": \"[\"27606456\",\"27606456\"]\",\n",
      "\t\t\"ts_us\": 1740183762305810,\n",
      "\t\t\"ts_ns\": 1740183762305810000,\n",
      "\t\t\"schema\": \"public\",\n",
      "\t\t\"table\": \"customers\",\n",
      "\t\t\"txId\": 763,\n",
      "\t\t\"lsn\": 27606456,\n",
      "\t\t\"xmin\": null\n",
      "\t},\n",
      "\t\"transaction\": null,\n",
      "\t\"op\": \"c\",\n",
      "\t\"ts_ms\": 1740183762818,\n",
      "\t\"ts_us\": 1740183762818345,\n",
      "\t\"ts_ns\": 1740183762818345200\n",
      "} and source stream name kafka_cdc_postgres_customers\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpayload_extraction_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the input data, the \"after\" payload is in the root layer. Therefore, the appropriate query to extract the \"after\" payload is:\n",
      "\n",
      "```sql\n",
      "SELECT raw:after FROM kafka_cdc_postgres_customers WHERE _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to target_schema_inference_agent):\n",
      "\n",
      "based on input data : {\n",
      "\t\"before\": null,\n",
      "\t\"after\": {\n",
      "\t\t\"customer_id\": 9,\n",
      "\t\t\"name\": \"Johnathan Rodriguez\",\n",
      "\t\t\"email\": \"thomasramirez@example.org\",\n",
      "\t\t\"phone\": \"001-845-290-8721x77863\",\n",
      "\t\t\"address\": \"743 Cervantes Causeway Apt. 762\n",
      "Port Lauren, NY 12698\"\n",
      "\t},\n",
      "\t\"source\": {\n",
      "\t\t\"version\": \"3.0.6.Final\",\n",
      "\t\t\"connector\": \"postgresql\",\n",
      "\t\t\"name\": \"postgres\",\n",
      "\t\t\"ts_ms\": 1740183762305,\n",
      "\t\t\"snapshot\": \"false\",\n",
      "\t\t\"db\": \"lumi_credit\",\n",
      "\t\t\"sequence\": \"[\"27606456\",\"27606456\"]\",\n",
      "\t\t\"ts_us\": 1740183762305810,\n",
      "\t\t\"ts_ns\": 1740183762305810000,\n",
      "\t\t\"schema\": \"public\",\n",
      "\t\t\"table\": \"customers\",\n",
      "\t\t\"txId\": 763,\n",
      "\t\t\"lsn\": 27606456,\n",
      "\t\t\"xmin\": null\n",
      "\t},\n",
      "\t\"transaction\": null,\n",
      "\t\"op\": \"c\",\n",
      "\t\"ts_ms\": 1740183762818,\n",
      "\t\"ts_us\": 1740183762818345,\n",
      "\t\"ts_ns\": 1740183762818345200\n",
      "} and target stream name customers\n",
      "Context: \n",
      "Based on the input data, the \"after\" payload is in the root layer. Therefore, the appropriate query to extract the \"after\" payload is:\n",
      "\n",
      "```sql\n",
      "SELECT raw:after FROM kafka_cdc_postgres_customers WHERE _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mtarget_schema_inference_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the provided input data, the \"after\" payload is in the root layer. We will use the JSON object in the \"after\" field to generate the DDL for the target stream named \"customers\".\n",
      "\n",
      "Here is the DDL in ClickHouse style:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM customers\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to mv_extraction_agent):\n",
      "\n",
      "please create materialized view to extrat information from source stream to target stream\n",
      "Context: \n",
      "Based on the input data, the \"after\" payload is in the root layer. Therefore, the appropriate query to extract the \"after\" payload is:\n",
      "\n",
      "```sql\n",
      "SELECT raw:after FROM kafka_cdc_postgres_customers WHERE _tp_time > earliest_ts()\n",
      "```\n",
      "Based on the provided input data, the \"after\" payload is in the root layer. We will use the JSON object in the \"after\" field to generate the DDL for the target stream named \"customers\".\n",
      "\n",
      "Here is the DDL in ClickHouse style:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM customers\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string\n",
      ")\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmv_extraction_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the context and the provided DDL for the target stream named \"customers\", we need to create a materialized view to extract information from the source stream into the target stream. The source stream has a single string field named `raw`, and we will extract the necessary fields from the JSON object in the \"after\" payload.\n",
      "\n",
      "Here is the materialized view in ClickHouse style:\n",
      "\n",
      "```sql\n",
      "CREATE MATERIALIZED VIEW IF NOT EXISTS customers_view\n",
      "INTO customers AS\n",
      "SELECT\n",
      "    json_extract_uint(raw:after, 'customer_id') AS customer_id,\n",
      "    json_extract_string(raw:after, 'name') AS name,\n",
      "    json_extract_string(raw:after, 'email') AS email,\n",
      "    json_extract_string(raw:after, 'phone') AS phone,\n",
      "    json_extract_string(raw:after, 'address') AS address\n",
      "FROM kafka_cdc_postgres_customers\n",
      "WHERE _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "This materialized view extracts the `customer_id`, `name`, `email`, `phone`, and `address` fields from the \"after\" payload in the `raw` field of the source stream and inserts them into the `customers` target stream.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "code type sql, extraction sql : SELECT raw:after FROM kafka_cdc_postgres_customers WHERE _tp_time > earliest_ts()\n",
      "Based on the provided input data, the \"after\" payload is in the root layer. We will use the JSON object in the \"after\" field to generate the DDL for the target stream named \"customers\".\n",
      "\n",
      "Here is the DDL in ClickHouse style:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM customers\n",
      "(\n",
      "  `customer_id` uint32,\n",
      "  `name` string,\n",
      "  `email` string,\n",
      "  `phone` string,\n",
      "  `address` string\n",
      ")\n",
      "```\n",
      "Based on the context and the provided DDL for the target stream named \"customers\", we need to create a materialized view to extract information from the source stream into the target stream. The source stream has a single string field named `raw`, and we will extract the necessary fields from the JSON object in the \"after\" payload.\n",
      "\n",
      "Here is the materialized view in ClickHouse style:\n",
      "\n",
      "```sql\n",
      "CREATE MATERIALIZED VIEW IF NOT EXISTS customers_view\n",
      "INTO customers AS\n",
      "SELECT\n",
      "    json_extract_uint(raw:after, 'customer_id') AS customer_id,\n",
      "    json_extract_string(raw:after, 'name') AS name,\n",
      "    json_extract_string(raw:after, 'email') AS email,\n",
      "    json_extract_string(raw:after, 'phone') AS phone,\n",
      "    json_extract_string(raw:after, 'address') AS address\n",
      "FROM kafka_cdc_postgres_customers\n",
      "WHERE _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "This materialized view extracts the `customer_id`, `name`, `email`, `phone`, and `address` fields from the \"after\" payload in the `raw` field of the source stream and inserts them into the `customers` target stream.\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"{\n",
    "\t\"before\": null,\n",
    "\t\"after\": {\n",
    "\t\t\"customer_id\": 9,\n",
    "\t\t\"name\": \"Johnathan Rodriguez\",\n",
    "\t\t\"email\": \"thomasramirez@example.org\",\n",
    "\t\t\"phone\": \"001-845-290-8721x77863\",\n",
    "\t\t\"address\": \"743 Cervantes Causeway Apt. 762\\nPort Lauren, NY 12698\"\n",
    "\t},\n",
    "\t\"source\": {\n",
    "\t\t\"version\": \"3.0.6.Final\",\n",
    "\t\t\"connector\": \"postgresql\",\n",
    "\t\t\"name\": \"postgres\",\n",
    "\t\t\"ts_ms\": 1740183762305,\n",
    "\t\t\"snapshot\": \"false\",\n",
    "\t\t\"db\": \"lumi_credit\",\n",
    "\t\t\"sequence\": \"[\\\"27606456\\\",\\\"27606456\\\"]\",\n",
    "\t\t\"ts_us\": 1740183762305810,\n",
    "\t\t\"ts_ns\": 1740183762305810000,\n",
    "\t\t\"schema\": \"public\",\n",
    "\t\t\"table\": \"customers\",\n",
    "\t\t\"txId\": 763,\n",
    "\t\t\"lsn\": 27606456,\n",
    "\t\t\"xmin\": null\n",
    "\t},\n",
    "\t\"transaction\": null,\n",
    "\t\"op\": \"c\",\n",
    "\t\"ts_ms\": 1740183762818,\n",
    "\t\"ts_us\": 1740183762818345,\n",
    "\t\"ts_ns\": 1740183762818345200\n",
    "}\"\"\"\n",
    "\n",
    "source_stream_name = \"kafka_cdc_postgres_customers\"\n",
    "target_stream_name = \"customers\"\n",
    "\n",
    "agent = DataExtractionAgent()\n",
    "\n",
    "agent1_output, agent2_output, agent3_output = agent.pipeline(data, source_stream_name, target_stream_name)\n",
    "\n",
    "code = extract_code_blocks_with_type(agent1_output)\n",
    "print(f\"code type {code[0][0]}, extraction sql : {code[0][1]}\")\n",
    "\n",
    "print(agent2_output)\n",
    "\n",
    "print(agent3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11cae06f-3eee-4dfc-acc2-1f66dac75986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to payload_extraction_agent):\n",
      "\n",
      "based on input data : {\n",
      "\t\"schema\": {\n",
      "\t\t\"type\": \"struct\",\n",
      "\t\t\"fields\": [\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"before\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"after\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"array\",\n",
      "\t\t\t\t\t\t\"items\": {\n",
      "\t\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\t\"optional\": false\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"removedFields\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\t\t\"field\": \"updatedFields\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"array\",\n",
      "\t\t\t\t\t\t\"items\": {\n",
      "\t\t\t\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\t\t\"field\": \"field\"\n",
      "\t\t\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\t\t\t\"type\": \"int32\",\n",
      "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\t\t\"field\": \"size\"\n",
      "\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t],\n",
      "\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.truncatedarray\",\n",
      "\t\t\t\t\t\t\t\"version\": 1\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"truncatedArrays\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.updatedescription\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"updateDescription\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"version\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"connector\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"name\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"ts_ms\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"name\": \"io.debezium.data.Enum\",\n",
      "\t\t\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\t\t\"parameters\": {\n",
      "\t\t\t\t\t\t\t\"allowed\": \"true,first,first_in_data_collection,last_in_data_collection,last,false,incremental\"\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"default\": \"false\",\n",
      "\t\t\t\t\t\t\"field\": \"snapshot\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"db\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"sequence\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"ts_us\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"ts_ns\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"collection\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int32\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"ord\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"lsid\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"txnNumber\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"wallTime\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\"name\": \"io.debezium.connector.mongo.Source\",\n",
      "\t\t\t\t\"field\": \"source\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"field\": \"op\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"field\": \"ts_ms\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"id\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"total_order\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"data_collection_order\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"event.block\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"transaction\"\n",
      "\t\t\t}\n",
      "\t\t],\n",
      "\t\t\"optional\": false,\n",
      "\t\t\"name\": \"mongodb.lumi_data.unstructured_data.Envelope\"\n",
      "\t},\n",
      "\t\"payload\": {\n",
      "\t\t\"before\": null,\n",
      "\t\t\"after\": \"{\"_id\": {\"$oid\": \"67b918d21585c8c281a60f0e\"},\"customer_id\": 10,\"raw_data\": {\"transaction_history\": [{\"date\": {\"$date\": 1740009600000},\"amount\": 734.57},{\"date\": {\"$date\": 1739836800000},\"amount\": 631.99},{\"date\": {\"$date\": 1735862400000},\"amount\": 384.18},{\"date\": {\"$date\": 1739404800000},\"amount\": 921.92}],\"social_media_activity\": {\"platform\": \"LinkedIn\",\"activity_score\": 63},\"miscellaneous\": {\"notes\": \"Cell week per all power administration.\",\"risk_flags\": \"Low\"}}}\",\n",
      "\t\t\"updateDescription\": null,\n",
      "\t\t\"source\": {\n",
      "\t\t\t\"version\": \"3.0.6.Final\",\n",
      "\t\t\t\"connector\": \"mongodb\",\n",
      "\t\t\t\"name\": \"mongodb\",\n",
      "\t\t\t\"ts_ms\": 1740183762000,\n",
      "\t\t\t\"snapshot\": \"false\",\n",
      "\t\t\t\"db\": \"lumi_data\",\n",
      "\t\t\t\"sequence\": null,\n",
      "\t\t\t\"ts_us\": 1740183762000000,\n",
      "\t\t\t\"ts_ns\": 1740183762000000000,\n",
      "\t\t\t\"collection\": \"unstructured_data\",\n",
      "\t\t\t\"ord\": 10,\n",
      "\t\t\t\"lsid\": null,\n",
      "\t\t\t\"txnNumber\": null,\n",
      "\t\t\t\"wallTime\": 1740183762308\n",
      "\t\t},\n",
      "\t\t\"op\": \"c\",\n",
      "\t\t\"ts_ms\": 1740183762403,\n",
      "\t\t\"transaction\": null\n",
      "\t}\n",
      "}\n",
      "} and source stream name kafka_cdc_mongo_unstructure\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mpayload_extraction_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. Therefore, the appropriate query to extract the `after` payload is:\n",
      "\n",
      "```sql\n",
      "select raw:payload:after from kafka_cdc_mongo_unstructure where _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to target_schema_inference_agent):\n",
      "\n",
      "based on input data : {\n",
      "\t\"schema\": {\n",
      "\t\t\"type\": \"struct\",\n",
      "\t\t\"fields\": [\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"before\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"after\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"array\",\n",
      "\t\t\t\t\t\t\"items\": {\n",
      "\t\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\t\"optional\": false\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"removedFields\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
      "\t\t\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\t\t\"field\": \"updatedFields\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"array\",\n",
      "\t\t\t\t\t\t\"items\": {\n",
      "\t\t\t\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\t\t\"field\": \"field\"\n",
      "\t\t\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\t\t\t\"type\": \"int32\",\n",
      "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\t\t\"field\": \"size\"\n",
      "\t\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\t],\n",
      "\t\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.truncatedarray\",\n",
      "\t\t\t\t\t\t\t\"version\": 1\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"truncatedArrays\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.updatedescription\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"updateDescription\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"version\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"connector\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"name\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"ts_ms\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"name\": \"io.debezium.data.Enum\",\n",
      "\t\t\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\t\t\"parameters\": {\n",
      "\t\t\t\t\t\t\t\"allowed\": \"true,first,first_in_data_collection,last_in_data_collection,last,false,incremental\"\n",
      "\t\t\t\t\t\t},\n",
      "\t\t\t\t\t\t\"default\": \"false\",\n",
      "\t\t\t\t\t\t\"field\": \"snapshot\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"db\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"sequence\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"ts_us\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"ts_ns\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"collection\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int32\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"ord\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"lsid\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"txnNumber\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\t\t\"field\": \"wallTime\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\"name\": \"io.debezium.connector.mongo.Source\",\n",
      "\t\t\t\t\"field\": \"source\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"field\": \"op\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"field\": \"ts_ms\"\n",
      "\t\t\t},\n",
      "\t\t\t{\n",
      "\t\t\t\t\"type\": \"struct\",\n",
      "\t\t\t\t\"fields\": [\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"string\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"id\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"total_order\"\n",
      "\t\t\t\t\t},\n",
      "\t\t\t\t\t{\n",
      "\t\t\t\t\t\t\"type\": \"int64\",\n",
      "\t\t\t\t\t\t\"optional\": false,\n",
      "\t\t\t\t\t\t\"field\": \"data_collection_order\"\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t],\n",
      "\t\t\t\t\"optional\": true,\n",
      "\t\t\t\t\"name\": \"event.block\",\n",
      "\t\t\t\t\"version\": 1,\n",
      "\t\t\t\t\"field\": \"transaction\"\n",
      "\t\t\t}\n",
      "\t\t],\n",
      "\t\t\"optional\": false,\n",
      "\t\t\"name\": \"mongodb.lumi_data.unstructured_data.Envelope\"\n",
      "\t},\n",
      "\t\"payload\": {\n",
      "\t\t\"before\": null,\n",
      "\t\t\"after\": \"{\"_id\": {\"$oid\": \"67b918d21585c8c281a60f0e\"},\"customer_id\": 10,\"raw_data\": {\"transaction_history\": [{\"date\": {\"$date\": 1740009600000},\"amount\": 734.57},{\"date\": {\"$date\": 1739836800000},\"amount\": 631.99},{\"date\": {\"$date\": 1735862400000},\"amount\": 384.18},{\"date\": {\"$date\": 1739404800000},\"amount\": 921.92}],\"social_media_activity\": {\"platform\": \"LinkedIn\",\"activity_score\": 63},\"miscellaneous\": {\"notes\": \"Cell week per all power administration.\",\"risk_flags\": \"Low\"}}}\",\n",
      "\t\t\"updateDescription\": null,\n",
      "\t\t\"source\": {\n",
      "\t\t\t\"version\": \"3.0.6.Final\",\n",
      "\t\t\t\"connector\": \"mongodb\",\n",
      "\t\t\t\"name\": \"mongodb\",\n",
      "\t\t\t\"ts_ms\": 1740183762000,\n",
      "\t\t\t\"snapshot\": \"false\",\n",
      "\t\t\t\"db\": \"lumi_data\",\n",
      "\t\t\t\"sequence\": null,\n",
      "\t\t\t\"ts_us\": 1740183762000000,\n",
      "\t\t\t\"ts_ns\": 1740183762000000000,\n",
      "\t\t\t\"collection\": \"unstructured_data\",\n",
      "\t\t\t\"ord\": 10,\n",
      "\t\t\t\"lsid\": null,\n",
      "\t\t\t\"txnNumber\": null,\n",
      "\t\t\t\"wallTime\": 1740183762308\n",
      "\t\t},\n",
      "\t\t\"op\": \"c\",\n",
      "\t\t\"ts_ms\": 1740183762403,\n",
      "\t\t\"transaction\": null\n",
      "\t}\n",
      "}\n",
      "} and target stream name mongo_unstructure\n",
      "Context: \n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. Therefore, the appropriate query to extract the `after` payload is:\n",
      "\n",
      "```sql\n",
      "select raw:payload:after from kafka_cdc_mongo_unstructure where _tp_time > earliest_ts()\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mtarget_schema_inference_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. The `after` field contains a JSON string, which we will use to generate the DDL for the ClickHouse stream. Here is the DDL based on the `after` payload:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM mongo_unstructure\n",
      "(\n",
      "  `_id` tuple(`$oid` string),\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(\n",
      "      tuple(\n",
      "        `date` tuple(`$date` int64),\n",
      "        `amount` float64\n",
      "      )\n",
      "    ),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "\n",
      "This DDL defines a stream named `mongo_unstructure` with fields corresponding to the structure of the JSON in the `after` payload. Composite types such as `tuple` and `array` are used to represent nested structures.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mdata_extraction_agent\u001b[0m (to mv_extraction_agent):\n",
      "\n",
      "please create materialized view to extrat information from source stream to target stream\n",
      "Context: \n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. Therefore, the appropriate query to extract the `after` payload is:\n",
      "\n",
      "```sql\n",
      "select raw:payload:after from kafka_cdc_mongo_unstructure where _tp_time > earliest_ts()\n",
      "```\n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. The `after` field contains a JSON string, which we will use to generate the DDL for the ClickHouse stream. Here is the DDL based on the `after` payload:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM mongo_unstructure\n",
      "(\n",
      "  `_id` tuple(`$oid` string),\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(\n",
      "      tuple(\n",
      "        `date` tuple(`$date` int64),\n",
      "        `amount` float64\n",
      "      )\n",
      "    ),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "\n",
      "This DDL defines a stream named `mongo_unstructure` with fields corresponding to the structure of the JSON in the `after` payload. Composite types such as `tuple` and `array` are used to represent nested structures.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mmv_extraction_agent\u001b[0m (to data_extraction_agent):\n",
      "\n",
      "Based on the provided context and the structure of the `after` payload, we can create a materialized view to extract and transform the data from the source stream into the target stream. Here is the SQL statement for the materialized view:\n",
      "\n",
      "```sql\n",
      "create materialized view if not exists extract_mongo_unstructure\n",
      "into mongo_unstructure as\n",
      "select\n",
      "    tuple_cast(json_extract_string(raw:payload:after:_id, '$oid')) as _id,\n",
      "    json_extract_uint(raw:payload:after, 'customer_id') as customer_id,\n",
      "    tuple_cast(\n",
      "        array_map(\n",
      "            x -> (\n",
      "                tuple_cast(\n",
      "                    json_extract_int(x:date, '$date'),\n",
      "                    json_extract_float(x, 'amount')\n",
      "                )\n",
      "            ),\n",
      "            json_extract_array(raw:payload:after:raw_data, 'transaction_history')\n",
      "        ),\n",
      "        tuple_cast(\n",
      "            json_extract_string(raw:payload:after:raw_data:social_media_activity, 'platform'),\n",
      "            json_extract_uint(raw:payload:after:raw_data:social_media_activity, 'activity_score')\n",
      "        ),\n",
      "        tuple_cast(\n",
      "            json_extract_string(raw:payload:after:raw_data:miscellaneous, 'notes'),\n",
      "            json_extract_string(raw:payload:after:raw_data:miscellaneous, 'risk_flags')\n",
      "        )\n",
      "    ) as raw_data\n",
      "from kafka_cdc_mongo_unstructure\n",
      "where _tp_time > earliest_ts();\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **_id**: Extracted using `json_extract_string` and converted to a tuple using `tuple_cast`.\n",
      "- **customer_id**: Extracted using `json_extract_uint`.\n",
      "- **raw_data**: A complex structure that includes:\n",
      "  - **transaction_history**: An array of tuples, each containing a `date` and `amount`. The `date` is extracted as an integer and the `amount` as a float.\n",
      "  - **social_media_activity**: A tuple containing `platform` and `activity_score`.\n",
      "  - **miscellaneous**: A tuple containing `notes` and `risk_flags`.\n",
      "\n",
      "The use of `tuple_cast` ensures that the hierarchical data is correctly structured in the target stream.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "code type sql, extraction sql : select raw:payload:after from kafka_cdc_mongo_unstructure where _tp_time > earliest_ts()\n",
      "Based on the provided input data, the `after` payload is located within the `payload` field. The `after` field contains a JSON string, which we will use to generate the DDL for the ClickHouse stream. Here is the DDL based on the `after` payload:\n",
      "\n",
      "```sql\n",
      "CREATE STREAM mongo_unstructure\n",
      "(\n",
      "  `_id` tuple(`$oid` string),\n",
      "  `customer_id` uint32,\n",
      "  `raw_data` tuple(\n",
      "    `transaction_history` array(\n",
      "      tuple(\n",
      "        `date` tuple(`$date` int64),\n",
      "        `amount` float64\n",
      "      )\n",
      "    ),\n",
      "    `social_media_activity` tuple(\n",
      "      `platform` string,\n",
      "      `activity_score` uint32\n",
      "    ),\n",
      "    `miscellaneous` tuple(\n",
      "      `notes` string,\n",
      "      `risk_flags` string\n",
      "    )\n",
      "  )\n",
      ")\n",
      "```\n",
      "\n",
      "This DDL defines a stream named `mongo_unstructure` with fields corresponding to the structure of the JSON in the `after` payload. Composite types such as `tuple` and `array` are used to represent nested structures.\n",
      "Based on the provided context and the structure of the `after` payload, we can create a materialized view to extract and transform the data from the source stream into the target stream. Here is the SQL statement for the materialized view:\n",
      "\n",
      "```sql\n",
      "create materialized view if not exists extract_mongo_unstructure\n",
      "into mongo_unstructure as\n",
      "select\n",
      "    tuple_cast(json_extract_string(raw:payload:after:_id, '$oid')) as _id,\n",
      "    json_extract_uint(raw:payload:after, 'customer_id') as customer_id,\n",
      "    tuple_cast(\n",
      "        array_map(\n",
      "            x -> (\n",
      "                tuple_cast(\n",
      "                    json_extract_int(x:date, '$date'),\n",
      "                    json_extract_float(x, 'amount')\n",
      "                )\n",
      "            ),\n",
      "            json_extract_array(raw:payload:after:raw_data, 'transaction_history')\n",
      "        ),\n",
      "        tuple_cast(\n",
      "            json_extract_string(raw:payload:after:raw_data:social_media_activity, 'platform'),\n",
      "            json_extract_uint(raw:payload:after:raw_data:social_media_activity, 'activity_score')\n",
      "        ),\n",
      "        tuple_cast(\n",
      "            json_extract_string(raw:payload:after:raw_data:miscellaneous, 'notes'),\n",
      "            json_extract_string(raw:payload:after:raw_data:miscellaneous, 'risk_flags')\n",
      "        )\n",
      "    ) as raw_data\n",
      "from kafka_cdc_mongo_unstructure\n",
      "where _tp_time > earliest_ts();\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **_id**: Extracted using `json_extract_string` and converted to a tuple using `tuple_cast`.\n",
      "- **customer_id**: Extracted using `json_extract_uint`.\n",
      "- **raw_data**: A complex structure that includes:\n",
      "  - **transaction_history**: An array of tuples, each containing a `date` and `amount`. The `date` is extracted as an integer and the `amount` as a float.\n",
      "  - **social_media_activity**: A tuple containing `platform` and `activity_score`.\n",
      "  - **miscellaneous**: A tuple containing `notes` and `risk_flags`.\n",
      "\n",
      "The use of `tuple_cast` ensures that the hierarchical data is correctly structured in the target stream.\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"{\n",
    "\t\"schema\": {\n",
    "\t\t\"type\": \"struct\",\n",
    "\t\t\"fields\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
    "\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\"field\": \"before\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
    "\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\"field\": \"after\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"struct\",\n",
    "\t\t\t\t\"fields\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"array\",\n",
    "\t\t\t\t\t\t\"items\": {\n",
    "\t\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\t\"optional\": false\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"removedFields\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"name\": \"io.debezium.data.Json\",\n",
    "\t\t\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\t\t\"field\": \"updatedFields\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"array\",\n",
    "\t\t\t\t\t\t\"items\": {\n",
    "\t\t\t\t\t\t\t\"type\": \"struct\",\n",
    "\t\t\t\t\t\t\t\"fields\": [\n",
    "\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\t\t\t\"field\": \"field\"\n",
    "\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\t\t\t\"type\": \"int32\",\n",
    "\t\t\t\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\t\t\t\"field\": \"size\"\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t],\n",
    "\t\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.truncatedarray\",\n",
    "\t\t\t\t\t\t\t\"version\": 1\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"truncatedArrays\"\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"name\": \"io.debezium.connector.mongodb.changestream.updatedescription\",\n",
    "\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\"field\": \"updateDescription\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"struct\",\n",
    "\t\t\t\t\"fields\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"version\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"connector\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"name\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"ts_ms\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"name\": \"io.debezium.data.Enum\",\n",
    "\t\t\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\t\t\"parameters\": {\n",
    "\t\t\t\t\t\t\t\"allowed\": \"true,first,first_in_data_collection,last_in_data_collection,last,false,incremental\"\n",
    "\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\"default\": \"false\",\n",
    "\t\t\t\t\t\t\"field\": \"snapshot\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"db\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"sequence\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"ts_us\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"ts_ns\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"collection\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int32\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"ord\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"lsid\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"txnNumber\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\t\t\"field\": \"wallTime\"\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\"name\": \"io.debezium.connector.mongo.Source\",\n",
    "\t\t\t\t\"field\": \"source\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"field\": \"op\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"field\": \"ts_ms\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"struct\",\n",
    "\t\t\t\t\"fields\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"id\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"total_order\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"int64\",\n",
    "\t\t\t\t\t\t\"optional\": false,\n",
    "\t\t\t\t\t\t\"field\": \"data_collection_order\"\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"optional\": true,\n",
    "\t\t\t\t\"name\": \"event.block\",\n",
    "\t\t\t\t\"version\": 1,\n",
    "\t\t\t\t\"field\": \"transaction\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"optional\": false,\n",
    "\t\t\"name\": \"mongodb.lumi_data.unstructured_data.Envelope\"\n",
    "\t},\n",
    "\t\"payload\": {\n",
    "\t\t\"before\": null,\n",
    "\t\t\"after\": \"{\\\"_id\\\": {\\\"$oid\\\": \\\"67b918d21585c8c281a60f0e\\\"},\\\"customer_id\\\": 10,\\\"raw_data\\\": {\\\"transaction_history\\\": [{\\\"date\\\": {\\\"$date\\\": 1740009600000},\\\"amount\\\": 734.57},{\\\"date\\\": {\\\"$date\\\": 1739836800000},\\\"amount\\\": 631.99},{\\\"date\\\": {\\\"$date\\\": 1735862400000},\\\"amount\\\": 384.18},{\\\"date\\\": {\\\"$date\\\": 1739404800000},\\\"amount\\\": 921.92}],\\\"social_media_activity\\\": {\\\"platform\\\": \\\"LinkedIn\\\",\\\"activity_score\\\": 63},\\\"miscellaneous\\\": {\\\"notes\\\": \\\"Cell week per all power administration.\\\",\\\"risk_flags\\\": \\\"Low\\\"}}}\",\n",
    "\t\t\"updateDescription\": null,\n",
    "\t\t\"source\": {\n",
    "\t\t\t\"version\": \"3.0.6.Final\",\n",
    "\t\t\t\"connector\": \"mongodb\",\n",
    "\t\t\t\"name\": \"mongodb\",\n",
    "\t\t\t\"ts_ms\": 1740183762000,\n",
    "\t\t\t\"snapshot\": \"false\",\n",
    "\t\t\t\"db\": \"lumi_data\",\n",
    "\t\t\t\"sequence\": null,\n",
    "\t\t\t\"ts_us\": 1740183762000000,\n",
    "\t\t\t\"ts_ns\": 1740183762000000000,\n",
    "\t\t\t\"collection\": \"unstructured_data\",\n",
    "\t\t\t\"ord\": 10,\n",
    "\t\t\t\"lsid\": null,\n",
    "\t\t\t\"txnNumber\": null,\n",
    "\t\t\t\"wallTime\": 1740183762308\n",
    "\t\t},\n",
    "\t\t\"op\": \"c\",\n",
    "\t\t\"ts_ms\": 1740183762403,\n",
    "\t\t\"transaction\": null\n",
    "\t}\n",
    "}\n",
    "}\"\"\"\n",
    "\n",
    "source_stream_name = \"kafka_cdc_mongo_unstructure\"\n",
    "target_stream_name = \"mongo_unstructure\"\n",
    "\n",
    "agent = DataExtractionAgent()\n",
    "\n",
    "agent1_output, agent2_output, agent3_output = agent.pipeline(data, source_stream_name, target_stream_name)\n",
    "\n",
    "code = extract_code_blocks_with_type(agent1_output)\n",
    "print(f\"code type {code[0][0]}, extraction sql : {code[0][1]}\")\n",
    "\n",
    "print(agent2_output)\n",
    "\n",
    "print(agent3_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
