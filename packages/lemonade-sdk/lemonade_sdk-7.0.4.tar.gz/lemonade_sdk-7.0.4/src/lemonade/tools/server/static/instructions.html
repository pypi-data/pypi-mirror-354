<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lemonade Server</title>
    <link rel="icon" href="data:,">
    <link rel="stylesheet" href="/static/styles.css">
    <script>
    window.SERVER_PORT = {{SERVER_PORT}};
    </script>
    {{SERVER_MODELS_JS}}
</head>
<body>
    <nav class="navbar">
        <a href="https://github.com/lemonade-sdk/lemonade">GitHub</a>
        <a href="https://lemonade-server.ai/docs/">Docs</a>
        <a href="https://lemonade-server.ai/docs/server/server_models/">Models</a>
        <a href="https://lemonade-server.ai/docs/server/apps/">Featured Apps</a>
    </nav>
    <main class="main">
        <div class="title">üçã Lemonade Server</div>
        <div class="tab-container"> 
            <div class="tabs"> 
                <button class="tab active" id="tab-chat" onclick="showTab('chat')">LLM Chat</button> 
                <button class="tab" id="tab-models" onclick="showTab('models')">Model Management</button> 
            </div> 
            <div class="tab-content active" id="content-chat"> 
                <div class="chat-container"> 
                    <div class="chat-history" id="chat-history"></div> 
                    <div class="chat-input-row"> 
                        <select id="model-select"></select> 
                        <input type="text" id="chat-input" placeholder="Type your message..." /> 
                        <button id="send-btn">Send</button> 
                    </div> 
                </div> 
            </div> 
            <div class="tab-content" id="content-models"> 
                <div class="model-mgmt-container">
                    <div class="model-mgmt-pane">
                        <h3>Installed Models</h3>
                        <table class="model-table" id="installed-models-table">
                            <colgroup><col style="width:100%"></colgroup>
                            <tbody id="installed-models-tbody"></tbody>
                        </table>
                    </div>
                    <div class="model-mgmt-pane">
                        <h3>Suggested Models</h3>
                        <table class="model-table" id="suggested-models-table">
                            <tbody id="suggested-models-tbody"></tbody>
                        </table>
                    </div>
                </div>
            </div> 
        </div> 
    </main>
    <footer class="site-footer">
        <div class="dad-joke">When life gives you LLMs, make an LLM aide.</div>
        <div class="copyright">Copyright 2025 AMD</div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/openai@4.21.0/dist/openai.min.js"></script> 
    <script> 
    // Tab switching logic 
    function showTab(tab) { 
        document.getElementById('tab-chat').classList.remove('active'); 
        document.getElementById('tab-models').classList.remove('active'); 
        document.getElementById('content-chat').classList.remove('active'); 
        document.getElementById('content-models').classList.remove('active'); 
        if (tab === 'chat') { 
            document.getElementById('tab-chat').classList.add('active'); 
            document.getElementById('content-chat').classList.add('active'); 
        } else { 
            document.getElementById('tab-models').classList.add('active'); 
            document.getElementById('content-models').classList.add('active'); 
        } 
    }

    // Helper to get server base URL
    function getServerBaseUrl() {
        const port = window.SERVER_PORT || 8000;
        return `http://localhost:${port}`;
    }

    // Populate model dropdown from /api/v1/models endpoint
    async function loadModels() {
        try {
            const resp = await fetch(getServerBaseUrl() + '/api/v1/models');
            const data = await resp.json();
            const select = document.getElementById('model-select');
            select.innerHTML = '';
            if (!data.data || !Array.isArray(data.data)) {
                select.innerHTML = '<option>No models found (malformed response)</option>';
                return;
            }
            if (data.data.length === 0) {
                select.innerHTML = '<option>No models available</option>';
                return;
            }
            let defaultIndex = 0;
            data.data.forEach(function(model, index) {
                const modelId = model.id || model.name || model;
                const opt = document.createElement('option');
                opt.value = modelId;
                opt.textContent = modelId;
                if (modelId === 'Llama-3.2-1B-Instruct-Hybrid') {
                    defaultIndex = index;
                }
                select.appendChild(opt);
            });
            select.selectedIndex = defaultIndex;
        } catch (e) {
            const select = document.getElementById('model-select');
            select.innerHTML = `<option>Error loading models: ${e.message}</option>`;
            console.error('Error loading models:', e);
        }
    }
    loadModels();

    // Model Management Tab Logic
    async function refreshModelMgmtUI() {
        // Get installed models from /api/v1/models
        let installed = [];
        try {
            const resp = await fetch(getServerBaseUrl() + '/api/v1/models');
            const data = await resp.json();
            if (data.data && Array.isArray(data.data)) {
                installed = data.data.map(m => m.id || m.name || m);
            }
        } catch (e) {}
        // All models from server_models.json (window.SERVER_MODELS)
        const allModels = window.SERVER_MODELS || {};
        // Filter suggested models not installed
        const suggested = Object.keys(allModels).filter(
            k => allModels[k].suggested && !installed.includes(k)
        );
        // Render installed models as a table (two columns, second is invisible)
        const installedTbody = document.getElementById('installed-models-tbody');
        installedTbody.innerHTML = '';
        installed.forEach(function(mid) {
            var tr = document.createElement('tr');
            var tdName = document.createElement('td');
            tdName.textContent = mid;
            var tdEmpty = document.createElement('td');
            tdEmpty.style.width = '0';
            tdEmpty.style.padding = '0';
            tdEmpty.style.border = 'none';
            tr.appendChild(tdName);
            tr.appendChild(tdEmpty);
            installedTbody.appendChild(tr);
        });
        // Render suggested models as a table
        const suggestedTbody = document.getElementById('suggested-models-tbody');
        suggestedTbody.innerHTML = '';
        suggested.forEach(mid => {
            const tr = document.createElement('tr');
            const tdName = document.createElement('td');
            tdName.textContent = mid;
            tdName.style.paddingRight = '1em';
            tdName.style.verticalAlign = 'middle';
            const tdBtn = document.createElement('td');
            tdBtn.style.width = '1%';
            tdBtn.style.verticalAlign = 'middle';
            const btn = document.createElement('button');
            btn.textContent = '+';
            btn.title = 'Install model';
            btn.onclick = async function() {
                btn.disabled = true;
                btn.textContent = 'Installing...';
                btn.classList.add('installing-btn');
                try {
                    await fetch(getServerBaseUrl() + '/api/v1/pull', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ model_name: mid })
                    });
                    await refreshModelMgmtUI();
                    await loadModels(); // update chat dropdown too
                } catch (e) {
                    btn.textContent = 'Error';
                }
            };
            tdBtn.appendChild(btn);
            tr.appendChild(tdName);
            tr.appendChild(tdBtn);
            suggestedTbody.appendChild(tr);
        });
    }
    // Initial load
    refreshModelMgmtUI();
    // Optionally, refresh when switching to the tab
    document.getElementById('tab-models').addEventListener('click', refreshModelMgmtUI);

    // Chat logic (streaming with OpenAI JS client placeholder)
    const chatHistory = document.getElementById('chat-history');
    const chatInput = document.getElementById('chat-input');
    const sendBtn = document.getElementById('send-btn');
    const modelSelect = document.getElementById('model-select');
    let messages = [];

    function appendMessage(role, text) {
        const div = document.createElement('div');
        div.className = 'chat-message ' + role;
        // Add a bubble for iMessage style
        const bubble = document.createElement('div');
        bubble.className = 'chat-bubble ' + role;
        bubble.innerHTML = text;
        div.appendChild(bubble);
        chatHistory.appendChild(div);
        chatHistory.scrollTop = chatHistory.scrollHeight;
    }

    async function sendMessage() {
        const text = chatInput.value.trim();
        if (!text) return;
        appendMessage('user', text);
        messages.push({ role: 'user', content: text });
        chatInput.value = '';
        sendBtn.disabled = true;
        // Streaming OpenAI completions (placeholder, adapt as needed)
        let llmText = '';
        appendMessage('llm', '...');
        const llmDiv = chatHistory.lastChild.querySelector('.chat-bubble.llm');
        try {
            // Use the correct endpoint for chat completions
            const resp = await fetch(getServerBaseUrl() + '/api/v1/chat/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: modelSelect.value,
                    messages: messages,
                    stream: true
                })
            });
            if (!resp.body) throw new Error('No stream');
            const reader = resp.body.getReader();
            let decoder = new TextDecoder();
            llmDiv.textContent = '';
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                if (chunk.trim() === 'data: [DONE]' || chunk.trim() === '[DONE]') continue;
                // Try to extract the content from the OpenAI chunk
                const match = chunk.match(/"content"\s*:\s*"([^"]*)"/);
                if (match && match[1]) {
                    llmText += match[1];
                    llmDiv.textContent = llmText;
                }
            }
            messages.push({ role: 'assistant', content: llmText });
        } catch (e) {
            llmDiv.textContent = '[Error: ' + e.message + ']';
        }
        sendBtn.disabled = false;
    }
    sendBtn.onclick = sendMessage;
    chatInput.addEventListener('keydown', function(e) {
        if (e.key === 'Enter') sendMessage();
    });
    </script>
</body>
</html>
