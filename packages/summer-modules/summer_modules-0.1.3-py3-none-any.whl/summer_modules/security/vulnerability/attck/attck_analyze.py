import httpx
from bs4 import BeautifulSoup
from pathlib import Path
from summer_modules.logger import init_and_get_logger
import json
from time import sleep
from typing import Union
from summer_modules.security.vulnerability.attck.excel_operation import (
    ATTCKExcelOperation,
    generate_attck_matrix_info_excel_with_attck_matrix_techniques_info,
)

CURRENT_DIR = Path(__file__).resolve().parent
HTML_BASE_DIR = CURRENT_DIR / "data/attck_html/"
ATTCK_MAIN_PAGE_URL = "https://attack.mitre.org"

logger = init_and_get_logger(CURRENT_DIR, "attck_analyze")


def determine_url_page_type_info(url: str) -> Union[str, list]:
    if url in [ATTCK_MAIN_PAGE_URL, f"{ATTCK_MAIN_PAGE_URL}/"]:
        return "ATTCKMainPage"
    elif url.startswith("https://attack.mitre.org/techniques/"):
        # 从 url 中提取 technique 的编号
        technique_url_split = url.split("/")
        # 如果 url 以 / 结尾，则取倒数第 2，3 个元素进行判断
        if url.endswith("/"):
            last_1 = technique_url_split[-2]
            last_2 = technique_url_split[-3]
        # 如果 url 不以 / 结尾，则取倒数第 1，2 个元素进行判断
        else:
            last_1 = technique_url_split[-1]
            last_2 = technique_url_split[-2]
        # 如果 last_2 是 techniques 的话说明当前 url 是 super technique 的 url
        if last_2 == "techniques":
            return ["SuperTechnique", last_1]
        # 如果 last_2 不是 techniques 的话说明当前 url 是 sub technique 的 url，此时需要用 last2.last1 作为文件名进行索引
        else:
            return ["SubTechnique", last_2, last_1]
    else:
        logger.error(f"未知的 url 类型 ---- {url}")
        return "UnknownPageType"


def generate_local_html_file_path_from_url(url: str) -> Path | None:
    """根据 url 生成本地 HTML 文件路径"""
    # 判断当前 url 类型
    url_page_type_info = determine_url_page_type_info(url)
    if url_page_type_info == "UnknownPageType":
        logger.error(f"determine_url_page_type_info 获取到未知的 url 类型 ---- {url}")
        return None
    elif url_page_type_info == "ATTCKMainPage":
        return HTML_BASE_DIR / "ATTCKMainPage.html"
    elif url_page_type_info[0] == "SuperTechnique":
        super_technique_id = url_page_type_info[1]
        return HTML_BASE_DIR / f"{super_technique_id}/{super_technique_id}.html"
    elif url_page_type_info[0] == "SubTechnique":
        super_technique_id = url_page_type_info[1]
        sub_technique_id = url_page_type_info[2]
        return (
            HTML_BASE_DIR
            / f"{super_technique_id}/{super_technique_id}.{sub_technique_id}.html"
        )
    else:
        logger.error(f"未知的 url 类型 ---- {url}")
        return None


def is_url_html_local_saved(url: str) -> bool:
    """判断 url 对应的 html 是否已经本地保存
    :param url: url
    :return: True or False
    """
    if local_html_file_path := generate_local_html_file_path_from_url(url):
        logger.debug("此url合理, 可生成相应的本地文件路径")
        if local_html_file_path.exists():
            logger.debug(f"本地 HTML 文件 {local_html_file_path} 已经存在")
            return True
    logger.info(f"本地 HTML 文件 {local_html_file_path} 不存在")
    return False


def write_response_to_local_html_file(
    response: httpx.Response, url: str, force_overwrite: bool = True
) -> None:
    """将 response 写入到本地 HTML_BASE_DIR 目录下
    :param response: response
    :param url: url
    :param force_overwrite: 是否强制覆盖
    """
    local_html_file_path = generate_local_html_file_path_from_url(url)
    if not local_html_file_path:
        logger.error(f"生成本地 HTML 文件路径失败 ---- {url}")
        return
    if local_html_file_path.exists():
        if not force_overwrite:
            logger.info(f"本地 HTML 文件 {local_html_file_path} 已经存在，不强制覆盖")
            return
        else:
            logger.info(f"本地 HTML 文件 {local_html_file_path} 已经存在，强制覆盖")
    local_html_file_path.parent.mkdir(parents=True, exist_ok=True)
    with local_html_file_path.open("w", encoding="utf-8") as f:
        f.write(response.text)
    logger.info(f"将 response 写入到本地 HTML 文件 {local_html_file_path} 中")


def get_local_html_file_content(url: str) -> str | None:
    """获取本地 HTML 文件的内容
    :param url: url
    :return: HTML 文件的内容
    """
    local_html_file_path = generate_local_html_file_path_from_url(url)
    if not local_html_file_path:
        logger.error(f"生成本地 HTML 文件路径失败 ---- {url}")
        return None
    if not local_html_file_path.exists():
        logger.error(f"本地 HTML 文件 {local_html_file_path} 不存在")
        return None
    with local_html_file_path.open("r", encoding="utf-8") as f:
        return f.read()


def get_response_from_url(
    url: str, enable_local_search: bool = True
) -> httpx.Response | str | None:
    """获取 url 的响应, 如果超时则等待 5s 后重试
    :param url: url
    :param enable_local_search: 是否启用本地HTML索引
    :return: 响应
    """
    force_overwrite = True
    if enable_local_search:
        force_overwrite = False
        if is_url_html_local_saved(url):
            return get_local_html_file_content(url)
    # User_Agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"
    User_Agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"
    max_retries = 5
    for _ in range(max_retries):
        try:
            response = httpx.get(
                url, headers={"User-Agent": User_Agent}, follow_redirects=True
            )
            write_response_to_local_html_file(
                response, url, force_overwrite=force_overwrite
            )
            return response
        except (httpx.ConnectTimeout, httpx.ReadTimeout):
            logger.error(f"请求 {url} 超时，等待 5s 后重试")
            sleep(5)
        except Exception as e:
            logger.error(f"请求 {url} 失败，异常: {e}")
            return None
    logger.error(f"请求 {url} 超过重试次数")
    return None


def analyze_attck_main_page_get_matrix_table_info(
    enable_local_search: bool = True,
) -> dict:
    """解析 https://attack.mitre.org/ 主页，获取矩阵表格信息"""
    # 由于 get_response_from_url 可能返回的是 httpx.Response 也可能是从本地读取的 HTML 文件内容，所以这里需要判断一下
    response = get_response_from_url(
        url=ATTCK_MAIN_PAGE_URL, enable_local_search=enable_local_search
    )
    soup = None
    if isinstance(response, str):
        soup = BeautifulSoup(response, "html.parser")
    elif isinstance(response, httpx.Response):
        soup = BeautifulSoup(response.text, "html.parser")
    else:
        logger.error(
            f"获取 {ATTCK_MAIN_PAGE_URL} 的响应失败，返回类型为 {type(response)}"
        )

    # 解析 <table class="matrix side"> 的表格元素
    ## 读取第一个 <table class="matrix side"> 元素即为 ATTCK 矩阵表格信息
    if not soup:
        logger.error("解析 ATTCK 主页失败， 没有找到 soup")
        return {}
    matrix_table = soup.find_all("table", class_="matrix side")[0]
    matrix_table_info = {}

    thead = matrix_table.find("thead") # type: ignore

    if not thead:
        logger.error("解析 tatic 与 technique 数量信息失败， 没有找到 thead")
        return matrix_table_info

    # thead 中有两条 tr，第一条为 tatic 信息， 第二条为 tatic 中的 technique 数量信息
    head_tr_list = thead.find_all("tr") # type: ignore
    if len(head_tr_list) < 2:
        logger.error("解析 tatic 与 technique 数量信息失败， 没有找到足够的 tr")
        return matrix_table_info
    tactics_info = head_tr_list[0]
    tactics_techniques_num_info = head_tr_list[1]
    # tactics_info 这个 tr 包含了多个 td，每个 td 代表一个 tactic， td 中有一个 a 标签，取其中的 href 与 url 进行拼接形成此 tatic 具体信息页面的 url，取 a 标签中的 text 作为 tactic 的名称， 取 a 标签中的 data-original-title 作为 tactic 的编号
    tactics_td_list = tactics_info.find_all("td") # type: ignore
    tactics_techniques_num_td_list = tactics_techniques_num_info.find_all("td") # type: ignore
    tactics_data = []
    for index, td in enumerate(tactics_td_list):
        tactic_data = {}
        a = td.find("a")
        if a:
            tactic_data["name"] = a.get_text(strip=True)
            tactic_data["url"] = ATTCK_MAIN_PAGE_URL + a.get("href")
            tactic_data["id"] = a.get("title") or "未知编号"
            if index < len(tactics_techniques_num_td_list):
                tactic_techniques_num_info = tactics_techniques_num_td_list[
                    index
                ].get_text(strip=True)
                # 从 tactic_techniques_num_info 中提取技术数量数值
                tactic_data["techniques_num"] = int(
                    tactic_techniques_num_info.split()[0]
                )
            tactics_data.append(tactic_data)

    # 获取 techniques_data 信息
    ## 从 matrix_table 中获取 tbody 元素
    tbody = matrix_table.find("tbody")
    if not tbody:
        logger.error("解析 techniques 信息失败， 没有找到 tbody")
        return matrix_table_info
    ## 此 tbody 只有一个 tr。 tr 中有多个 <td class="tactic">， 其中每个只有一个 table 元素代表 techniques 信息
    body_tr = tbody.find("tr")
    if not body_tr:
        logger.error("解析 techniques 信息失败， 没有找到 tr")
        return matrix_table_info
    td_list = body_tr.find_all("td", class_="tactic")

    for index, td in enumerate(td_list):
        sub_table = td.find("table")
        if not sub_table:
            logger.error("没有从 techniques tr-td 中找到 table 元素")
            return matrix_table_info
        ## subtable 中仅包含一个 tbody, 这个 tdoby 中包含若干个 <tr class="technique-row">， 每个 <tr class="technique-row">都代表一个一级 technique
        ## 统计当前 table 中的一级 technique 数量， 对应的 tactics_data 中的索引为 index，与其中的 techniques_num 进行比对，如果不同则记录信息
        current_table_contain_techniques_num = len(sub_table.find_all("tr"))
        technique_rows = sub_table.find_all("tr", class_="technique-row")
        current_table_contain_techniques_num = len(technique_rows)
        if (
            current_table_contain_techniques_num
            != tactics_data[index]["techniques_num"]
        ):
            logger.error(
                f"tactic: {tactics_data[index]['name']} 中的 techniques 数量与实际数量不符"
            )

        ## 遍历 technique_rows，获取每个 technique 的信息
        tactics_data[index]["techniques_data"] = {}
        for technique_row in technique_rows:
            technique_data = {}
            # 第一个 td 没有 class 标签，其中包含了一级 technique 的信息
            supertechnique_td = technique_row.find("td")
            ## 这个 td 中只有一个 table 元素，其中包含了一级 technique 的信息
            supertechnique_td_table = supertechnique_td.find(
                "table", class_="supertechnique"
            )
            ## 如果没有 table 元素，则说明此 technique 为一个一级 technique，没有子技术
            if not supertechnique_td_table:
                supertechnique_td_a = supertechnique_td.find("a")
                technique_data["super_technique_name"] = supertechnique_td_a.get_text(
                    strip=True
                )
                technique_data["super_technique_url"] = (
                    ATTCK_MAIN_PAGE_URL + supertechnique_td_a.get("href")
                )
                technique_data["super_technique_id"] = (
                    supertechnique_td_a.get("title") or "未知编号"
                )
                technique_data["subtechniques"] = None
                technique_data["super_technique_contains_subtechnique_num"] = 0
                tactics_data[index]["techniques_data"][
                    f"{technique_data['super_technique_id']}-{technique_data['super_technique_name']}"
                ] = technique_data
                continue
            ### 这个 table 中只有一层 tbody-tr-td-div-a 结构，其中 a 标签中包含了一级 technique 的名称与链接
            supertechnique_td_table_tbody_tr_td_div_a = (
                supertechnique_td_table.find("tr").find("td").find("div").find("a")
            )

            # 取 a 标签的 text 作为 technique 的名称， 取 a 标签的 href 与 url 进行拼接形成此 technique 具体信息页面的 url，取 a 标签中的 title 作为 technique 的编号
            ## 取到的 text 为 name(num) 的形式则表示此 supertechnique 包含 num 个 technique，如果没有 (num) 则表示只有一个 supertechnique
            super_technique_name_num = (
                supertechnique_td_table_tbody_tr_td_div_a.get_text(strip=True)
            )
            super_technique_name = super_technique_name_num.split("(")[0]
            super_technique_contains_subtechnique_num = (
                super_technique_name_num.split("(")[1].split(")")[0]
                if "(" in super_technique_name_num
                else 0
            )
            super_technique_url = (
                ATTCK_MAIN_PAGE_URL
                + supertechnique_td_table_tbody_tr_td_div_a.get("href")
            )
            super_technique_id = (
                supertechnique_td_table_tbody_tr_td_div_a.get("title") or "未知编号"
            )
            technique_data["super_technique_name"] = super_technique_name
            technique_data["super_technique_url"] = super_technique_url
            technique_data["super_technique_id"] = super_technique_id
            technique_data["super_technique_contains_subtechnique_num"] = (
                super_technique_contains_subtechnique_num
            )

            # 如果此 supertechnique 没有子技术，则直接将此 supertechnique 信息存储到 techniques_data 中
            ## PS：理论上这种情况应该不会出现，因为如果没有子技术的话这里就没有 table， 进入不了循环
            if super_technique_contains_subtechnique_num == 0:
                logger.error(
                    f"supertechnique: {super_technique_name} 没有子技术, 本不应该进入此分支"
                )
                technique_data["subtechniques"] = None
                continue

            # 如果此 supertechnique 包含子技术，则继续解析子技术
            technique_data["subtechniques"] = {}
            ## technique_row 的第 2 个 td 是一个侧边菜单按钮的样式， 不用处理
            ## technique_row 的第 3 个 td 为 <td class="subtechniques-td">，其中包含了子技术的信息
            subtechniques_td = technique_row.find("td", class_="subtechniques-td")
            ### 这个 td 中只有一个 div 元素，其中包含了子技术的信息
            subtechniques_td_div = subtechniques_td.find("div")
            #### 这个 div 中包含 super_technique_contains_subtechnique_num 个 <div class="subtechnique">- <div class="technique-cell ">-a 元素，每个代表一个子技术
            subtechniques_td_div_list = subtechniques_td_div.find_all(
                "div", class_="subtechnique"
            )
            for subtechnique_div in subtechniques_td_div_list:
                subtechnique_a = subtechnique_div.find("a")
                subtechnique_data = {"name": subtechnique_a.get_text(strip=True)}
                subtechnique_data["url"] = ATTCK_MAIN_PAGE_URL + subtechnique_a.get(
                    "href"
                )
                subtechnique_data["id"] = subtechnique_a.get("title") or "未知编号"
                technique_data["subtechniques"][
                    f"{subtechnique_data['id']}.{subtechnique_data['name']}"
                ] = subtechnique_data
            tactics_data[index]["techniques_data"][
                f"{technique_data['super_technique_id']}-{technique_data['super_technique_name']}"
            ] = technique_data
    # 解析 tactics_data, 将其 id-name 作为 key，其本身作为 value 存储到 matrix_table_info 中
    for tactic in tactics_data:
        matrix_table_info[tactic["id"] + "-" + tactic["name"]] = tactic

    return matrix_table_info


def write_dict_to_local_json_file(src_dict: dict, tar_json_filepath: Path) -> None:
    """将 dict 写入到本地 json 文件"""
    with tar_json_filepath.open("w", encoding="utf-8") as f:
        json.dump(src_dict, f, ensure_ascii=False, indent=4)
    # 顺便再写一行紧凑的 json 文件
    with tar_json_filepath.with_suffix(".min.json").open("w", encoding="utf-8") as f:
        json.dump(src_dict, f, ensure_ascii=False)


def analyze_attck_technique_page_get_info(
    attck_technique_page_url: str, enable_local_search: True
) -> dict:
    """解析 ATTCK 技术页面，获取技术信息返回一个技术信息 dict
    :param attck_technique_page_url: ATTCK 技术页面的 url

    :return: 技术信息 dict
    """
    # 如果 enable_local_search 为 True， 则尝试从本地读取 HTML 文件
    response = get_response_from_url(
        url=attck_technique_page_url, enable_local_search=enable_local_search
    )
    if isinstance(response, str):
        soup = BeautifulSoup(response, "html.parser")
    else:
        soup = BeautifulSoup(response.text, "html.parser")
        # 如果状态码不是 200， 则返回空字典
        if response.status_code != 200:
            logger.error(
                f"请求 {attck_technique_page_url} 失败，状态码为 {response.status_code}"
            )
            return {}

    technique_info = {}

    # <h1> 标签中包含了技术名称
    h1 = soup.find("h1")
    if not h1:
        logger.error("解析技术名称失败， 没有找到 h1")
        return technique_info
    technique_info["name"] = h1.get_text(strip=True)

    # <div class="description-body"> 中的内容为技术的描述
    description_body = soup.find("div", class_="description-body")
    paragraphs = description_body.find_all("p")
    technique_info["description"] = "\n\n".join(
        p.get_text(strip=True) for p in paragraphs
    )
    if not description_body:
        logger.error("解析技术描述失败， 没有找到 description-body")
        return technique_info
    # logger.info(f"技术信息:\n{technique_info["description"] }")

    examples_h2 = soup.find("h2", id="examples")
    mitigations_h2 = soup.find("h2", id="mitigations")
    detection_h2 = soup.find("h2", id="detection")
    references_h2 = soup.find("h2", id="references")

    #####################################################################  解析 Examples 信息 #####################################################################
    # <h2 class="pt-3" id="examples"> 后面只有一个  <div class="tables-mobile"> 元素（这个div元素不在 h2 的嵌套层中）， 其中只有一个 <table class="table table-bordered table-alternate mt-2"> 元素，其中包含了示例信息
    technique_info["examples"] = {}
    if examples_h2 := soup.find("h2", id="examples"):
        # 查找 examples_h2 到 detection_h2 之间是否有 div
        next_element = examples_h2.find_next_sibling()
        while next_element != detection_h2:
            if next_element.name == "div":
                examples_div = next_element
                break
            next_element = next_element.find_next_sibling()
        if not examples_div:
            logger.error(
                f"解析示例 {attck_technique_page_url} 信息失败， 没有找到 examples div"
            )
            return technique_info
        examples_table = examples_div.find("table")
        if not examples_table:
            logger.error(
                f"解析示例 {attck_technique_page_url} 信息失败， 没有找到 examples table"
            )
            return technique_info
        # 表格有三列 ID，Name，Description，这里新建个列表来存储这个字典列表
        examples_table_tbody = examples_table.find("tbody")
        # 遍历 tbody 中的 tr，每个 tr 代表一个示例
        for tr in examples_table_tbody.find_all("tr"):
            # 每个 tr 中有三个 td，分别代表 ID，Name，Description
            td_list = tr.find_all("td")
            # ID 为 a 标签，取 a 标签中的 text 作为示例的 ID， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL 进行拼接形成此示例具体信息页面的 url
            example_info_id_td = td_list[0]
            example_info = {
                "id": {"name": example_info_id_td.find("a").get_text(strip=True)}
            }
            example_info["id"]["url"] = ATTCK_MAIN_PAGE_URL + example_info_id_td.find(
                "a"
            ).get("href")
            # Name 为 a 标签，取 a 标签中的 text 作为示例的 Name， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL 进行拼接形成此示例具体信息页面的 url
            example_info["name"] = {}
            example_info_name_td = td_list[1]
            example_info["name"]["name"] = example_info_name_td.find("a").get_text(
                strip=True
            )
            example_info["name"]["url"] = (
                ATTCK_MAIN_PAGE_URL + example_info_name_td.find("a").get("href")
            )
            # Description 为文本，取 td 中的 text 作为示例的 Description
            example_info["description"] = td_list[2].get_text(strip=True)
            # 以 example_info["id"]["name"] 作为 key， example_info 作为 value 存储到  technique_info["examples"] 中
            technique_info["examples"][example_info["id"]["name"]] = example_info
    else:
        # 有的 technique 确实没有 examples
        logger.info(f"技术 {attck_technique_page_url} 没有 examples")
        technique_info["examples"] = None

    #####################################################################  解析 mitigation 信息 #####################################################################
    # <h2 class="pt-3" id="mitigations"> 后面只有一个  <div class="tables-mobile"> 元素（这个div元素不在 h2 的嵌套层中）， 其中只有一个 <table class="table table-bordered table-alternate mt-2"> 元素，其中包含了缓解措施信息
    if not mitigations_h2:
        logger.info(f"当前技术 {attck_technique_page_url} 没有缓解措施")
        technique_info["mitigations"] = None
    else:
        next_element = mitigations_h2.find_next_sibling()
        mitigations_div = None
        mitigations_p = None
        while next_element != detection_h2:
            if next_element.name == "div":
                mitigations_div = next_element
                break
            if next_element.name == "p":
                mitigations_p = next_element
                break
            next_element = next_element.find_next_sibling()
        if not mitigations_div and not mitigations_p:
            logger.error(
                f"解析缓解措施 {attck_technique_page_url} 信息失败， 没有找到 mitigations div 或 mitigations p"
            )
            return technique_info
        elif mitigations_p:
            mitigations_info = "\n\n".join(
                p.get_text(strip=True) for p in mitigations_p.find_all("p")
            )
            technique_info["mitigations"] = mitigations_info
        else:
            # 判断当前 div 是否有 _class， 如果有且为 tables-mobile 则说明是表格形式的缓解措施，如果没有则是 p 标签形式的缓解措施， 否则报错
            mitigations_div_class = mitigations_div.get("class")
            if not mitigations_div_class:
                mitigations_info = "\n\n".join(
                    p.get_text(strip=True) for p in mitigations_div.find_all("p")
                )
                technique_info["mitigations"] = mitigations_info
            elif "tables-mobile" in mitigations_div_class:
                mitigations_table = mitigations_div.find("table")
                if not mitigations_table:
                    logger.error(
                        f"解析缓解措施 {attck_technique_page_url} 信息失败， 没有找到 mitigations table"
                    )
                    return technique_info
                # 表格有三列 ID，Mitigation，Description，这里新建个列表来存储这个字典列表
                mitigations_table_info = []
                mitigations_table_tbody = mitigations_table.find("tbody")
                # 遍历 tbody 中的 tr，每个 tr 代表一个缓解措施
                for tr in mitigations_table_tbody.find_all("tr"):
                    # 每个 tr 中有三个 td，分别代表 ID，Mitigation，Description
                    td_list = tr.find_all("td")
                    mitigation_info = {}
                    # ID 为 a 标签，取 a 标签中的 text 作为缓解措施的 ID， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL 进行拼接形成此缓解措施具体信息页面的 url
                    mitigation_info_id_td = td_list[0]
                    mitigation_info["id"] = {
                        "name": mitigation_info_id_td.find("a").get_text(strip=True)
                    }
                    mitigation_info["id"]["url"] = (
                        ATTCK_MAIN_PAGE_URL
                        + mitigation_info_id_td.find("a").get("href")
                    )
                    # Mitigation 为 a 标签，取 a 标签中的 text 作为缓解措施的 Mitigation， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL进行拼接形成此缓解措施具体信息页面的 url
                    mitigation_info["mitigation"] = {}
                    mitigation_info_mitigation_td = td_list[1]
                    mitigation_info["mitigation"]["name"] = (
                        mitigation_info_mitigation_td.find("a").get_text(strip=True)
                    )
                    mitigation_info["mitigation"]["url"] = (
                        ATTCK_MAIN_PAGE_URL
                        + mitigation_info_mitigation_td.find("a").get("href")
                    )
                    # Description 为文本，取 td 中的 text 作为缓解措施的 Description
                    mitigation_info["description"] = td_list[2].get_text(strip=True)
                    mitigations_table_info.append(mitigation_info)
                technique_info["mitigations"] = mitigations_table_info
            else:
                logger.error(
                    f"解析缓解措施 {attck_technique_page_url} 信息失败， mitigations div 有未知的 class"
                )

    #####################################################################  解析 Detection 信息 #####################################################################
    # <h2 class="pt-3" id="detection"> 后面只有一个  <div class="tables-mobile"> 元素（这个div元素不在 h2 的嵌套层中）， 其中只有一个 <table class="table datasources-table table-bordered"> 元素，其中包含了检测信息
    if not detection_h2:
        logger.info(f"当前技术 {attck_technique_page_url} 没有检测信息")
        technique_info["detection"] = None
        return technique_info

    # 如果没有 ddetection_h2 的话，当前技术就构造完成并且返回了，进入到下面这里说明有 detection_h2
    next_element = detection_h2.find_next_sibling()
    while next_element != references_h2:
        if next_element.name == "div":
            detection_div = next_element
            break
        next_element = next_element.find_next_sibling()
    if not detection_div:
        logger.error(
            f"解析检测 {attck_technique_page_url} 信息失败， 没有找到 detection div"
        )
        return technique_info
    # 判断当前 div 是否有 _class， 如果有且为 tables-mobile 则说明是表格形式的检测，如果没有则是 p 标签形式的检测， 否则报错
    detection_div_class = detection_div.get("class")
    if not detection_div_class:
        detection_info = "\n\n".join(
            p.get_text(strip=True) for p in detection_div.find_all("p")
        )
        technique_info["detection"] = detection_info
    elif "tables-mobile" in detection_div_class:
        detection_table = detection_div.find("table")
        if not detection_table:
            logger.error(
                f"解析检测 {attck_technique_page_url} 信息失败， 没有找到 detection table"
            )
            return technique_info
        # 表格有 4 列 ID, Data Source, Data Component, Detects, 这里新建个列表来存储这个字典列表
        detection_table_info = []
        detection_table_tbody = detection_table.find("tbody")
        # 遍历 tbody 中的 <tr class="datasource"，每个 <tr class="datasource" 代表一个检测信息
        for tr in detection_table_tbody.select("tr.datasource:not(.datacomponent)"):
            # 每个 tr 中有 4 个 td，分别代表 ID, Data Source, Data Component, Detects
            td_list = tr.find_all("td")
            detection_info = {}
            # ID 为 a 标签，取 a 标签中的 text 作为检测信息的 ID， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL 进行拼接形成此检测信息具体信息页面的 url
            detection_info_id_td = td_list[0]
            detection_info["id"] = {}
            detection_info["id"]["name"] = detection_info_id_td.find("a").get_text(
                strip=True
            )
            detection_info["id"]["url"] = (
                ATTCK_MAIN_PAGE_URL + detection_info_id_td.find("a").get("href")
            )
            # Data Source 为 a 标签，取 a 标签中的 text 作为检测信息的 Data Source， 取 a 标签中的 href 与 ATTCK_MAIN_PAGE_URL 进行拼接形成此检测信息具体信息页面的 url
            detection_info["data_source"] = {}
            detection_info_data_source_td = td_list[1]
            detection_info["data_source"]["name"] = detection_info_data_source_td.find(
                "a"
            ).get_text(strip=True)
            detection_info["data_source"]["url"] = (
                ATTCK_MAIN_PAGE_URL
                + detection_info_data_source_td.find("a").get("href")
            )
            # Data Component 可能不止一个，需要判断当前 <tr class="datasource" 后续是否有 <tr class="datacomponent datasource"， 如果有的话则后续的这些 <tr class="datacomponent datasource" 也属于当前 <tr class="datasource" 的 Data Component
            data_component = []
            # 优先解析当前 <tr class="datasource" 中的 Data Component， 这是个 a 标签，取 a 标签中的 text 作为检测信息的 Data Component
            detection_info_data_component_td = td_list[2]
            data_component_info = {}
            data_component_info["name"] = detection_info_data_component_td.find(
                "a"
            ).get_text(strip=True)
            data_component_info["url"] = (
                ATTCK_MAIN_PAGE_URL
                + detection_info_data_component_td.find("a").get("href")
            )
            # Detects 是跟着 Data Componet 的
            data_component_info["detects"] = td_list[3].get_text(strip=True)
            data_component.append(data_component_info)

            # 判断当前 <tr class="datasource 后续是否有 <tr class="datacomponent datasource"， 如果有的话则后续的这些 <tr class="datacomponent datasource" 也属于当前 <tr class="datasource" 的 Data Component
            data_component_tr_list = tr.find_next_siblings("tr", class_="datacomponent")
            for data_component_tr in data_component_tr_list:
                # 每个 tr 中有 4 个 td，分别代表 ID, Data Source, Data Component, Detects, 当前，前两个 td 为空，只有后两个 td 有内容
                data_component_td_list = data_component_tr.find_all("td")
                data_component_info = {}
                data_component_info["name"] = (
                    data_component_td_list[2].find("a").get_text(strip=True)
                )
                data_component_info["url"] = (
                    ATTCK_MAIN_PAGE_URL
                    + data_component_td_list[2].find("a").get("href")
                )
                data_component_info["detects"] = data_component_td_list[3].get_text(
                    strip=True
                )
                data_component.append(data_component_info)
            detection_info["data_component"] = data_component
            detection_table_info.append(detection_info)
        technique_info["detection"] = detection_table_info
    else:
        logger.error(
            f"解析检测 {attck_technique_page_url} 信息失败， detection div 有未知的 class"
        )
    return technique_info


def iterate_attck_matrix_info_techniques_generate_techniques_info(
    attck_matrix_info: dict, enable_local_search: True
) -> dict:
    """遍历 ATTCK 矩阵信息，生成技术信息"""
    for tactic_key, tactic_value in attck_matrix_info.items():
        techniques_data = tactic_value.get("techniques_data")
        if not techniques_data:
            logger.error(f"tactic: {tactic_value['name']} 中没有 techniques_data")
            # 完全没有 techniques_data 的话，直接跳过，反正也没对原 dict 进行修改
            continue
        new_super_techniques_data = {}
        for super_technique in techniques_data:
            super_technique_data = techniques_data.get(super_technique)
            super_technique_url = super_technique_data.get("super_technique_url")
            if not super_technique_url:
                logger.error(
                    f"tactic: {tactic_value['name']} ---- technique: {super_technique_data['name']} 中没有 url"
                )
                continue
            super_technique_info = analyze_attck_technique_page_get_info(
                super_technique_url, enable_local_search=enable_local_search
            )
            super_technique_data["info"] = super_technique_info

            # 遍历子技术
            subtechniques_data = super_technique_data.get("subtechniques")
            if not subtechniques_data:
                logger.info(
                    f"tactic: {tactic_value['name']} technique: {super_technique_data['super_technique_name']} 中没有 subtechniques"
                )
                new_super_techniques_data[super_technique] = super_technique_data
                continue
            for subtechnique in subtechniques_data:
                subtechnique_data = subtechniques_data.get(subtechnique)
                subtechnique_url = subtechnique_data.get("url")
                if not subtechnique_url:
                    logger.error(
                        f"tactic: {tactic_value['name']} ---- technique: {super_technique_data['super_technique_name']} ---- subtechnique: {subtechnique_data['name']} 中没有 url"
                    )
                    continue
                subtechnique_info = analyze_attck_technique_page_get_info(
                    subtechnique_url, enable_local_search=enable_local_search
                )
                subtechnique_data["info"] = subtechnique_info
                super_technique_data["subtechniques"][subtechnique] = subtechnique_data
                # 休眠 1 秒
                if enable_local_search and not is_url_html_local_saved(
                    subtechnique_url
                ):
                    sleep(1)
            new_super_techniques_data[super_technique] = super_technique_data
        tactic_value["techniques_data"] = new_super_techniques_data
        attck_matrix_info[tactic_key] = tactic_value
    return attck_matrix_info


def analyze_attck_info(
    attck_matrix_info_json_filepath: Path,
    attck_matrix_info_with_techniques_info_json_filepath: Path,
) -> dict:
    """解析 ATTCK 主页，获取 ATTCK 矩阵信息，返回最终生成的 ATTCK 矩阵信息 dict"""
    try:
        attck_matrix_info = analyze_attck_main_page_get_matrix_table_info(
            enable_local_search=True
        )

        try:
            write_dict_to_local_json_file(
                attck_matrix_info, attck_matrix_info_json_filepath
            )
        except Exception as e:
            logger.error(f"写入 ATTCK 矩阵信息失败， 错误信息为: {e}")
            return {}

        # test_technique_url = "https://attack.mitre.org/techniques/T1595/"
        # analyze_attck_technique_page_get_info(test_technique_url)

        attck_matrix_info = (
            iterate_attck_matrix_info_techniques_generate_techniques_info(
                attck_matrix_info, enable_local_search=True
            )
        )
        write_dict_to_local_json_file(
            attck_matrix_info, attck_matrix_info_with_techniques_info_json_filepath
        )
        return attck_matrix_info
    except Exception as e:
        logger.error(f"解析 ATTCK 信息失败， 错误信息为: {e}")
        return {}


class TestAnalyzeATTCKInfo:

    def __init__(self, github_token: str, deepseek_api_key: str):
        self.github_token = github_token
        self.attck_excel_opertaion = ATTCKExcelOperation(
            github_token=self.github_token, deepseek_api_key=deepseek_api_key
        )

    def test_analyze_attck_info(self):
        ATTCK_MATRIX_INFO_JSON_FILEPATH = CURRENT_DIR / "data/attck_matrix_info.json"
        ATTCK_MATRIX_INFO_ALL_IN_ONE = (
            CURRENT_DIR / "data/attck_matrix_info_all_in_one.json"
        )
        ATTCK_MATRIX_INFO_EXCEL_FILEPATH = CURRENT_DIR / "data/attck_matrix_info.xlsx"

        # 是否从本地读取 ATTCK 信息
        is_excel_generate_read_local_data = True
        # is_excel_generate_read_local_data = False

        if not is_excel_generate_read_local_data:
            attck_matrix_info = analyze_attck_info(
                ATTCK_MATRIX_INFO_JSON_FILEPATH, ATTCK_MATRIX_INFO_ALL_IN_ONE
            )
        else:
            # 从本地读取 ATTCK 信息
            with ATTCK_MATRIX_INFO_ALL_IN_ONE.open("r", encoding="utf-8") as f:
                attck_matrix_info = json.load(f)
            if not attck_matrix_info:
                logger.error("解析 ATTCK 信息失败")
                return
            generate_attck_matrix_info_excel_with_attck_matrix_techniques_info(
                attck_matrix_info, ATTCK_MATRIX_INFO_EXCEL_FILEPATH
            )
            self.attck_excel_opertaion.generate_attck_matrix_examples_with_cve_info_with_attck_matrix_techniques_info(
                attck_matrix_info=attck_matrix_info,
                excel_output_filepath=ATTCK_MATRIX_INFO_EXCEL_FILEPATH,
                attck_matrix_info_all_in_one_json_filepath=ATTCK_MATRIX_INFO_ALL_IN_ONE,
            )
            logger.info(
                f"ATTCK 信息解析完成，生成的 Excel 文件为: {ATTCK_MATRIX_INFO_EXCEL_FILEPATH}"
            )
