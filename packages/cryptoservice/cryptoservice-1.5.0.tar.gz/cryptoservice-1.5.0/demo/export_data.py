from pathlib import Path
from cryptoservice.models.universe import UniverseDefinition
from cryptoservice.models.enums import Freq
from cryptoservice.data import MarketDB

# ============== é…ç½®å‚æ•° ==============
# æ–‡ä»¶è·¯å¾„
UNIVERSE_FILE = "./data/universe.json"  # Universeå®šä¹‰æ–‡ä»¶
DB_PATH = "./data/database/market.db"  # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
EXPORT_BASE_PATH = "./data/exports"  # å¯¼å‡ºæ–‡ä»¶åŸºç¡€è·¯å¾„

# å¯¼å‡ºé…ç½®
EXPORT_FREQ = Freq.m1  # å¯¼å‡ºæ•°æ®é¢‘ç‡
CHUNK_DAYS = 100  # åˆ†å—å¤©æ•°

# å¯¼å‡ºçš„ç‰¹å¾ï¼ˆçŸ­å­—æ®µåæ ¼å¼ï¼ŒæŒ‰æŒ‡å®šé¡ºåºï¼‰
EXPORT_FEATURES = [
    "cls",
    "hgh",
    "low",
    "tnum",
    "opn",
    "amt",
    "tbvol",
    "tbamt",
    "vol",
    "vwap",
    "ret",
    "tsvol",
    "tsamt",
]

# ç‰¹å¾æè¿°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
FEATURE_DESCRIPTIONS = {
    "cls": "æ”¶ç›˜ä»·",
    "hgh": "æœ€é«˜ä»·",
    "low": "æœ€ä½ä»·",
    "tnum": "äº¤æ˜“ç¬”æ•°",
    "opn": "å¼€ç›˜ä»·",
    "amt": "æˆäº¤é¢",
    "tbvol": "ä¸»åŠ¨ä¹°å…¥é‡",
    "tbamt": "ä¸»åŠ¨ä¹°å…¥é¢",
    "vol": "æˆäº¤é‡",
    "vwap": "VWAP",
    "ret": "æ”¶ç›Šç‡",
    "tsvol": "ä¸»åŠ¨å–å‡ºé‡",
    "tsamt": "ä¸»åŠ¨å–å‡ºé¢",
}

# ========================================


def main():
    """ä»æ•°æ®åº“å¯¼å‡ºæ•°æ®è„šæœ¬"""
    print("ğŸ“¤ å¼€å§‹ä»æ•°æ®åº“å¯¼å‡ºæ•°æ®")
    print(f"ğŸ“‹ Universeæ–‡ä»¶: {UNIVERSE_FILE}")
    print(f"ğŸ’¾ æ•°æ®åº“è·¯å¾„: {DB_PATH}")
    print(f"ğŸ“ å¯¼å‡ºè·¯å¾„: {EXPORT_BASE_PATH}")
    print(f"â±ï¸ å¯¼å‡ºé¢‘ç‡: {EXPORT_FREQ}")
    print(f"ğŸ“Š å¯¼å‡ºç‰¹å¾: {len(EXPORT_FEATURES)}ä¸ª")
    print(
        f"    {', '.join([f'{feat}({FEATURE_DESCRIPTIONS[feat]})' for feat in EXPORT_FEATURES[:5]])}..."
    )

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(UNIVERSE_FILE).exists():
        print(f"âŒ Universeæ–‡ä»¶ä¸å­˜åœ¨: {UNIVERSE_FILE}")
        print("è¯·å…ˆè¿è¡Œ define_universe.py åˆ›å»ºUniverseæ–‡ä»¶")
        return

    if not Path(DB_PATH).exists():
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {DB_PATH}")
        print("è¯·å…ˆè¿è¡Œ download_data.py ä¸‹è½½æ•°æ®")
        return

    # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
    Path(EXPORT_BASE_PATH).mkdir(parents=True, exist_ok=True)

    try:
        # åŠ è½½Universeå®šä¹‰
        print("ğŸ“– åŠ è½½Universeå®šä¹‰...")
        universe_def = UniverseDefinition.load_from_file(UNIVERSE_FILE)
        print(f"   âœ… æˆåŠŸåŠ è½½ {len(universe_def.snapshots)} ä¸ªå¿«ç…§")

        t1 = universe_def.config.t1_months
        t2 = universe_def.config.t2_months
        t3 = universe_def.config.t3_months
        top_k = universe_def.config.top_k
        delay_days = universe_def.config.delay_days
        quote_asset = universe_def.config.quote_asset

        # åˆ›å»ºMarketDBå®ä¾‹
        db = MarketDB(DB_PATH)

        # å¤„ç†æ¯ä¸ªå¿«ç…§
        for i, snapshot in enumerate(universe_def.snapshots):
            print(
                f"\nğŸ“‹ å¤„ç†å¿«ç…§ {i+1}/{len(universe_def.snapshots)}: {snapshot.start_date} - {snapshot.end_date}"
            )

            start_date_ts = snapshot.start_date_ts
            end_date_ts = snapshot.end_date_ts
            symbols = snapshot.symbols

            print(f"   â° æ—¶é—´èŒƒå›´: {start_date_ts} - {end_date_ts}")
            print(f"   ğŸ’± äº¤æ˜“å¯¹æ•°é‡: {len(symbols)}")
            print(f"   ğŸ“ å‰5ä¸ªäº¤æ˜“å¯¹: {symbols[:5]}")

            # åˆ›å»ºå¿«ç…§ä¸“ç”¨çš„å¯¼å‡ºç›®å½•
            snapshot_export_path = (
                Path(EXPORT_BASE_PATH)
                / f"{t1}_{t2}_{t3}_{top_k}_{delay_days}_{quote_asset}"
            )

            # å¯¼å‡ºæ•°æ®
            db.export_to_files_by_timestamp(
                output_path=snapshot_export_path,
                start_ts=start_date_ts,
                end_ts=end_date_ts,
                freq=Freq.m1,
                target_freq=EXPORT_FREQ,
                symbols=symbols,
                chunk_days=CHUNK_DAYS,
            )

            # æ˜¾ç¤ºå¯¼å‡ºçš„æ–‡ä»¶ä¿¡æ¯
            if snapshot_export_path.exists():
                export_files = list(snapshot_export_path.rglob("*.npy"))
                universe_files = list(snapshot_export_path.rglob("universe_token.pkl"))

                if export_files:
                    total_size = sum(f.stat().st_size for f in export_files) / (
                        1024 * 1024
                    )  # MB
                    print(f"      ğŸ“Š å¯¼å‡ºæ–‡ä»¶æ•°é‡: {len(export_files)}ä¸ª.npyæ–‡ä»¶")
                    print(f"      ğŸ¯ Universeæ–‡ä»¶: {len(universe_files)}ä¸ª.pklæ–‡ä»¶")
                    print(f"      ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size:.1f} MB")

                    # æ˜¾ç¤ºç‰¹å¾åˆ†å¸ƒ
                    feature_dirs = [f.parent.name for f in export_files]
                    unique_features = set(feature_dirs)
                    print(
                        f"      ğŸ“ˆ ç‰¹å¾ç±»å‹: {len(unique_features)}ç§ ({', '.join(sorted(unique_features))})"
                    )

        # æ˜¾ç¤ºå¯¼å‡ºç»“æ„ç¤ºä¾‹
        first_snapshot_dir = (
            next(Path(EXPORT_BASE_PATH).iterdir(), None)
            if Path(EXPORT_BASE_PATH).exists()
            else None
        )
        if first_snapshot_dir and first_snapshot_dir.is_dir():
            print(f"\nğŸ“‚ å¯¼å‡ºæ–‡ä»¶ç»“æ„ç¤ºä¾‹ (åŸºäº {first_snapshot_dir.name}):")
            freq_dirs = [d for d in first_snapshot_dir.iterdir() if d.is_dir()]
            if freq_dirs:
                freq_dir = freq_dirs[0]
                print(f"   {first_snapshot_dir.name}/")
                print(f"   â””â”€â”€ {freq_dir.name}/")

                date_dirs = [d for d in freq_dir.iterdir() if d.is_dir()]
                if date_dirs:
                    date_dir = date_dirs[0]
                    print(f"       â””â”€â”€ {date_dir.name}/")

                    feature_dirs = [d for d in date_dir.iterdir() if d.is_dir()]
                    universe_file = date_dir / "universe_token.pkl"

                    for i, feature_dir in enumerate(sorted(feature_dirs)[:3]):
                        desc = FEATURE_DESCRIPTIONS.get(
                            feature_dir.name, feature_dir.name
                        )
                        print(f"           â”œâ”€â”€ {feature_dir.name}/  # {desc}")
                        npy_files = list(feature_dir.glob("*.npy"))
                        if npy_files:
                            print(f"           â”‚   â””â”€â”€ {npy_files[0].name}")

                    if len(feature_dirs) > 3:
                        print(
                            f"           â”œâ”€â”€ ... (è¿˜æœ‰ {len(feature_dirs)-3} ä¸ªç‰¹å¾ç›®å½•)"
                        )

                    if universe_file.exists():
                        print(f"           â””â”€â”€ universe_token.pkl  # äº¤æ˜“å¯¹é¡ºåº")

        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        all_export_files = list(Path(EXPORT_BASE_PATH).rglob("*.npy"))
        all_universe_files = list(Path(EXPORT_BASE_PATH).rglob("universe_token.pkl"))

        if all_export_files:
            total_size = sum(f.stat().st_size for f in all_export_files) / (
                1024 * 1024
            )  # MB
            print(f"ğŸ“Š æ€»è®¡å¯¼å‡ºæ–‡ä»¶: {len(all_export_files)}ä¸ª.npyæ–‡ä»¶")
            print(f"ğŸ¯ æ€»è®¡Universeæ–‡ä»¶: {len(all_universe_files)}ä¸ª.pklæ–‡ä»¶")
            print(f"ğŸ’¾ æ€»è®¡æ–‡ä»¶å¤§å°: {total_size:.1f} MB")

            # ç»Ÿè®¡æ‰€æœ‰ç‰¹å¾ç±»å‹
            all_features = set(f.parent.name for f in all_export_files)
            print(f"ğŸ“ˆ åŒ…å«ç‰¹å¾: {len(all_features)}ç§")
            print(f"    å®Œæ•´ç‰¹å¾åˆ—è¡¨: {', '.join(sorted(all_features))}")

    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
