# ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„

Gradio PianoRoll ì»´í¬ë„ŒíŠ¸ëŠ” ê³ ê¸‰ ì˜¤ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ìŒì„±ê³¼ ìŒì•…ì˜ ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ì‹œê°í™”í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” F0(ê¸°ë³¸ ì£¼íŒŒìˆ˜), Loudness(ìŒëŸ‰), Voice/Unvoice ë¶„ì„ ë“± ì£¼ìš” ì˜¤ë””ì˜¤ íŠ¹ì„± ë¶„ì„ ê¸°ëŠ¥ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“Š ì§€ì›í•˜ëŠ” ì˜¤ë””ì˜¤ íŠ¹ì„±

### 1. F0 (Fundamental Frequency) ë¶„ì„
ê¸°ë³¸ ì£¼íŒŒìˆ˜(í”¼ì¹˜) ì¶”ì¶œ ë° ì‹œê°í™”:
- **PYIN ì•Œê³ ë¦¬ì¦˜**: ë†’ì€ ì •í™•ë„, ê¸´ ì²˜ë¦¬ ì‹œê°„
- **PipTrack ì•Œê³ ë¦¬ì¦˜**: ë¹ ë¥¸ ì²˜ë¦¬, ì¤‘ê°„ ì •í™•ë„
- ì‹¤ì‹œê°„ í”¼ì¹˜ ê³¡ì„  ì‹œê°í™”
- MIDI ë…¸íŠ¸ì™€ ì—°ë™ëœ í”¼ì¹˜ ë§¤í•‘

### 2. Loudness ë¶„ì„
ìŒëŸ‰(ë°ì‹œë²¨) ì¶”ì¶œ ë° ì‹œê°í™”:
- RMS(Root Mean Square) ê¸°ë°˜ ìŒëŸ‰ ê³„ì‚°
- ë°ì‹œë²¨ ë³€í™˜ ì˜µì…˜
- ì‹œê°„ì— ë”°ë¥¸ ìŒëŸ‰ ë³€í™” ê³¡ì„ 
- ì‚¬ìš©ì ì •ì˜ Yì¶• ë²”ìœ„ ì„¤ì •

### 3. Voice/Unvoice ë¶„ì„
ìœ ì„±ìŒ/ë¬´ì„±ìŒ êµ¬ë¶„:
- í™•ë¥  ê¸°ë°˜ ë˜ëŠ” ì´ì§„ ë¶„ë¥˜
- ìŒì„±í•™ì  íŠ¹ì„± ë¶„ì„
- ë°œìŒ í’ˆì§ˆ í‰ê°€ ì§€ì›

## ğŸµ ê¸°ë³¸ ì‚¬ìš©ë²•

### ë…¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ìƒì„± í›„ ë¶„ì„

```python
import gradio as gr
from gradio_pianoroll import PianoRoll

def analyze_generated_audio(piano_roll_data):
    """í”¼ì•„ë…¸ë¡¤ ë…¸íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•˜ê³  ë¶„ì„"""
    
    # ì‹ ë””ì‚¬ì´ì € ì„¤ì •
    adsr_settings = {
        "attack": 0.01,
        "decay": 0.1,
        "sustain": 0.7,
        "release": 0.3
    }
    
    # ë¶„ì„í•  íŠ¹ì„± ì„ íƒ
    analysis_settings = {
        "include_f0": True,
        "include_loudness": True,
        "include_voicing": True,
        "f0_method": "pyin"
    }
    
    # ë°±ì—”ë“œì—ì„œ ì˜¤ë””ì˜¤ ìƒì„± ë° ë¶„ì„ ìˆ˜í–‰
    # (ì‹¤ì œ êµ¬í˜„ì€ backend í•¨ìˆ˜ ì°¸ì¡°)
    
    return piano_roll_data

with gr.Blocks() as demo:
    piano_roll = PianoRoll(
        value={
            "notes": [
                {
                    "start": 0,
                    "duration": 320,
                    "pitch": 60,
                    "velocity": 100,
                    "lyric": "ë„"
                }
            ],
            "tempo": 120
        },
        use_backend_audio=True  # ë°±ì—”ë“œ ì˜¤ë””ì˜¤ ì—”ì§„ ì‚¬ìš©
    )
    
    analyze_btn = gr.Button("ì˜¤ë””ì˜¤ ìƒì„± & ë¶„ì„")
    analyze_btn.click(
        fn=analyze_generated_audio,
        inputs=[piano_roll],
        outputs=[piano_roll]
    )
```

### ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„

```python
def analyze_uploaded_audio(piano_roll_data, audio_file):
    """ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„"""
    
    if not audio_file:
        return piano_roll_data
    
    # ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ
    features = extract_audio_features(
        audio_file_path=audio_file,
        f0_method="pyin",
        include_f0=True,
        include_loudness=True,
        include_voicing=True
    )
    
    # í”¼ì•„ë…¸ë¡¤ì— ë¶„ì„ ê²°ê³¼ ì ìš©
    piano_roll_data["curve_data"] = {
        "f0_curve": features.get("f0", []),
        "loudness_curve": features.get("loudness", []),
        "voicing_curve": features.get("voicing", [])
    }
    
    return piano_roll_data

with gr.Blocks() as demo:
    piano_roll = PianoRoll()
    audio_input = gr.Audio(type="filepath")
    
    analyze_btn = gr.Button("ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„")
    analyze_btn.click(
        fn=analyze_uploaded_audio,
        inputs=[piano_roll, audio_input],
        outputs=[piano_roll]
    )
```

## âš™ï¸ ê³ ê¸‰ ì„¤ì •

### F0 ë¶„ì„ ì„¤ì •

```python
def extract_f0_with_custom_settings(audio_file_path, method="pyin"):
    """F0 ì¶”ì¶œ ì»¤ìŠ¤í…€ ì„¤ì •"""
    
    if method == "pyin":
        # PYIN ë°©ë²•: ë†’ì€ ì •í™•ë„
        f0_data = librosa.pyin(
            audio_data,
            fmin=80,      # ìµœì†Œ ì£¼íŒŒìˆ˜ (Hz)
            fmax=400,     # ìµœëŒ€ ì£¼íŒŒìˆ˜ (Hz)
            sr=sample_rate,
            frame_length=2048,
            hop_length=512
        )
    elif method == "piptrack":
        # PipTrack ë°©ë²•: ë¹ ë¥¸ ì²˜ë¦¬
        pitches, magnitudes = librosa.piptrack(
            audio_data,
            sr=sample_rate,
            threshold=0.1,
            fmin=80,
            fmax=400
        )
        
    return f0_data
```

### Loudness ë¶„ì„ ì„¤ì •

```python
def extract_loudness_with_custom_settings(audio_file_path):
    """Loudness ì¶”ì¶œ ì»¤ìŠ¤í…€ ì„¤ì •"""
    
    # RMS ì—ë„ˆì§€ ê³„ì‚°
    rms_energy = librosa.feature.rms(
        y=audio_data,
        frame_length=2048,
        hop_length=512
    )
    
    # ë°ì‹œë²¨ ë³€í™˜
    loudness_db = librosa.amplitude_to_db(
        rms_energy,
        ref=np.max  # ìµœëŒ€ê°’ ê¸°ì¤€ ì •ê·œí™”
    )
    
    return loudness_db
```

### Voice/Unvoice ë¶„ì„ ì„¤ì •

```python
def extract_voicing_with_custom_settings(audio_file_path):
    """Voice/Unvoice ë¶„ì„ ì»¤ìŠ¤í…€ ì„¤ì •"""
    
    # ìœ ì„±ìŒ í™•ë¥  ê³„ì‚°
    voicing_probs = []
    
    for frame in frames:
        # ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì„± ê¸°ë°˜ ë¶„ë¥˜
        spectral_centroid = librosa.feature.spectral_centroid(frame)
        zero_crossing_rate = librosa.feature.zero_crossing_rate(frame)
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ë¶„ë¥˜
        if spectral_centroid > threshold and zero_crossing_rate < threshold:
            voicing_probs.append(1.0)  # ìœ ì„±ìŒ
        else:
            voicing_probs.append(0.0)  # ë¬´ì„±ìŒ
    
    return voicing_probs
```

## ğŸ›ï¸ ì‹ ë””ì‚¬ì´ì € ì„¤ì •

### ADSR ì—”ë²¨ë¡œí”„

```python
def configure_adsr_envelope():
    """ADSR ì—”ë²¨ë¡œí”„ ì„¤ì •"""
    
    adsr_config = {
        "attack": 0.01,    # Attack ì‹œê°„ (ì´ˆ): 0.001 ~ 1.0
        "decay": 0.1,      # Decay ì‹œê°„ (ì´ˆ): 0.001 ~ 1.0  
        "sustain": 0.7,    # Sustain ë ˆë²¨: 0.0 ~ 1.0
        "release": 0.3     # Release ì‹œê°„ (ì´ˆ): 0.001 ~ 2.0
    }
    
    return adsr_config
```

### íŒŒí˜• íƒ€ì…

```python
def configure_waveform_type():
    """íŒŒí˜• íƒ€ì… ì„¤ì •"""
    
    waveform_options = {
        "complex": "ë³µí•© íŒŒí˜• (í•˜ëª¨ë‹‰ + FM)",
        "harmonic": "í•˜ëª¨ë‹‰ í•©ì„±",
        "fm": "FM í•©ì„±",
        "sawtooth": "í†±ë‹ˆíŒŒ",
        "square": "ì‚¬ê°íŒŒ", 
        "triangle": "ì‚¼ê°íŒŒ",
        "sine": "ì‚¬ì¸íŒŒ"
    }
    
    return waveform_options
```

## ğŸ“ˆ ì‹œê°í™” ì˜µì…˜

### F0 ê³¡ì„  ì‹œê°í™”

```python
def create_f0_visualization(f0_data, tempo=120, pixels_per_beat=80):
    """F0 ë°ì´í„°ë¥¼ í”¼ì•„ë…¸ë¡¤ ì¢Œí‘œê³„ë¡œ ë³€í™˜"""
    
    line_data = []
    
    for i, f0_value in enumerate(f0_data):
        if f0_value > 0:  # ìœ íš¨í•œ F0 ê°’ë§Œ
            # ì‹œê°„ì„ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            time_seconds = i * hop_length / sample_rate
            x_pixels = time_seconds * (tempo / 60) * pixels_per_beat
            
            # ì£¼íŒŒìˆ˜ë¥¼ MIDI ë…¸íŠ¸ë¡œ ë³€í™˜
            midi_note = 12 * np.log2(f0_value / 440) + 69
            y_pixels = (127 - midi_note) * 10  # í”¼ì•„ë…¸ë¡¤ Y ì¢Œí‘œ
            
            line_data.append({"x": x_pixels, "y": y_pixels})
    
    return {
        "f0_curve": {
            "type": "line",
            "points": line_data,
            "color": "#ff6b6b",
            "lineWidth": 2
        }
    }
```

### Loudness ê³¡ì„  ì‹œê°í™”

```python
def create_loudness_visualization(loudness_data, y_min=-60, y_max=0):
    """Loudness ë°ì´í„° ì‹œê°í™”"""
    
    line_data = []
    
    for i, loudness_value in enumerate(loudness_data):
        time_seconds = i * hop_length / sample_rate
        x_pixels = time_seconds * (tempo / 60) * pixels_per_beat
        
        # Yì¶• ì •ê·œí™” (ë°ì‹œë²¨ â†’ í”½ì…€)
        normalized_y = (loudness_value - y_min) / (y_max - y_min)
        y_pixels = (1 - normalized_y) * 600  # 600px ë†’ì´ ê¸°ì¤€
        
        line_data.append({"x": x_pixels, "y": y_pixels})
    
    return {
        "loudness_curve": {
            "type": "line",
            "points": line_data,
            "color": "#4ecdc4",
            "lineWidth": 2
        }
    }
```

## ğŸ”§ ì‹¤ìš©ì ì¸ í™œìš©ë²•

### 1. ìŒì„± ë¶„ì„ ì›Œí¬í”Œë¡œìš°

```python
def voice_analysis_workflow(audio_file):
    """ìŒì„± ë¶„ì„ ì™„ì „ ì›Œí¬í”Œë¡œìš°"""
    
    # 1ë‹¨ê³„: ê¸°ë³¸ íŠ¹ì„± ì¶”ì¶œ
    features = extract_audio_features(
        audio_file_path=audio_file,
        f0_method="pyin",
        include_f0=True,
        include_loudness=True, 
        include_voicing=True
    )
    
    # 2ë‹¨ê³„: í”¼ì•„ë…¸ë¡¤ ë°ì´í„° ìƒì„±
    piano_roll_data = {
        "notes": [],
        "tempo": 120,
        "curve_data": {
            "f0_curve": create_f0_line_data(features["f0"]),
            "loudness_curve": create_loudness_line_data(features["loudness"]),
            "voicing_curve": create_voicing_line_data(features["voicing"])
        },
        "use_backend_audio": True
    }
    
    # 3ë‹¨ê³„: ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
    analysis_report = {
        "í‰ê· _f0": np.mean([f for f in features["f0"] if f > 0]),
        "f0_ë²”ìœ„": [np.min(features["f0"]), np.max(features["f0"])],
        "í‰ê· _loudness": np.mean(features["loudness"]),
        "ìœ ì„±ìŒ_ë¹„ìœ¨": np.mean(features["voicing"])
    }
    
    return piano_roll_data, analysis_report
```

### 2. ì‹¤ì‹œê°„ ë¶„ì„ ëª¨ë‹ˆí„°ë§

```python
def setup_realtime_analysis():
    """ì‹¤ì‹œê°„ ë¶„ì„ ì„¤ì •"""
    
    with gr.Blocks() as demo:
        piano_roll = PianoRoll(use_backend_audio=True)
        
        # ë¶„ì„ ì„¤ì • UI
        with gr.Row():
            f0_toggle = gr.Checkbox(label="F0 ë¶„ì„", value=True)
            loudness_toggle = gr.Checkbox(label="Loudness ë¶„ì„", value=True)
            voicing_toggle = gr.Checkbox(label="Voice/Unvoice ë¶„ì„", value=True)
        
        with gr.Row():
            f0_method = gr.Dropdown(
                choices=[("PYIN", "pyin"), ("PipTrack", "piptrack")],
                value="pyin",
                label="F0 ë°©ë²•"
            )
            
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        def update_analysis(piano_roll_data, f0_enabled, loudness_enabled, 
                          voicing_enabled, method):
            # ì‹¤ì‹œê°„ ë¶„ì„ ë¡œì§
            return piano_roll_data
        
        # ì£¼ê¸°ì  ì—…ë°ì´íŠ¸ (ì˜ˆ: 1ì´ˆë§ˆë‹¤)
        timer = gr.Timer(1.0)
        timer.tick(
            fn=update_analysis,
            inputs=[piano_roll, f0_toggle, loudness_toggle, voicing_toggle, f0_method],
            outputs=[piano_roll]
        )
```

### 3. ìŒì§ˆ í‰ê°€ ë„êµ¬

```python
def audio_quality_assessment(audio_file):
    """ì˜¤ë””ì˜¤ í’ˆì§ˆ í‰ê°€"""
    
    features = extract_audio_features(audio_file)
    
    quality_metrics = {
        "í”¼ì¹˜_ì•ˆì •ì„±": calculate_f0_stability(features["f0"]),
        "ìŒëŸ‰_ì¼ê´€ì„±": calculate_loudness_consistency(features["loudness"]),
        "ì¡ìŒ_ìˆ˜ì¤€": calculate_noise_level(features),
        "ì „ì²´_ì ìˆ˜": 0.0
    }
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚°
    quality_metrics["ì „ì²´_ì ìˆ˜"] = (
        quality_metrics["í”¼ì¹˜_ì•ˆì •ì„±"] * 0.4 +
        quality_metrics["ìŒëŸ‰_ì¼ê´€ì„±"] * 0.3 +
        (1 - quality_metrics["ì¡ìŒ_ìˆ˜ì¤€"]) * 0.3
    )
    
    return quality_metrics

def calculate_f0_stability(f0_data):
    """F0 ì•ˆì •ì„± ê³„ì‚°"""
    valid_f0 = [f for f in f0_data if f > 0]
    if len(valid_f0) < 2:
        return 0.0
    
    # ë³€ë™ ê³„ìˆ˜ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì•ˆì •)
    cv = np.std(valid_f0) / np.mean(valid_f0)
    stability = max(0, 1 - cv)
    
    return stability
```

## ğŸ¯ ì„±ëŠ¥ ìµœì í™”

### 1. ì²˜ë¦¬ ì†ë„ í–¥ìƒ

```python
def optimize_analysis_speed():
    """ë¶„ì„ ì†ë„ ìµœì í™” íŒ"""
    
    # ì§§ì€ ì˜¤ë””ì˜¤ íŒŒì¼ìš© ë¹ ë¥¸ ì„¤ì •
    fast_settings = {
        "f0_method": "piptrack",  # PYIN ëŒ€ì‹  PipTrack ì‚¬ìš©
        "hop_length": 1024,       # ë” í° hop size
        "frame_length": 2048,     # ì ì ˆí•œ frame size
    }
    
    # ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ìš© ì •í™•í•œ ì„¤ì •  
    accurate_settings = {
        "f0_method": "pyin",      # ë†’ì€ ì •í™•ë„
        "hop_length": 512,        # ì‘ì€ hop size
        "frame_length": 2048,     # í‘œì¤€ frame size
    }
    
    return fast_settings, accurate_settings
```

### 2. ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”

```python
def optimize_memory_usage(audio_file, chunk_size=10.0):
    """ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™” (ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬)"""
    
    # ê¸´ ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    audio_data, sr = librosa.load(audio_file)
    chunk_samples = int(chunk_size * sr)
    
    all_features = {"f0": [], "loudness": [], "voicing": []}
    
    for i in range(0, len(audio_data), chunk_samples):
        chunk = audio_data[i:i+chunk_samples]
        
        # ì²­í¬ë³„ ë¶„ì„
        chunk_features = extract_audio_features_chunk(chunk, sr)
        
        # ê²°ê³¼ ë³‘í•©
        for key in all_features:
            all_features[key].extend(chunk_features[key])
    
    return all_features
```

## ğŸ“ ë¬¸ì œí•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

**Q: F0 ë¶„ì„ ê²°ê³¼ê°€ ë¶€ì •í™•í•´ìš”**
- PYIN ë°©ë²• ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤
- fmin, fmax íŒŒë¼ë¯¸í„°ë¥¼ ìŒì„± ë²”ìœ„ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”
- ë…¸ì´ì¦ˆê°€ ë§ì€ ì˜¤ë””ì˜¤ëŠ” ì „ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

**Q: ë¶„ì„ ì†ë„ê°€ ë„ˆë¬´ ëŠë ¤ìš”**
- PipTrack ë°©ë²•ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”
- hop_lengthë¥¼ ì¦ê°€ì‹œì¼œ ì‹œê°„ í•´ìƒë„ë¥¼ ë‚®ì¶”ì„¸ìš”
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”

**Q: ì‹œê°í™”ê°€ ì œëŒ€ë¡œ ì•ˆ ë³´ì—¬ìš”**
- curve_data í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”
- ì¢Œí‘œ ë³€í™˜ ê³„ì‚°ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”
- ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”

### ë””ë²„ê¹… íŒ

```python
def debug_analysis_pipeline(audio_file):
    """ë¶„ì„ íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹…"""
    
    print(f"ğŸ” ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘: {audio_file}")
    
    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ í™•ì¸
        audio_data, sr = librosa.load(audio_file)
        print(f"âœ… ì˜¤ë””ì˜¤ ë¡œë“œ ì„±ê³µ: {len(audio_data)} ìƒ˜í”Œ, {sr}Hz")
        
        # F0 ë¶„ì„ í™•ì¸
        f0_data = extract_f0_from_audio(audio_file)
        valid_f0_count = len([f for f in f0_data if f > 0])
        print(f"âœ… F0 ë¶„ì„ ì™„ë£Œ: {valid_f0_count}/{len(f0_data)} ìœ íš¨í•œ í”„ë ˆì„")
        
        # Loudness ë¶„ì„ í™•ì¸
        loudness_data = extract_loudness_from_audio(audio_file)
        print(f"âœ… Loudness ë¶„ì„ ì™„ë£Œ: {len(loudness_data)} í”„ë ˆì„")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return False
```

ì´ ê°€ì´ë“œë¥¼ í†µí•´ Gradio PianoRoll ì»´í¬ë„ŒíŠ¸ì˜ ê°•ë ¥í•œ ì˜¤ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŒì„±í•™, ìŒì•…í•™, ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ì „ë¬¸ì ì¸ ë¶„ì„ ë„êµ¬ë¡œ ì‚¬ìš©í•˜ì„¸ìš”! 