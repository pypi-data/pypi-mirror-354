# ê°œë°œì ì˜ˆì œ

ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” Gradio PianoRoll ì»´í¬ë„ŒíŠ¸ì˜ ë‹¤ì–‘í•œ ì˜ˆì œë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¹ ê¸°ë³¸ ì˜ˆì œ

### 1. ê°„ë‹¨í•œ MIDI ì—ë””í„°

```python
import gradio as gr
from gradio_pianoroll import PianoRoll

def save_midi_data(piano_roll_data):
    """MIDI ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    notes = piano_roll_data.get("notes", [])
    tempo = piano_roll_data.get("tempo", 120)
    
    # MIDI íŒŒì¼ ìƒì„± ë¡œì§ (python-midi ë“± ì‚¬ìš©)
    filename = f"composition_{len(notes)}_notes.mid"
    
    return f"âœ… {filename}ì— {len(notes)}ê°œ ë…¸íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."

with gr.Blocks(title="MIDI ì‘ê³¡ ë„êµ¬") as demo:
    with gr.Row():
        piano_roll = PianoRoll(
            label="ğŸ¼ MIDI ì—ë””í„°",
            height=500,
            width=1200
        )
    
    with gr.Row():
        save_btn = gr.Button("ğŸ’¾ MIDI ì €ì¥", variant="primary")
        clear_btn = gr.Button("ğŸ—‘ï¸ ì´ˆê¸°í™”", variant="secondary")
    
    status_text = gr.Textbox(label="ìƒíƒœ", interactive=False)
    
    save_btn.click(
        fn=save_midi_data,
        inputs=[piano_roll],
        outputs=[status_text]
    )

demo.launch()
```

### 2. ì‹¤ì‹œê°„ ìŒì•… ë¶„ì„ê¸°

```python
import gradio as gr
from gradio_pianoroll import PianoRoll
import librosa
import numpy as np

def analyze_composition(piano_roll_data):
    """ì‘ê³¡ëœ ìŒì•…ì˜ íŠ¹ì„± ë¶„ì„"""
    notes = piano_roll_data.get("notes", [])
    tempo = piano_roll_data.get("tempo", 120)
    
    if not notes:
        return {"ë¶„ì„": "ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}
    
    # ìŒì • ë¶„ì„
    pitches = [note["pitch"] for note in notes]
    pitch_range = max(pitches) - min(pitches)
    avg_pitch = np.mean(pitches)
    
    # ë¦¬ë“¬ ë¶„ì„
    durations = [note["durationSeconds"] for note in notes]
    avg_duration = np.mean(durations)
    
    # ì¡°ì„± ì¶”ì • (ê°„ë‹¨í•œ ë²„ì „)
    pitch_classes = [pitch % 12 for pitch in pitches]
    most_common_key = max(set(pitch_classes), key=pitch_classes.count)
    
    analysis = {
        "ì´ ë…¸íŠ¸ ìˆ˜": len(notes),
        "ìŒì—­ëŒ€": f"{pitch_range} ë°˜ìŒ",
        "í‰ê·  ìŒë†’ì´": f"MIDI {avg_pitch:.1f}",
        "í‰ê·  ë…¸íŠ¸ ê¸¸ì´": f"{avg_duration:.2f}ì´ˆ",
        "ì¶”ì • ì¡°ì„±": f"Key of {most_common_key}",
        "í…œí¬": f"{tempo} BPM"
    }
    
    return analysis

with gr.Blocks() as demo:
    piano_roll = PianoRoll(height=400)
    
    with gr.Row():
        analyze_btn = gr.Button("ğŸ” ìŒì•… ë¶„ì„")
        analysis_output = gr.JSON(label="ë¶„ì„ ê²°ê³¼")
    
    analyze_btn.click(
        fn=analyze_composition,
        inputs=[piano_roll],
        outputs=[analysis_output]
    )
    
    # ì‹¤ì‹œê°„ ë¶„ì„ (ë…¸íŠ¸ ë³€ê²½ì‹œë§ˆë‹¤)
    piano_roll.change(
        fn=analyze_composition,
        inputs=[piano_roll],
        outputs=[analysis_output]
    )

demo.launch()
```

## ğŸ¤ ìŒì„± í•©ì„± ì˜ˆì œ

### 3. í•œêµ­ì–´ ê°€ì‚¬ TTS ì‹œìŠ¤í…œ

```python
from gradio_pianoroll import PianoRoll
import gradio as gr

def text_to_phoneme(text):
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìŒì†Œë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ì˜ˆì œ)"""
    # ì‹¤ì œë¡œëŠ” G2P ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
    phoneme_map = {
        "ì•ˆë…•": "ã…‡ã…ã„´ã„´ã…•ã…‡",
        "í•˜ì„¸ìš”": "ã…ã…ã……ã…”ã…‡ã…›",
        "ê°ì‚¬": "ã„±ã…ã…ã……ã…",
        "í•©ë‹ˆë‹¤": "ã…ã…ã…ã„´ã…£ã„·ã…"
    }
    return phoneme_map.get(text, text)

def process_lyrics_input(piano_roll_data, lyrics_text):
    """ê°€ì‚¬ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ë…¸íŠ¸ì— í• ë‹¹"""
    notes = piano_roll_data.get("notes", [])
    lyrics_list = lyrics_text.strip().split()
    
    # ê°€ì‚¬ë¥¼ ë…¸íŠ¸ì— ìˆœì„œëŒ€ë¡œ í• ë‹¹
    for i, note in enumerate(notes):
        if i < len(lyrics_list):
            note["lyric"] = lyrics_list[i]
            # ìŒì†Œ ë³€í™˜ë„ í•¨ê»˜ ì €ì¥
            note["phoneme"] = text_to_phoneme(lyrics_list[i])
    
    return piano_roll_data

def synthesize_speech(piano_roll_data):
    """ìŒì„± í•©ì„± ìˆ˜í–‰"""
    notes = piano_roll_data.get("notes", [])
    
    if not notes:
        return piano_roll_data, "ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê° ë…¸íŠ¸ì˜ ê°€ì‚¬ì™€ ìŒë†’ì´ë¥¼ ì´ìš©í•´ ìŒì„± í•©ì„±
    synthesis_info = []
    
    for note in notes:
        lyric = note.get("lyric", "")
        phoneme = note.get("phoneme", "")
        pitch = note.get("pitch", 60)
        duration = note.get("durationSeconds", 1.0)
        
        if lyric:
            synthesis_info.append(f"'{lyric}' ({phoneme}) - {pitch} MIDI, {duration:.2f}ì´ˆ")
    
    # ì‹¤ì œ ìŒì„± í•©ì„± ë¡œì§ì€ ì—¬ê¸°ì— êµ¬í˜„
    # piano_roll_data["audio_data"] = synthesized_audio_base64
    piano_roll_data["use_backend_audio"] = True
    
    status = f"âœ… {len(synthesis_info)}ê°œ ë…¸íŠ¸ì˜ ìŒì„±ì„ í•©ì„±í–ˆìŠµë‹ˆë‹¤:\n" + "\n".join(synthesis_info)
    
    return piano_roll_data, status

with gr.Blocks(title="í•œêµ­ì–´ TTS ì‹œìŠ¤í…œ") as demo:
    gr.Markdown("## ğŸ¤ í•œêµ­ì–´ ê°€ì‚¬ ìŒì„± í•©ì„±")
    
    with gr.Row():
        with gr.Column(scale=3):
            piano_roll = PianoRoll(
                height=400,
                use_backend_audio=True
            )
        
        with gr.Column(scale=1):
            lyrics_input = gr.Textbox(
                label="ğŸµ ê°€ì‚¬ ì…ë ¥",
                placeholder="ì•ˆë…• í•˜ì„¸ìš” ê°ì‚¬ í•©ë‹ˆë‹¤",
                lines=5
            )
            
            process_lyrics_btn = gr.Button("ğŸ“ ê°€ì‚¬ ì ìš©")
            synthesize_btn = gr.Button("ğŸ¤ ìŒì„± í•©ì„±", variant="primary")
    
    status_output = gr.Textbox(label="í•©ì„± ìƒíƒœ", lines=6, interactive=False)
    
    process_lyrics_btn.click(
        fn=process_lyrics_input,
        inputs=[piano_roll, lyrics_input],
        outputs=[piano_roll]
    )
    
    synthesize_btn.click(
        fn=synthesize_speech,
        inputs=[piano_roll],
        outputs=[piano_roll, status_output]
    )

demo.launch()
```

## ğŸ”Š ì˜¤ë””ì˜¤ ë¶„ì„ ì˜ˆì œ

### 4. ìŒì„± ë¶„ì„ ë„êµ¬

```python
import gradio as gr
from gradio_pianoroll import PianoRoll
import librosa
import numpy as np

def extract_pitch_curve(audio_file):
    """ì˜¤ë””ì˜¤ì—ì„œ í”¼ì¹˜ ê³¡ì„  ì¶”ì¶œ"""
    if not audio_file:
        return None
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_file)
    
    # F0 ì¶”ì¶œ (PYIN)
    f0, voiced_flag, voiced_probs = librosa.pyin(
        y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')
    )
    
    # ì‹œê°„ì¶• ìƒì„±
    times = librosa.frames_to_time(np.arange(len(f0)), sr=sr)
    
    return f0, times, voiced_probs

def create_pitch_visualization(f0_data, times, tempo=120, pixels_per_beat=80):
    """F0 ë°ì´í„°ë¥¼ í”¼ì•„ë…¸ë¡¤ ì‹œê°í™” í˜•íƒœë¡œ ë³€í™˜"""
    line_points = []
    
    for i, (f0_val, time_val) in enumerate(zip(f0_data, times)):
        if not np.isnan(f0_val) and f0_val > 0:
            # ì‹œê°„ì„ í”½ì…€ë¡œ ë³€í™˜
            x_pixel = time_val * (tempo / 60) * pixels_per_beat
            
            # ì£¼íŒŒìˆ˜ë¥¼ MIDI ë…¸íŠ¸ë¡œ ë³€í™˜
            midi_note = librosa.hz_to_midi(f0_val)
            y_pixel = (127 - midi_note) * 10  # í”¼ì•„ë…¸ë¡¤ Y ì¢Œí‘œ
            
            line_points.append({"x": x_pixel, "y": y_pixel})
    
    return {
        "f0_curve": {
            "type": "line",
            "points": line_points,
            "color": "#ff6b6b",
            "lineWidth": 2
        }
    }

def analyze_uploaded_audio(piano_roll_data, audio_file):
    """ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ ë¶„ì„"""
    if not audio_file:
        return piano_roll_data, "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    try:
        # í”¼ì¹˜ ì¶”ì¶œ
        f0_data, times, voiced_probs = extract_pitch_curve(audio_file)
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        curve_data = create_pitch_visualization(f0_data, times)
        
        # í”¼ì•„ë…¸ë¡¤ì— ì ìš©
        piano_roll_data["curve_data"] = curve_data
        
        # í†µê³„ ì •ë³´
        valid_f0 = f0_data[~np.isnan(f0_data) & (f0_data > 0)]
        if len(valid_f0) > 0:
            status = f"""
âœ… í”¼ì¹˜ ë¶„ì„ ì™„ë£Œ
â€¢ ì´ í”„ë ˆì„: {len(f0_data)}
â€¢ ìœ ì„±ìŒ í”„ë ˆì„: {len(valid_f0)} ({len(valid_f0)/len(f0_data)*100:.1f}%)
â€¢ í‰ê·  F0: {np.mean(valid_f0):.1f} Hz
â€¢ F0 ë²”ìœ„: {np.min(valid_f0):.1f} - {np.max(valid_f0):.1f} Hz
â€¢ í‰ê·  ìœ ì„±ìŒ í™•ë¥ : {np.mean(voiced_probs):.2f}
            """
        else:
            status = "âŒ ìœ íš¨í•œ í”¼ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return piano_roll_data, status.strip()
        
    except Exception as e:
        return piano_roll_data, f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

with gr.Blocks(title="ìŒì„± ë¶„ì„ ë„êµ¬") as demo:
    gr.Markdown("## ğŸ” ìŒì„± í”¼ì¹˜ ë¶„ì„ ë„êµ¬")
    
    with gr.Row():
        with gr.Column(scale=2):
            audio_input = gr.Audio(
                label="ğŸµ ë¶„ì„í•  ì˜¤ë””ì˜¤ ì—…ë¡œë“œ",
                type="filepath"
            )
            analyze_btn = gr.Button("ğŸ”¬ í”¼ì¹˜ ë¶„ì„ ì‹œì‘", variant="primary")
        
        with gr.Column(scale=1):
            analysis_status = gr.Textbox(
                label="ë¶„ì„ ìƒíƒœ",
                lines=8,
                interactive=False
            )
    
    piano_roll = PianoRoll(
        label="ğŸ“Š í”¼ì¹˜ ê³¡ì„  ì‹œê°í™”",
        height=500,
        width=1200
    )
    
    analyze_btn.click(
        fn=analyze_uploaded_audio,
        inputs=[piano_roll, audio_input],
        outputs=[piano_roll, analysis_status]
    )

demo.launch()
```

### 5. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§

```python
import gradio as gr
from gradio_pianoroll import PianoRoll
import numpy as np

class AudioMonitor:
    def __init__(self):
        self.is_monitoring = False
        self.audio_buffer = []
    
    def start_monitoring(self):
        self.is_monitoring = True
        return "ğŸ”´ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨"
    
    def stop_monitoring(self):
        self.is_monitoring = False
        return "â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨"
    
    def process_audio_chunk(self, audio_chunk):
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬"""
        if not self.is_monitoring:
            return None
        
        # ê°„ë‹¨í•œ í”¼ì¹˜ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        # ì—¬ê¸°ì„œëŠ” ë°ëª¨ìš© ëœë¤ ë°ì´í„° ìƒì„±
        mock_f0 = 200 + 100 * np.sin(len(self.audio_buffer) * 0.1)
        
        self.audio_buffer.append({
            "time": len(self.audio_buffer) * 0.1,
            "f0": mock_f0,
            "amplitude": np.random.random()
        })
        
        # ìµœê·¼ 100ê°œ ìƒ˜í”Œë§Œ ìœ ì§€
        if len(self.audio_buffer) > 100:
            self.audio_buffer = self.audio_buffer[-100:]
        
        return self.create_realtime_visualization()
    
    def create_realtime_visualization(self):
        """ì‹¤ì‹œê°„ ì‹œê°í™” ë°ì´í„° ìƒì„±"""
        if not self.audio_buffer:
            return {}
        
        line_points = []
        for i, sample in enumerate(self.audio_buffer):
            x_pixel = i * 10  # 10í”½ì…€ ê°„ê²©
            midi_note = librosa.hz_to_midi(sample["f0"])
            y_pixel = (127 - midi_note) * 10
            
            line_points.append({"x": x_pixel, "y": y_pixel})
        
        return {
            "realtime_f0": {
                "type": "line",
                "points": line_points,
                "color": "#00ff00",
                "lineWidth": 3
            }
        }

monitor = AudioMonitor()

def update_monitoring_display(piano_roll_data):
    """ëª¨ë‹ˆí„°ë§ ë””ìŠ¤í”Œë ˆì´ ì—…ë°ì´íŠ¸"""
    # ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    visualization = monitor.process_audio_chunk(None)
    
    if visualization:
        piano_roll_data["curve_data"] = visualization
    
    return piano_roll_data

with gr.Blocks(title="ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°") as demo:
    gr.Markdown("## ğŸ™ï¸ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ í”¼ì¹˜ ëª¨ë‹ˆí„°ë§")
    
    with gr.Row():
        start_btn = gr.Button("ğŸ”´ ëª¨ë‹ˆí„°ë§ ì‹œì‘", variant="primary")
        stop_btn = gr.Button("â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€", variant="secondary")
        status_text = gr.Textbox(label="ìƒíƒœ", interactive=False)
    
    piano_roll = PianoRoll(
        label="ğŸ“Š ì‹¤ì‹œê°„ í”¼ì¹˜ ëª¨ë‹ˆí„°",
        height=400,
        width=1000
    )
    
    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (0.1ì´ˆë§ˆë‹¤)
    timer = gr.Timer(0.1)
    
    start_btn.click(
        fn=monitor.start_monitoring,
        outputs=[status_text]
    )
    
    stop_btn.click(
        fn=monitor.stop_monitoring,
        outputs=[status_text]
    )
    
    timer.tick(
        fn=update_monitoring_display,
        inputs=[piano_roll],
        outputs=[piano_roll]
    )

demo.launch()
```

## ğŸ›ï¸ ê³ ê¸‰ í™œìš© ì˜ˆì œ

### 6. ìŒì•… êµìœ¡ ë„êµ¬

```python
import gradio as gr
from gradio_pianoroll import PianoRoll
import random

class MusicTeacher:
    def __init__(self):
        self.scales = {
            "C Major": [60, 62, 64, 65, 67, 69, 71],
            "A Minor": [57, 59, 60, 62, 64, 65, 67],
            "G Major": [67, 69, 71, 72, 74, 76, 78],
            "E Minor": [64, 66, 67, 69, 71, 72, 74]
        }
        self.current_exercise = None
    
    def generate_scale_exercise(self, scale_name):
        """ìŠ¤ì¼€ì¼ ì—°ìŠµ ë¬¸ì œ ìƒì„±"""
        if scale_name not in self.scales:
            return None
        
        notes = []
        scale_notes = self.scales[scale_name]
        
        for i, pitch in enumerate(scale_notes):
            note = {
                "id": f"scale-note-{i}",
                "start": i * 160,  # 160í”½ì…€ ê°„ê²©
                "duration": 120,
                "pitch": pitch,
                "velocity": 100,
                "lyric": f"ë„ë ˆë¯¸íŒŒì†”ë¼ì‹œ"[i] if i < 7 else ""
            }
            notes.append(note)
        
        self.current_exercise = {
            "type": "scale",
            "scale": scale_name,
            "notes": notes
        }
        
        return {
            "notes": notes,
            "tempo": 120,
            "timeSignature": {"numerator": 4, "denominator": 4},
            "editMode": "select",
            "snapSetting": "1/4",
            "pixelsPerBeat": 80
        }
    
    def generate_interval_exercise(self, interval_type):
        """ìŒì • ì—°ìŠµ ë¬¸ì œ ìƒì„±"""
        intervals = {
            "Perfect 5th": 7,
            "Major 3rd": 4,
            "Minor 3rd": 3,
            "Octave": 12
        }
        
        if interval_type not in intervals:
            return None
        
        root_note = random.randint(60, 72)
        interval_semitones = intervals[interval_type]
        
        notes = [
            {
                "id": "interval-root",
                "start": 0,
                "duration": 160,
                "pitch": root_note,
                "velocity": 100,
                "lyric": "Root"
            },
            {
                "id": "interval-target",
                "start": 200,
                "duration": 160,
                "pitch": root_note + interval_semitones,
                "velocity": 100,
                "lyric": interval_type
            }
        ]
        
        return {
            "notes": notes,
            "tempo": 120,
            "timeSignature": {"numerator": 4, "denominator": 4},
            "editMode": "select",
            "snapSetting": "1/4",
            "pixelsPerBeat": 80
        }

teacher = MusicTeacher()

def load_scale_exercise(scale_name):
    """ìŠ¤ì¼€ì¼ ì—°ìŠµ ë¡œë“œ"""
    exercise_data = teacher.generate_scale_exercise(scale_name)
    if exercise_data:
        return exercise_data, f"âœ… {scale_name} ìŠ¤ì¼€ì¼ ì—°ìŠµì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
    else:
        return None, "âŒ ìŠ¤ì¼€ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def load_interval_exercise(interval_type):
    """ìŒì • ì—°ìŠµ ë¡œë“œ"""
    exercise_data = teacher.generate_interval_exercise(interval_type)
    if exercise_data:
        return exercise_data, f"âœ… {interval_type} ìŒì • ì—°ìŠµì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
    else:
        return None, "âŒ ìŒì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def check_student_answer(piano_roll_data):
    """í•™ìƒ ë‹µì•ˆ ê²€ì‚¬"""
    if not teacher.current_exercise:
        return "ì—°ìŠµ ë¬¸ì œë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    student_notes = piano_roll_data.get("notes", [])
    correct_notes = teacher.current_exercise["notes"]
    
    if len(student_notes) != len(correct_notes):
        return f"âŒ ë…¸íŠ¸ ê°œìˆ˜ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. (ì •ë‹µ: {len(correct_notes)}ê°œ, ì…ë ¥: {len(student_notes)}ê°œ)"
    
    correct_count = 0
    for i, (student, correct) in enumerate(zip(student_notes, correct_notes)):
        if abs(student.get("pitch", 0) - correct["pitch"]) == 0:
            correct_count += 1
    
    accuracy = correct_count / len(correct_notes) * 100
    
    if accuracy == 100:
        return f"ğŸ‰ ì™„ë²½í•©ë‹ˆë‹¤! {accuracy:.0f}% ì •í™•ë„"
    elif accuracy >= 80:
        return f"ğŸ‘ ì¢‹ìŠµë‹ˆë‹¤! {accuracy:.0f}% ì •í™•ë„ ({correct_count}/{len(correct_notes)})"
    else:
        return f"ğŸ’ª ë” ì—°ìŠµí•´ë³´ì„¸ìš”. {accuracy:.0f}% ì •í™•ë„ ({correct_count}/{len(correct_notes)})"

with gr.Blocks(title="ìŒì•… êµìœ¡ ë„êµ¬") as demo:
    gr.Markdown("## ğŸ¼ ìŒì•… ì´ë¡  í•™ìŠµ ë„êµ¬")
    
    with gr.Tabs():
        with gr.TabItem("ìŠ¤ì¼€ì¼ ì—°ìŠµ"):
            with gr.Row():
                scale_dropdown = gr.Dropdown(
                    choices=list(teacher.scales.keys()),
                    label="ìŠ¤ì¼€ì¼ ì„ íƒ",
                    value="C Major"
                )
                load_scale_btn = gr.Button("ğŸ“š ìŠ¤ì¼€ì¼ ë¡œë“œ")
            
            piano_roll_scale = PianoRoll(height=300)
            scale_status = gr.Textbox(label="ìŠ¤ì¼€ì¼ ì—°ìŠµ ìƒíƒœ", interactive=False)
            
            load_scale_btn.click(
                fn=load_scale_exercise,
                inputs=[scale_dropdown],
                outputs=[piano_roll_scale, scale_status]
            )
        
        with gr.TabItem("ìŒì • ì—°ìŠµ"):
            with gr.Row():
                interval_dropdown = gr.Dropdown(
                    choices=["Perfect 5th", "Major 3rd", "Minor 3rd", "Octave"],
                    label="ìŒì • ì„ íƒ",
                    value="Perfect 5th"
                )
                load_interval_btn = gr.Button("ğŸ“š ìŒì • ë¡œë“œ")
            
            piano_roll_interval = PianoRoll(height=300)
            interval_status = gr.Textbox(label="ìŒì • ì—°ìŠµ ìƒíƒœ", interactive=False)
            
            load_interval_btn.click(
                fn=load_interval_exercise,
                inputs=[interval_dropdown],
                outputs=[piano_roll_interval, interval_status]
            )
    
    with gr.Row():
        check_btn = gr.Button("âœ… ë‹µì•ˆ ê²€ì‚¬", variant="primary")
        result_text = gr.Textbox(label="ê²€ì‚¬ ê²°ê³¼", interactive=False)
    
    # í˜„ì¬ í™œì„± íƒ­ì— ë”°ë¼ ê²€ì‚¬ (ê°„ë‹¨í™”ë¥¼ ìœ„í•´ ìŠ¤ì¼€ì¼ë§Œ)
    check_btn.click(
        fn=check_student_answer,
        inputs=[piano_roll_scale],
        outputs=[result_text]
    )

demo.launch()
```

ì´ ì˜ˆì œë“¤ì€ Gradio PianoRoll ì»´í¬ë„ŒíŠ¸ì˜ ë‹¤ì–‘í•œ í™œìš© ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê° ì˜ˆì œë¥¼ ì°¸ê³ í•˜ì—¬ ìŒì•… êµìœ¡, ì‘ê³¡ ë„êµ¬, ìŒì„± ë¶„ì„ ë“± ë‹¤ì–‘í•œ ëª©ì ì— ë§ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 