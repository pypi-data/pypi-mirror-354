#!/usr/bin/env python3
"""
Advanced Visualization Demo for LLMShark

This example demonstrates the state-of-the-art visualization capabilities
including interactive dashboards, statistical analysis, and performance analytics.
"""

from pathlib import Path
from typing import List

from llmshark.analyzer import StreamAnalyzer
from llmshark.advanced_visualization import AdvancedVisualizer
from llmshark.dashboard_app import launch_dashboard
from llmshark.models import AnalysisResult
from llmshark.parser import PCAPParser
from llmshark.streamlit_dashboard import StreamlitDashboard


def run_visualization_demo(pcap_files: List[Path], output_dir: Path) -> None:
    """Run comprehensive visualization demo."""
    
    print("ü¶à LLMShark Advanced Visualization Demo")
    print("=" * 50)
    
    # 1. Parse PCAP files
    print("\nüìÅ Step 1: Parsing PCAP files...")
    parser = PCAPParser()
    all_sessions = []
    
    for pcap_file in pcap_files:
        print(f"  ‚Ä¢ Processing {pcap_file.name}")
        sessions = parser.parse_file(pcap_file)
        all_sessions.extend(sessions)
        print(f"    Found {len(sessions)} streaming sessions")
    
    if not all_sessions:
        print("‚ùå No streaming sessions found!")
        return
    
    print(f"‚úÖ Total sessions found: {len(all_sessions)}")
    
    # 2. Analyze sessions
    print("\nüî¨ Step 2: Analyzing streaming performance...")
    analyzer = StreamAnalyzer()
    result = analyzer.analyze_sessions(all_sessions, detect_anomalies=True)
    
    print(f"  ‚Ä¢ Session count: {result.session_count}")
    print(f"  ‚Ä¢ Total tokens: {result.total_tokens_analyzed:,}")
    print(f"  ‚Ä¢ Total bytes: {result.total_bytes_analyzed:,}")
    print(f"  ‚Ä¢ Analysis duration: {result.analysis_duration_seconds:.2f}s")
    
    if result.overall_timing_stats.ttft_ms:
        print(f"  ‚Ä¢ Average TTFT: {result.overall_timing_stats.ttft_ms:.1f}ms")
    if result.overall_timing_stats.mean_itl_ms:
        print(f"  ‚Ä¢ Average ITL: {result.overall_timing_stats.mean_itl_ms:.1f}ms")
    if result.overall_timing_stats.tokens_per_second:
        print(f"  ‚Ä¢ Throughput: {result.overall_timing_stats.tokens_per_second:.1f} tokens/sec")
    
    # 3. Generate advanced visualizations
    print("\nüé® Step 3: Creating state-of-the-art visualizations...")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    visualizer = AdvancedVisualizer()
    
    # Interactive Dashboard
    print("  ‚Ä¢ Creating interactive dashboard...")
    dashboard_path = visualizer.create_interactive_dashboard(result, output_dir)
    print(f"    ‚úÖ Dashboard saved: {dashboard_path}")
    
    # Performance Overview
    print("  ‚Ä¢ Generating performance overview...")
    performance_fig = visualizer._create_performance_overview(result)
    performance_path = output_dir / "performance_overview.html"
    performance_fig.write_html(str(performance_path))
    print(f"    ‚úÖ Performance overview: {performance_path}")
    
    # Timeline Analysis
    print("  ‚Ä¢ Creating timeline analysis...")
    timeline_fig = visualizer._create_advanced_timeline(result)
    timeline_path = output_dir / "timeline_analysis.html"
    timeline_fig.write_html(str(timeline_path))
    print(f"    ‚úÖ Timeline analysis: {timeline_path}")
    
    # Statistical Analysis
    print("  ‚Ä¢ Generating statistical distributions...")
    stats_fig = visualizer._create_statistical_distributions(result)
    stats_path = output_dir / "statistical_analysis.html"
    stats_fig.write_html(str(stats_path))
    print(f"    ‚úÖ Statistical analysis: {stats_path}")
    
    # Anomaly Detection
    print("  ‚Ä¢ Creating anomaly detection visualizations...")
    anomaly_fig = visualizer._create_anomaly_detection_viz(result)
    anomaly_path = output_dir / "anomaly_detection.html"
    anomaly_fig.write_html(str(anomaly_path))
    print(f"    ‚úÖ Anomaly detection: {anomaly_path}")
    
    # Correlation Analysis
    print("  ‚Ä¢ Building correlation matrix...")
    correlation_fig = visualizer._create_correlation_matrix(result)
    correlation_path = output_dir / "correlation_matrix.html"
    correlation_fig.write_html(str(correlation_path))
    print(f"    ‚úÖ Correlation matrix: {correlation_path}")
    
    # Performance Clustering
    print("  ‚Ä¢ Performing performance clustering...")
    clustering_fig = visualizer._create_performance_clustering(result)
    clustering_path = output_dir / "performance_clustering.html"
    clustering_fig.write_html(str(clustering_path))
    print(f"    ‚úÖ Performance clustering: {clustering_path}")
    
    # 4. Display summary
    print("\nüìä Step 4: Visualization Summary")
    print("-" * 30)
    
    quality_score = visualizer._calculate_quality_score(result)
    print(f"üåü Overall Quality Score: {quality_score:.0f}/100")
    
    if result.anomalies.large_gaps:
        print(f"‚ö†Ô∏è  Large gaps detected: {len(result.anomalies.large_gaps)}")
    
    if result.anomalies.outlier_chunks:
        print(f"üîç Outlier chunks found: {len(result.anomalies.outlier_chunks)}")
    
    # Key insights
    if result.key_insights:
        print("\nüí° Key Insights:")
        for insight in result.key_insights[:3]:  # Show top 3
            print(f"  ‚Ä¢ {insight}")
    
    # Recommendations
    if result.recommendations:
        print("\nüéØ Top Recommendations:")
        for rec in result.recommendations[:3]:  # Show top 3
            print(f"  ‚Ä¢ {rec}")
    
    print(f"\n‚úÖ All visualizations saved to: {output_dir}")
    print("\nüöÄ Next Steps:")
    print("  1. Open the interactive dashboard in your browser")
    print("  2. Explore individual visualization files")
    print("  3. Use the CLI dashboard command for real-time analysis:")
    print(f"     llmshark dashboard {' '.join(str(f) for f in pcap_files)}")
    
    return result


def demonstrate_dashboard_features(result: AnalysisResult) -> None:
    """Demonstrate dashboard features."""
    
    print("\nüñ•Ô∏è  Dashboard Features Demo")
    print("=" * 30)
    
    print("Available dashboard types:")
    print("  ‚Ä¢ Dash (default) - Advanced interactive components")
    print("  ‚Ä¢ Streamlit - User-friendly interface")
    
    print("\nKey features:")
    print("  üìä Real-time performance metrics")
    print("  üïí Interactive timeline analysis")
    print("  üìà Statistical distributions")
    print("  üîç Anomaly detection with clustering")
    print("  üéØ Performance correlation analysis")
    print("  üìã Exportable reports and data")
    
    print("\nInteractive capabilities:")
    print("  ‚Ä¢ Filter by session, time range, metrics")
    print("  ‚Ä¢ Zoom, pan, hover for detailed data")
    print("  ‚Ä¢ Real-time updates and refresh")
    print("  ‚Ä¢ Export charts as PNG, PDF, HTML")
    print("  ‚Ä¢ CSV data export for further analysis")


def create_sample_report(result: AnalysisResult, output_dir: Path) -> None:
    """Create sample analysis report."""
    
    report = {
        "llmshark_analysis_report": {
            "metadata": {
                "version": "1.0",
                "generated_at": "2024-01-20T10:30:00Z",
                "analysis_type": "streaming_performance"
            },
            "summary": {
                "sessions_analyzed": result.session_count,
                "total_tokens": result.total_tokens_analyzed,
                "total_bytes": result.total_bytes_analyzed,
                "analysis_duration_seconds": result.analysis_duration_seconds
            },
            "performance_metrics": {
                "ttft_ms": result.overall_timing_stats.ttft_ms,
                "mean_itl_ms": result.overall_timing_stats.mean_itl_ms,
                "median_itl_ms": result.overall_timing_stats.median_itl_ms,
                "tokens_per_second": result.overall_timing_stats.tokens_per_second,
                "bytes_per_second": result.overall_timing_stats.bytes_per_second
            },
            "anomalies": {
                "large_gaps_count": len(result.anomalies.large_gaps),
                "outlier_chunks_count": len(result.anomalies.outlier_chunks),
                "unusual_patterns": result.anomalies.unusual_patterns
            },
            "insights": result.key_insights,
            "recommendations": result.recommendations
        }
    }
    
    import json
    report_path = output_dir / "analysis_report.json"
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    print(f"üìã Analysis report saved: {report_path}")


if __name__ == "__main__":
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(
        description="LLMShark Advanced Visualization Demo"
    )
    parser.add_argument(
        "pcap_files",
        nargs="+",
        type=Path,
        help="PCAP files to analyze"
    )
    parser.add_argument(
        "--output-dir",
        "-o",
        type=Path,
        default=Path("demo_output"),
        help="Output directory for visualizations"
    )
    parser.add_argument(
        "--launch-dashboard",
        action="store_true",
        help="Launch interactive dashboard after analysis"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8050,
        help="Port for dashboard (default: 8050)"
    )
    
    args = parser.parse_args()
    
    # Validate input files
    valid_files = []
    for pcap_file in args.pcap_files:
        if pcap_file.exists() and pcap_file.is_file():
            valid_files.append(pcap_file)
        else:
            print(f"‚ùå File not found: {pcap_file}")
    
    if not valid_files:
        print("‚ùå No valid PCAP files provided!")
        sys.exit(1)
    
    # Run demo
    try:
        result = run_visualization_demo(valid_files, args.output_dir)
        
        demonstrate_dashboard_features(result)
        create_sample_report(result, args.output_dir)
        
        if args.launch_dashboard:
            print(f"\nüöÄ Launching dashboard on port {args.port}...")
            launch_dashboard(result, args.port)
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Demo interrupted by user")
    except Exception as e:
        print(f"‚ùå Demo error: {e}")
        sys.exit(1) 