# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: api/model_deployment_manager_service.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from models import model_deployment_pb2 as models_dot_model__deployment__pb2
from models import graph_models_pb2 as models_dot_graph__models__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n*api/model_deployment_manager_service.proto\x12\x03\x61pi\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1dmodels/model_deployment.proto\x1a\x19models/graph_models.proto2\xb2\x04\n\x16ModelDeploymentManager\x12?\n\x15GetCurrentActiveModel\x12\x0e.models.Device\x1a\x16.google.protobuf.Empty\x12\x41\n\x0b\x44\x65ployModel\x12\x1a.models.DeployModelRequest\x1a\x16.google.protobuf.Empty\x12S\n\x18GetModelDeploymentStatus\x12\x1a.models.DeployModelRequest\x1a\x1b.models.DeployModelResponse\x12\x31\n\x08GetModel\x12\x0e.models.Device\x1a\x15.models.ModelArtifact\x12M\n\x12GetLatestArtifacts\x12\x16.google.protobuf.Empty\x1a\x1f.models.ResponseLatestArtifacts\x12U\n\x12GetHistoricConfigs\x12\x1e.models.HistoricConfigsRequest\x1a\x1f.models.HistoricConfigsResponse\x12\x66\n\x19GetDeviceDeploymentStatus\x12#.models.HistoricDeviceDeployRequest\x1a$.models.HistoricDeviceDeployResponseB5\n\x0b\x61i.volt.apiP\x01Z$github.com/vlt-ai/atla/generated/apib\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'api.model_deployment_manager_service_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n\013ai.volt.apiP\001Z$github.com/vlt-ai/atla/generated/api'
  _MODELDEPLOYMENTMANAGER._serialized_start=139
  _MODELDEPLOYMENTMANAGER._serialized_end=701
# @@protoc_insertion_point(module_scope)
