#!/usr/bin/env python3
"""
é«˜æ€§èƒ½åŒ…ç®¡ç†å·¥å…·ç›®å½•æ‰«æå™¨
æ‰«æç³»ç»Ÿä¸­å„ç§ç¼–ç¨‹è¯­è¨€åŒ…ç®¡ç†å·¥å…·çš„ç¼“å­˜ç›®å½•å’Œå¯æ‰§è¡Œæ–‡ä»¶ï¼Œç»Ÿè®¡å¤§å°
"""

import os
import sys
import json
import argparse
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional, Tuple
import time


@dataclass
class ScanResult:
    """æ‰«æç»“æœæ•°æ®ç±»"""
    path: str
    size_bytes: int
    size_human: str
    file_count: int
    tool_type: str
    exists: bool
    error: Optional[str] = None


class PackageScanner:
    """åŒ…ç®¡ç†å·¥å…·ç›®å½•æ‰«æå™¨"""
    
    def __init__(self, max_workers: int = 8):
        self.max_workers = max_workers
        self.results: List[ScanResult] = []
        self.lock = threading.Lock()
        
    def get_package_paths(self) -> Dict[str, List[str]]:
        """è·å–å„ç§åŒ…ç®¡ç†å·¥å…·çš„è·¯å¾„"""
        home = Path.home()

        paths = {
            # Node.js ç”Ÿæ€
            "npm": [
                str(home / ".npm"),
                str(home / ".npm-global"),
            ],
            "yarn": [
                str(home / ".yarn"),
                str(home / ".cache/yarn"),
            ],
            "pnpm": [
                str(home / "pnpm"),
                str(home / ".pnpm-store"),
                str(home / ".local/share/pnpm"),
            ],
            "node_modules": [
                "./node_modules",
                str(home / "node_modules"),
            ],

            # Python ç”Ÿæ€
            "pip": [
                str(home / ".cache/pip"),
                str(home / "Library/Caches/pip"),  # macOS
            ],
            "uv": [
                str(home / ".cache/uv"),
                str(home / "Library/Caches/uv"),  # macOS
            ],
            "conda": [
                str(home / "miniconda3"),
                str(home / "anaconda3"),
                str(home / ".conda"),
            ],
            "python_site_packages": [
                "/usr/local/lib/python*/site-packages",
                str(home / ".local/lib/python*/site-packages"),
            ],

            # Go ç”Ÿæ€
            "go": [
                str(home / "go/pkg"),
                os.environ.get("GOPATH", str(home / "go")) + "/pkg",
                os.environ.get("GOCACHE", str(home / "Library/Caches/go-build")),
            ],

            # Java ç”Ÿæ€
            "maven": [
                str(home / ".m2/repository"),
            ],
            "gradle": [
                str(home / ".gradle/caches"),
                str(home / ".gradle/kotlin"),  # Kotlinç¼“å­˜
            ],

            # PHP ç”Ÿæ€
            "composer": [
                str(home / ".composer/cache"),
                str(home / ".cache/composer"),
                "./vendor",
            ],

            # Ruby ç”Ÿæ€
            "gem": [
                str(home / ".gem"),
                "./vendor/bundle",
            ],

            # Rust ç”Ÿæ€
            "rust_cargo": [
                str(home / ".cargo"),
                str(home / "Library/Caches/cargo"),  # macOS
                str(home / ".rustup"),
            ],

            # C/C++ ç”Ÿæ€
            "cpp_tools": [
                str(home / "Library/Caches/clang"),  # macOS
                str(home / "Library/Caches/cmake"),  # macOS
                str(home / ".cache/clang"),
                str(home / ".cache/cmake"),
                str(home / ".conan"),
                str(home / "vcpkg"),
            ],

            # macOS å¼€å‘å·¥å…·
            "xcode": [
                str(home / "Library/Developer/Xcode"),
                str(home / "Library/Caches/com.apple.dt.Xcode"),
                str(home / "Library/Developer/CoreSimulator"),
                str(home / "Library/Developer/XCTestDevices"),
            ],

            # Swift ç”Ÿæ€
            "swift": [
                str(home / "Library/Caches/org.swift.swiftpm"),
                str(home / ".swiftpm"),
            ],

            # ç§»åŠ¨å¼€å‘
            "flutter": [
                str(home / "Library/Caches/flutter_engine"),  # macOS
                str(home / ".pub-cache"),
                str(home / "flutter"),
            ],

            "android": [
                str(home / "Library/Android"),  # macOS
                str(home / ".android"),
                str(home / "Android"),
            ],

            "react_native": [
                str(home / "Library/Caches/com.facebook.react.packager"),  # macOS
                str(home / ".cache/react-native"),
            ],

            # å®¹å™¨åŒ–å·¥å…·
            "docker": [
                str(home / "Library/Caches/Docker Desktop"),  # macOS
                str(home / "Library/Containers/com.docker.docker"),  # macOS
                str(home / ".docker"),
                str(home / ".local/share/docker"),
            ],

            "podman": [
                str(home / ".local/share/containers"),
                str(home / ".config/containers"),
            ],

            # åŒ…ç®¡ç†å™¨
            "homebrew": [
                str(home / "Library/Caches/Homebrew"),  # macOS
                "/opt/homebrew/var/cache",  # macOS Apple Silicon
                "/usr/local/var/cache",  # macOS Intel
            ],

            "macports": [
                "/opt/local/var/macports",  # macOS
            ],

            # å…¶ä»–ç¼–ç¨‹è¯­è¨€
            "dart": [
                str(home / ".pub-cache"),
                str(home / "Library/Caches/dart"),  # macOS
            ],

            "kotlin": [
                str(home / ".konan"),
                str(home / ".gradle/kotlin"),
            ],

            "scala": [
                str(home / ".ivy2"),
                str(home / ".sbt"),
                str(home / ".cache/coursier"),
            ],

            "haskell": [
                str(home / ".stack"),
                str(home / ".cabal"),
                str(home / ".ghc"),
            ],

            # IDE å’Œç¼–è¾‘å™¨ç¼“å­˜
            "vscode": [
                str(home / "Library/Caches/com.microsoft.VSCode"),  # macOS
                str(home / ".cache/vscode"),
                str(home / ".vscode/extensions"),
            ],

            "jetbrains": [
                str(home / "Library/Caches/JetBrains"),  # macOS
                str(home / ".cache/JetBrains"),
                str(home / "Library/Application Support/JetBrains"),  # macOS
            ],

            "sublime": [
                str(home / "Library/Caches/com.sublimetext.3"),  # macOS
                str(home / "Library/Caches/com.sublimetext.4"),  # macOS
            ],

            # æ„å»ºå·¥å…·
            "cmake": [
                str(home / "Library/Caches/cmake"),  # macOS
                str(home / ".cache/cmake"),
            ],

            "bazel": [
                str(home / ".cache/bazel"),
                str(home / "Library/Caches/bazel"),  # macOS
            ],

            "ninja": [
                str(home / ".ninja_log"),
            ],

            # å…¶ä»–å·¥å…·
            "conan": [
                str(home / ".conan"),
                str(home / ".conan2"),
            ],

            "vcpkg": [
                str(home / "vcpkg"),
                "./vcpkg",
            ],

            # å¯æ‰§è¡Œæ–‡ä»¶ç›®å½•
            "executables": [
                "/usr/local/bin",
                str(home / ".local/bin"),
                str(home / "bin"),
                "/opt/homebrew/bin",  # macOS Homebrew
                "/opt/local/bin",  # macOS MacPorts
            ],
        }

        # æ·»åŠ ç¯å¢ƒå˜é‡ä¸­çš„è·¯å¾„
        if "PATH" in os.environ:
            for path in os.environ["PATH"].split(os.pathsep):
                if any(keyword in path.lower() for keyword in ["node", "python", "go", "java", "php", "ruby"]):
                    paths.setdefault("executables", []).append(path)
        
        return paths
    
    def calculate_directory_size(self, path: str) -> Tuple[int, int]:
        """è®¡ç®—ç›®å½•å¤§å°å’Œæ–‡ä»¶æ•°é‡"""
        total_size = 0
        file_count = 0
        
        try:
            path_obj = Path(path)
            if not path_obj.exists():
                return 0, 0
                
            if path_obj.is_file():
                return path_obj.stat().st_size, 1
                
            # ä½¿ç”¨ os.scandir æé«˜æ€§èƒ½
            for entry in os.scandir(path):
                try:
                    if entry.is_file(follow_symlinks=False):
                        total_size += entry.stat().st_size
                        file_count += 1
                    elif entry.is_dir(follow_symlinks=False):
                        dir_size, dir_files = self.calculate_directory_size(entry.path)
                        total_size += dir_size
                        file_count += dir_files
                except (OSError, PermissionError):
                    continue
                    
        except (OSError, PermissionError) as e:
            return 0, 0
            
        return total_size, file_count
    
    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} PB"
    
    def scan_path(self, path: str, tool_type: str) -> ScanResult:
        """æ‰«æå•ä¸ªè·¯å¾„"""
        try:
            path_obj = Path(path)
            exists = path_obj.exists()
            
            if not exists:
                return ScanResult(
                    path=path,
                    size_bytes=0,
                    size_human="0 B",
                    file_count=0,
                    tool_type=tool_type,
                    exists=False
                )
            
            size_bytes, file_count = self.calculate_directory_size(path)
            size_human = self.format_size(size_bytes)
            
            return ScanResult(
                path=path,
                size_bytes=size_bytes,
                size_human=size_human,
                file_count=file_count,
                tool_type=tool_type,
                exists=True
            )
            
        except Exception as e:
            return ScanResult(
                path=path,
                size_bytes=0,
                size_human="0 B",
                file_count=0,
                tool_type=tool_type,
                exists=False,
                error=str(e)
            )
    
    def scan_all(self, show_progress: bool = True) -> List[ScanResult]:
        """æ‰«ææ‰€æœ‰è·¯å¾„"""
        package_paths = self.get_package_paths()
        all_tasks = []
        
        # å‡†å¤‡æ‰€æœ‰æ‰«æä»»åŠ¡
        for tool_type, paths in package_paths.items():
            for path in paths:
                all_tasks.append((path, tool_type))
        
        print(f"å¼€å§‹æ‰«æ {len(all_tasks)} ä¸ªè·¯å¾„...")
        
        # å¹¶å‘æ‰§è¡Œæ‰«æ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_task = {
                executor.submit(self.scan_path, path, tool_type): (path, tool_type)
                for path, tool_type in all_tasks
            }
            
            completed = 0
            for future in as_completed(future_to_task):
                result = future.result()
                
                with self.lock:
                    self.results.append(result)
                    completed += 1
                    
                if show_progress:
                    print(f"è¿›åº¦: {completed}/{len(all_tasks)} ({completed/len(all_tasks)*100:.1f}%)", end="\r")
        
        if show_progress:
            print()  # æ¢è¡Œ
            
        return self.results
    
    def get_summary(self) -> Dict:
        """è·å–æ‰«æç»“æœæ‘˜è¦"""
        existing_results = [r for r in self.results if r.exists and r.size_bytes > 0]

        total_size = sum(r.size_bytes for r in existing_results)
        total_files = sum(r.file_count for r in existing_results)

        # æŒ‰å·¥å…·ç±»å‹åˆ†ç»„
        by_tool = {}
        for result in existing_results:
            if result.tool_type not in by_tool:
                by_tool[result.tool_type] = {
                    "size_bytes": 0,
                    "file_count": 0,
                    "paths": []
                }
            by_tool[result.tool_type]["size_bytes"] += result.size_bytes
            by_tool[result.tool_type]["file_count"] += result.file_count
            by_tool[result.tool_type]["paths"].append({
                "path": result.path,
                "size_bytes": result.size_bytes,
                "size_human": result.size_human,
                "file_count": result.file_count
            })

        # æ·»åŠ äººç±»å¯è¯»çš„å¤§å°
        for tool_data in by_tool.values():
            tool_data["size_human"] = self.format_size(tool_data["size_bytes"])

        return {
            "total_size_bytes": total_size,
            "total_size_human": self.format_size(total_size),
            "total_files": total_files,
            "scanned_paths": len(self.results),
            "existing_paths": len(existing_results),
            "by_tool": by_tool
        }

    def generate_cleanup_report(self) -> str:
        """ç”Ÿæˆæ¸…ç†æ•™ç¨‹æŠ¥å‘Š"""
        summary = self.get_summary()
        existing_results = [r for r in self.results if r.exists and r.size_bytes > 0]

        # æ¸…ç†è§„åˆ™å®šä¹‰
        cleanup_rules = {
            "docker": {
                "priority": "ğŸš¨ æé«˜ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "docker system prune -a --volumes  # æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨çš„é•œåƒã€å®¹å™¨ã€ç½‘ç»œå’Œå·",
                    "docker image prune -a  # ä»…æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ",
                    "docker container prune  # ä»…æ¸…ç†åœæ­¢çš„å®¹å™¨"
                ],
                "description": "Dockerå®¹å™¨å’Œé•œåƒç¼“å­˜",
                "impact": "åˆ é™¤æœªä½¿ç”¨çš„Dockerèµ„æºï¼Œä¸å½±å“æ­£åœ¨è¿è¡Œçš„å®¹å™¨",
                "rebuild_time": "é‡æ–°æ‹‰å–é•œåƒéœ€è¦æ—¶é—´ï¼Œå–å†³äºç½‘ç»œé€Ÿåº¦"
            },
            "jetbrains": {
                "priority": "ğŸ”¥ é«˜ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "# æ‰‹åŠ¨æ¸…ç†JetBrainsç¼“å­˜ç›®å½•",
                    "find ~/Library/Caches/JetBrains -name 'caches' -type d -exec rm -rf {} +",
                    "find ~/Library/Caches/JetBrains -name 'tmp' -type d -exec rm -rf {} +",
                    "# æˆ–è€…ç›´æ¥åˆ é™¤æ•´ä¸ªç¼“å­˜ç›®å½•",
                    "rm -rf ~/Library/Caches/JetBrains"
                ],
                "description": "JetBrains IDEç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶",
                "impact": "IDEé¦–æ¬¡å¯åŠ¨ä¼šé‡å»ºç´¢å¼•ï¼Œå¯åŠ¨é€Ÿåº¦å˜æ…¢",
                "rebuild_time": "é‡å»ºç´¢å¼•éœ€è¦å‡ åˆ†é’Ÿåˆ°å‡ ååˆ†é’Ÿ"
            },
            "uv": {
                "priority": "âš ï¸ ä¸­ç­‰ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "uv cache clean  # æ¸…ç†æ‰€æœ‰uvç¼“å­˜",
                    "uv cache clean --package <package_name>  # æ¸…ç†ç‰¹å®šåŒ…ç¼“å­˜"
                ],
                "description": "Python uvåŒ…ç®¡ç†å™¨ç¼“å­˜",
                "impact": "ä¸‹æ¬¡å®‰è£…åŒ…æ—¶éœ€è¦é‡æ–°ä¸‹è½½",
                "rebuild_time": "é‡æ–°ä¸‹è½½åŒ…çš„æ—¶é—´å–å†³äºç½‘ç»œé€Ÿåº¦"
            },
            "pip": {
                "priority": "âš ï¸ ä¸­ç­‰ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "pip cache purge  # æ¸…ç†æ‰€æœ‰pipç¼“å­˜",
                    "pip cache remove <package_name>  # æ¸…ç†ç‰¹å®šåŒ…ç¼“å­˜"
                ],
                "description": "Python pipåŒ…ç¼“å­˜",
                "impact": "ä¸‹æ¬¡å®‰è£…åŒ…æ—¶éœ€è¦é‡æ–°ä¸‹è½½",
                "rebuild_time": "é‡æ–°ä¸‹è½½åŒ…çš„æ—¶é—´å–å†³äºç½‘ç»œé€Ÿåº¦"
            },
            "npm": {
                "priority": "âš ï¸ ä¸­ç­‰ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "npm cache clean --force  # å¼ºåˆ¶æ¸…ç†npmç¼“å­˜",
                    "npm cache verify  # éªŒè¯ç¼“å­˜å®Œæ•´æ€§"
                ],
                "description": "Node.js npmåŒ…ç¼“å­˜",
                "impact": "ä¸‹æ¬¡å®‰è£…åŒ…æ—¶éœ€è¦é‡æ–°ä¸‹è½½",
                "rebuild_time": "é‡æ–°ä¸‹è½½åŒ…çš„æ—¶é—´å–å†³äºç½‘ç»œé€Ÿåº¦"
            },
            "rust_cargo": {
                "priority": "âš ï¸ ä¸­ç­‰ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "cargo cache --autoclean  # éœ€è¦å…ˆå®‰è£…cargo-cache",
                    "cargo install cargo-cache  # å®‰è£…cargo-cacheå·¥å…·",
                    "rm -rf ~/.cargo/registry/cache  # æ‰‹åŠ¨æ¸…ç†æ³¨å†Œè¡¨ç¼“å­˜",
                    "rm -rf ~/.cargo/git/checkouts  # æ¸…ç†gitæ£€å‡ºç¼“å­˜"
                ],
                "description": "Rust CargoåŒ…ç¼“å­˜å’Œå·¥å…·é“¾",
                "impact": "é‡æ–°ç¼–è¯‘é¡¹ç›®æ—¶éœ€è¦é‡æ–°ä¸‹è½½ä¾èµ–",
                "rebuild_time": "é‡æ–°ç¼–è¯‘å’Œä¸‹è½½ä¾èµ–éœ€è¦è¾ƒé•¿æ—¶é—´"
            },
            "vscode": {
                "priority": "ğŸ“ ä½ä¼˜å…ˆçº§",
                "safety": "âš ï¸ è°¨æ…",
                "risk_level": "ä¸­é£é™©",
                "commands": [
                    "rm -rf ~/Library/Caches/com.microsoft.VSCode  # æ¸…ç†VS Codeç¼“å­˜",
                    "# æ‰©å±•ç›®å½•å»ºè®®æ‰‹åŠ¨æ£€æŸ¥åæ¸…ç†",
                    "ls ~/.vscode/extensions  # æŸ¥çœ‹å·²å®‰è£…æ‰©å±•"
                ],
                "description": "VS Codeç¼“å­˜å’Œæ‰©å±•",
                "impact": "å¯èƒ½éœ€è¦é‡æ–°é…ç½®æ‰©å±•å’Œè®¾ç½®",
                "rebuild_time": "é‡æ–°å®‰è£…æ‰©å±•éœ€è¦å‡ åˆ†é’Ÿ"
            },
            "go": {
                "priority": "ğŸ“ ä½ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "go clean -cache  # æ¸…ç†æ„å»ºç¼“å­˜",
                    "go clean -modcache  # æ¸…ç†æ¨¡å—ç¼“å­˜",
                    "go clean -testcache  # æ¸…ç†æµ‹è¯•ç¼“å­˜"
                ],
                "description": "Goè¯­è¨€æ„å»ºå’Œæ¨¡å—ç¼“å­˜",
                "impact": "é‡æ–°ç¼–è¯‘é¡¹ç›®æ—¶éœ€è¦é‡æ–°ä¸‹è½½æ¨¡å—",
                "rebuild_time": "é‡æ–°ç¼–è¯‘å’Œä¸‹è½½æ¨¡å—éœ€è¦ä¸€äº›æ—¶é—´"
            },
            "homebrew": {
                "priority": "ğŸ“ ä½ä¼˜å…ˆçº§",
                "safety": "âœ… å®‰å…¨",
                "risk_level": "ä½é£é™©",
                "commands": [
                    "brew cleanup  # æ¸…ç†æ—§ç‰ˆæœ¬å’Œç¼“å­˜",
                    "brew autoremove  # ç§»é™¤ä¸éœ€è¦çš„ä¾èµ–",
                    "brew cleanup --prune=all  # æ¸…ç†æ‰€æœ‰ç¼“å­˜"
                ],
                "description": "HomebrewåŒ…ç®¡ç†å™¨ç¼“å­˜",
                "impact": "é‡æ–°å®‰è£…åŒ…æ—¶éœ€è¦é‡æ–°ä¸‹è½½",
                "rebuild_time": "é‡æ–°ä¸‹è½½åŒ…çš„æ—¶é—´å–å†³äºç½‘ç»œé€Ÿåº¦"
            },
            "executables": {
                "priority": "â„¹ï¸ ä¿¡æ¯å‚è€ƒ",
                "safety": "âš ï¸ è°¨æ…",
                "risk_level": "é«˜é£é™©",
                "commands": [
                    "# å¯æ‰§è¡Œæ–‡ä»¶ç›®å½• - ä»…ä¾›å‚è€ƒï¼Œè¯·å‹¿éšæ„åˆ é™¤",
                    "# è¿™äº›æ˜¯ç³»ç»Ÿå’Œå¼€å‘å·¥å…·çš„å¯æ‰§è¡Œæ–‡ä»¶",
                    "# åˆ é™¤å¯èƒ½å¯¼è‡´ç³»ç»Ÿæˆ–å¼€å‘ç¯å¢ƒæ— æ³•æ­£å¸¸å·¥ä½œ"
                ],
                "description": "ç³»ç»Ÿå’Œå¼€å‘å·¥å…·å¯æ‰§è¡Œæ–‡ä»¶",
                "impact": "åˆ é™¤å¯èƒ½å¯¼è‡´ç³»ç»Ÿæˆ–å¼€å‘ç¯å¢ƒæ— æ³•æ­£å¸¸å·¥ä½œ",
                "rebuild_time": "éœ€è¦é‡æ–°å®‰è£…ç›¸å…³å·¥å…·å’Œç¯å¢ƒ"
            }
        }

        # ç”ŸæˆæŠ¥å‘Š
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ§¹ å¼€å‘å·¥å…·ç¼“å­˜æ¸…ç†æ•™ç¨‹æŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append(f"ğŸ“Š æ‰«æç»“æœ: {summary['total_size_human']} ({summary['total_files']:,} æ–‡ä»¶)")
        report_lines.append(f"ğŸ“ æ‰«æè·¯å¾„: {summary['scanned_paths']} ä¸ª")
        report_lines.append(f"âœ… å‘ç°ç¼“å­˜: {summary['existing_paths']} ä¸ª")
        report_lines.append("")

        # æŒ‰å¤§å°æ’åºå·¥å…·
        sorted_tools = sorted(summary["by_tool"].items(),
                            key=lambda x: x[1]["size_bytes"], reverse=True)

        # è®¡ç®—å¯æ¸…ç†çš„æ€»ç©ºé—´
        cleanable_size = 0
        high_priority_size = 0

        for tool_type, tool_data in sorted_tools:
            if tool_type in cleanup_rules:
                cleanable_size += tool_data["size_bytes"]
                if "æé«˜ä¼˜å…ˆçº§" in cleanup_rules[tool_type]["priority"] or "é«˜ä¼˜å…ˆçº§" in cleanup_rules[tool_type]["priority"]:
                    high_priority_size += tool_data["size_bytes"]

        report_lines.append(f"ğŸ’¾ å¯æ¸…ç†ç©ºé—´: {self.format_size(cleanable_size)}")
        report_lines.append(f"ğŸš¨ é«˜ä¼˜å…ˆçº§å¯æ¸…ç†: {self.format_size(high_priority_size)}")
        report_lines.append("")

        # ç”Ÿæˆæ¸…ç†å»ºè®®
        report_lines.append("ğŸ“‹ æ¸…ç†å»ºè®® (æŒ‰ä¼˜å…ˆçº§æ’åº)")
        report_lines.append("=" * 50)

        for tool_type, tool_data in sorted_tools:
            if tool_data["size_bytes"] > 0:
                # å¦‚æœæœ‰æ¸…ç†è§„åˆ™ï¼Œæ˜¾ç¤ºæ¸…ç†å»ºè®®
                if tool_type in cleanup_rules:
                    rule = cleanup_rules[tool_type]
                    report_lines.append("")
                    report_lines.append(f"{rule['priority']} {rule['description']}")
                    report_lines.append(f"ğŸ“¦ å¤§å°: {tool_data['size_human']} ({tool_data['file_count']:,} æ–‡ä»¶)")
                    report_lines.append(f"ğŸ›¡ï¸  å®‰å…¨æ€§: {rule['safety']} ({rule['risk_level']})")
                    report_lines.append(f"ğŸ“ å½±å“: {rule['impact']}")
                    report_lines.append(f"â±ï¸  é‡å»ºæ—¶é—´: {rule['rebuild_time']}")
                    report_lines.append("ğŸ”§ æ¸…ç†å‘½ä»¤:")
                    for cmd in rule['commands']:
                        report_lines.append(f"   {cmd}")
                else:
                    # æ²¡æœ‰æ¸…ç†è§„åˆ™çš„å·¥å…·ï¼Œä»…æ˜¾ç¤ºä¿¡æ¯
                    report_lines.append("")
                    report_lines.append(f"ğŸ“Š ä¿¡æ¯å‚è€ƒ {tool_type.upper()}")
                    report_lines.append(f"ğŸ“¦ å¤§å°: {tool_data['size_human']} ({tool_data['file_count']:,} æ–‡ä»¶)")
                    report_lines.append("â„¹ï¸  è¯´æ˜: æ­¤ç±»æ–‡ä»¶ä»…ä¾›å‚è€ƒï¼Œå»ºè®®è°¨æ…å¤„ç†")

                # æ˜¾ç¤ºå…·ä½“è·¯å¾„å’Œæ–‡ä»¶å¤§å°æ¸…å•
                if len(tool_data['paths']) > 0:
                    report_lines.append("ğŸ“ è¯¦ç»†è·¯å¾„æ¸…å•:")
                    for path_info in sorted(tool_data['paths'], key=lambda x: x['size_bytes'], reverse=True):
                        if path_info['size_bytes'] > 0:
                            report_lines.append(f"   ğŸ“‚ {path_info['path']}")
                            report_lines.append(f"      ğŸ’¾ å¤§å°: {path_info['size_human']}")
                            report_lines.append(f"      ğŸ“„ æ–‡ä»¶æ•°: {path_info['file_count']:,}")

                report_lines.append("-" * 50)

        # æ·»åŠ æ³¨æ„äº‹é¡¹
        report_lines.append("")
        report_lines.append("âš ï¸  é‡è¦æ³¨æ„äº‹é¡¹")
        report_lines.append("=" * 30)
        report_lines.append("1. ğŸ”’ æ¸…ç†å‰è¯·ç¡®ä¿é‡è¦æ•°æ®å·²å¤‡ä»½")
        report_lines.append("2. ğŸš« ä¸è¦æ¸…ç†æ­£åœ¨ä½¿ç”¨çš„é¡¹ç›®ç›®å½•")
        report_lines.append("3. ğŸ“‹ å»ºè®®æŒ‰ä¼˜å…ˆçº§é¡ºåºé€ä¸ªæ¸…ç†")
        report_lines.append("4. ğŸ” æ¸…ç†åå¯é‡æ–°è¿è¡Œæ‰«ææŸ¥çœ‹æ•ˆæœ")
        report_lines.append("5. ğŸ’¡ å®šæœŸæ¸…ç†å¯ä¿æŒç³»ç»Ÿæ€§èƒ½")
        report_lines.append("")
        report_lines.append("ğŸ”„ é‡æ–°æ‰«æå‘½ä»¤:")
        report_lines.append("   python3 package_scanner.py")
        report_lines.append("")

        return "\n".join(report_lines)


def main():
    parser = argparse.ArgumentParser(description="æ‰«æç³»ç»Ÿä¸­åŒ…ç®¡ç†å·¥å…·çš„ç›®å½•å¤§å°")
    parser.add_argument("--workers", type=int, default=8, help="å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument("--output", choices=["table", "json", "cleanup"], default="cleanup", help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--file", help="è¾“å‡ºåˆ°æ–‡ä»¶", default="æ¸…ç†æŠ¥å‘Š.md")

    args = parser.parse_args()

    scanner = PackageScanner(max_workers=args.workers)

    start_time = time.time()
    results = scanner.scan_all()
    end_time = time.time()

    summary = scanner.get_summary()

    if args.output == "cleanup":
        # ç”Ÿæˆæ¸…ç†æ•™ç¨‹æŠ¥å‘Š
        output_text = scanner.generate_cleanup_report()
    elif args.output == "json":
        output_data = {
            "summary": summary,
            "results": [asdict(r) for r in results if r.exists and r.size_bytes > 0],
            "scan_time_seconds": end_time - start_time
        }
        output_text = json.dumps(output_data, indent=2, ensure_ascii=False)
    else:
        # è¡¨æ ¼è¾“å‡º
        output_lines = []
        output_lines.append("=" * 80)
        output_lines.append("åŒ…ç®¡ç†å·¥å…·ç›®å½•å¤§å°ç»Ÿè®¡")
        output_lines.append("=" * 80)
        output_lines.append(f"æ€»å¤§å°: {summary['total_size_human']}")
        output_lines.append(f"æ€»æ–‡ä»¶æ•°: {summary['total_files']:,}")
        output_lines.append(f"æ‰«ææ—¶é—´: {end_time - start_time:.2f} ç§’")
        output_lines.append("")

        for tool_type, tool_data in sorted(summary["by_tool"].items(),
                                         key=lambda x: x[1]["size_bytes"], reverse=True):
            output_lines.append(f"{tool_type.upper()}: {tool_data['size_human']} ({tool_data['file_count']:,} æ–‡ä»¶)")
            for path_info in sorted(tool_data["paths"], key=lambda x: x["size_bytes"], reverse=True):
                if path_info["size_bytes"] > 0:
                    output_lines.append(f"  {path_info['path']}: {path_info['size_human']} ({path_info['file_count']:,} æ–‡ä»¶)")
            output_lines.append("")

        output_text = "\n".join(output_lines)

    if args.file:
        with open(args.file, 'w', encoding='utf-8') as f:
            f.write(output_text)
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.file}")
    else:
        print(output_text)


if __name__ == "__main__":
    main()
