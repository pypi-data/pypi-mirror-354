Metadata-Version: 2.1
Name: ladder-ai
Version: 0.1.9
Summary: Ladder + TTFT LLM Finetuning
Author-Email: abdelrahman abounida <abdelrahmanaboneda@gmail.com>
License: MIT
Requires-Python: >=3.11
Requires-Dist: typing-extensions>=4.13.2
Requires-Dist: loguru>=0.7.3
Requires-Dist: pydantic>=2.11.3
Requires-Dist: dspy>=2.6.5
Requires-Dist: python-dotenv>=1.1.0
Requires-Dist: pandas>=2.2.3
Description-Content-Type: text/markdown

# Ladder + TTFT

Custom Ladder implementation on any Complex problem for LLM. a reimplementation of the paper “LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION”
https://arxiv.org/pdf/2503.00735

![workflow](./assets/workflow_version2.svg)

## Finetuned Qwen2-0.5B with Ladder (Model Response)

![Ladder-Finetuned](./assets/finetuned-ladder-answer.png)

# setup

## install from source using PDM

```bash
git clone git@github.com:AbdelrahmanAbounida/ladder.git
cd ladder
pdm install
```

# Run

## our main usecase (Graph problem)

```bash
python src/main.py
```

## TODO

### Dataset Generation

- [x] LLM Intelligence ratio Equation
- [x] Custom Verification Method if required (for our Graph Usecase)
- [x] DatasetGenerator > Generate subproblems according to the model intelligence ratio (step3)
- [x] Difficulty Engine should decide the level of difficulty to be generated and what transformations to be applied
- [x] Verification engine should use the small llm to be tuned not the Larger one
- [ ] LLM Engine (temperature cycling and persona based prompts for different operations like variant generation)

### Ladder

- [x] Ladder Finetuning Process
- [x] GRPO Implementation
- [x] reward functions

### TTRL

- [x] TTRL Implementation
- [x] Data Generation in a loop

### Others

- [x] General Configurations for all Constants and Hyper Parameters
- [x] implement different interfaced for different models to be used (HF, Ollama, VLLM, deepspeed, LiteLLM,..)
- [x] LLMS Benchmarking
- [x] Metrics and other evaluation methods
- [ ] implement more usecases if required for diverse benchmarking
- [ ] use accelerate / PEFT / deepspeed and vllm to speed up training process

### Production

- [x] Documentation
- [x] packaging
- [x] CICD
- [ ] Testing
