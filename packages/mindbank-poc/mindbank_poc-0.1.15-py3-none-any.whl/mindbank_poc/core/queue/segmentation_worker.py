"""
–§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤.
"""
import asyncio
from typing import Dict, List, Set, Optional
from datetime import datetime
import time

from mindbank_poc.common.logging import get_logger
from mindbank_poc.core.config.settings import settings
from mindbank_poc.core.enrichment import SegmentationService
from mindbank_poc.core.knowledge_store import get_knowledge_store
from mindbank_poc.core.knowledge_store.base import KnowledgeStore
from mindbank_poc.core.providers.segmentation import register_segmentation_providers

logger = get_logger(__name__)


class SegmentationWorker:
    """
    –§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
    –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —é–Ω–∏—Ç–æ–≤ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
    """
    
    def __init__(
        self, 
        knowledge_store: Optional[KnowledgeStore] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–æ—Ä–∫–µ—Ä–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
        
        Args:
            knowledge_store: –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        self.knowledge_store = knowledge_store or get_knowledge_store()
        
        self.segmentation_service = SegmentationService(
            knowledge_store=self.knowledge_store
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.enabled = settings.enrichment.enabled
        self.threshold = settings.enrichment.segmentation_threshold
        self.segmentation_timeout_sec = settings.enrichment.segmentation_timeout_sec
        self.check_interval = settings.enrichment.check_interval_seconds
        self.batch_size = settings.enrichment.batch_size
        
        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self._running = False
        self._task: Optional[asyncio.Task] = None
        self._processed_units: Set[str] = set()  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã
        self._group_last_change: Dict[str, float] = {}  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
        self._group_unit_counts: Dict[str, int] = {}  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —é–Ω–∏—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
        logger.info(
            f"SegmentationWorker initialized: "
            f"enabled={self.enabled}, threshold={self.threshold}, "
            f"timeout={self.segmentation_timeout_sec}s, "
            f"check_interval={self.check_interval}s"
        )
    
    async def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä."""
        if not self.enabled:
            logger.info("SegmentationWorker is disabled in settings")
            return
            
        if self._running:
            logger.warning("SegmentationWorker is already running")
            return
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        register_segmentation_providers()
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        from mindbank_poc.core.providers.clustering import register_clustering_providers
        register_clustering_providers()
        
        self._running = True
        self._task = asyncio.create_task(self._run_worker())
        logger.info("SegmentationWorker started")
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä."""
        if not self._running:
            return
            
        self._running = False
        
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        
        logger.info("SegmentationWorker stopped")
    
    async def _run_worker(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞."""
        logger.info("SegmentationWorker main loop started")
        
        while self._running:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–µ—Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã
                await self._check_and_process()
                
                # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                await asyncio.sleep(self.check_interval)
                
            except asyncio.CancelledError:
                logger.info("SegmentationWorker loop cancelled")
                break
            except Exception as e:
                logger.error(f"Error in SegmentationWorker loop: {e}", exc_info=True)
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏
                await asyncio.sleep(self.check_interval)
    
    async def _check_and_process(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≥—Ä—É–ø–ø —Å –Ω–æ–≤—ã–º–∏ —é–Ω–∏—Ç–∞–º–∏ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é."""
        try:
            # –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–±: –∏—â–µ–º –≥—Ä—É–ø–ø—ã —Å –Ω–æ–≤—ã–º–∏ —é–Ω–∏—Ç–∞–º–∏ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            if hasattr(self.knowledge_store, 'get_groups_with_new_units_for_segmentation'):
                groups_to_process = await self.knowledge_store.get_groups_with_new_units_for_segmentation(self.threshold)
            else:
                # Fallback: —Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞
                groups_to_process = []
                if hasattr(self.knowledge_store, 'list_unprocessed_groups'):
                    groups_to_process = await self.knowledge_store.list_unprocessed_groups(self.threshold)
                else:
                    groups_to_process = await self._get_unprocessed_groups_fallback()

            if not groups_to_process:
                logger.debug("No groups qualifying for segmentation (new units)")
                return

            logger.info(f"üìã Processing {len(groups_to_process)} groups with new units for segmentation")

            for group_id in groups_to_process:
                try:
                    await self._process_group(group_id)
                except Exception as e:
                    logger.error(f"Error processing group {group_id}: {e}", exc_info=True)
        except Exception as e:
            logger.error(f"Error in check_and_process: {e}", exc_info=True)
    
    async def _process_group(self, group_id: str):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥—Ä—É–ø–ø—É –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.
        """
        logger.info(f"Processing group {group_id} for segmentation")
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —é–Ω–∏—Ç—ã –≥—Ä—É–ø–ø—ã
            if hasattr(self.knowledge_store, 'list_by_group'):
                units = await self.knowledge_store.list_by_group(group_id)
            else:
                all_units = await self.knowledge_store.list_all()
                units = [u for u in all_units if u.group_id == group_id]

            if not units:
                logger.warning(f"No units found for group {group_id}")
                return

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            units_sorted = sorted(units, key=lambda u: u.normalized_at or getattr(u, 'stored_at', ""))
            last_unit = units_sorted[-1]

            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
            segments = await self.segmentation_service.segment_group(group_id)

            if segments:
                logger.info(f"Created {len(segments)} segments for group {group_id}")
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≥—Ä—É–ø–ø—ã
                if hasattr(self.knowledge_store, 'set_group_segmentation_meta'):
                    await self.knowledge_store.set_group_segmentation_meta(
                        group_id,
                        last_segmented_at=datetime.utcnow().isoformat(),
                        last_segmented_unit_id=last_unit.id
                    )
            else:
                logger.warning(f"No segments created for group {group_id}")
        except Exception as e:
            logger.error(f"Error processing group {group_id}: {e}", exc_info=True)
            raise
    
    def get_stats(self) -> Dict[str, any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –≤–æ—Ä–∫–µ—Ä–∞.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        return {
            "running": self._running,
            "enabled": self.enabled,
            "threshold": self.threshold,
            "timeout": self.segmentation_timeout_sec,
            "check_interval": self.check_interval,
            "processed_units_count": len(self._processed_units),
            "batch_size": self.batch_size
        } 