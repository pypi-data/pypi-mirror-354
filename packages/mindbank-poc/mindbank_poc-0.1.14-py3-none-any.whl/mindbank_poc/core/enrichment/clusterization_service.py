"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–Ω–∞–Ω–∏–π.
"""
import time
from typing import List, Optional, Dict, Any
from datetime import datetime

from mindbank_poc.common.logging import get_logger
from mindbank_poc.core.config.settings import settings
from mindbank_poc.core.knowledge_store.base import KnowledgeStore
from mindbank_poc.core.enrichment.models import SegmentModel, ClusterModel
from mindbank_poc.core.services.provider_service import get_provider_service
from mindbank_poc.core.providers.selector import ProviderSelector
from mindbank_poc.core.common.types import ProviderType

logger = get_logger(__name__)


class ClusterizationService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–Ω–∞–Ω–∏–π."""
    
    def __init__(self, knowledge_store: KnowledgeStore):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.
        
        Args:
            knowledge_store: –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
        """
        self.knowledge_store = knowledge_store
        self.provider_service = get_provider_service()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        self.cluster_min_pending = getattr(settings.enrichment, 'cluster_min_pending', 500)
        self.cluster_timeout_sec = getattr(settings.enrichment, 'cluster_timeout_sec', 3600)
        
        # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        self.last_run_timestamp = 0
        
        logger.info(f"ClusterizationService initialized with min_pending={self.cluster_min_pending}, "
                   f"timeout={self.cluster_timeout_sec}s")
    
    async def get_unclustered_segments(self) -> List[SegmentModel]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –±—ã–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω—ã.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–µ–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            all_segments = []
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            if hasattr(self.knowledge_store, 'list_all_segments'):
                all_segments = await self.knowledge_store.list_all_segments()
                logger.info(f"üìä Retrieved {len(all_segments)} total segments via list_all_segments()")
            else:
                # Fallback: –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ –≥—Ä—É–ø–ø—ã
                group_ids = await self._get_all_group_ids()
                logger.info(f"üìä Found {len(group_ids)} groups, getting segments...")
                for group_id in group_ids:
                    segments = await self.knowledge_store.list_segments_by_group(group_id)
                    all_segments.extend(segments)
                    logger.debug(f"  Group {group_id}: {len(segments)} segments")
                logger.info(f"üìä Retrieved {len(all_segments)} total segments via groups")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º ID –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            clustered_segment_ids = set()
            try:
                all_clusters = await self.knowledge_store.list_clusters()
                logger.info(f"üìä Found {len(all_clusters)} existing clusters")
                
                for cluster in all_clusters:
                    clustered_segment_ids.update(cluster.segment_ids)
                    logger.debug(f"  Cluster {cluster.id[:8]}... contains {len(cluster.segment_ids)} segments")
                
                logger.info(f"üìä Total clustered segment IDs: {len(clustered_segment_ids)}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not retrieve clusters (maybe none exist yet): {e}")
                clustered_segment_ids = set()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            unclustered = []
            clustered_count = 0
            
            for segment in all_segments:
                if segment.id not in clustered_segment_ids:
                    unclustered.append(segment)
                    logger.debug(f"  Unclustered: {segment.id[:8]}...")
                else:
                    clustered_count += 1
                    logger.debug(f"  Clustered: {segment.id[:8]}...")
            
            logger.info(f"üìä Segments status: {len(unclustered)} unclustered, {clustered_count} already clustered")
            return unclustered
            
        except Exception as e:
            logger.error(f"‚ùå Error getting unclustered segments: {e}")
            return []
    
    async def _get_all_group_ids(self) -> List[str]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID –≥—Ä—É–ø–ø –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö group_id
        """
        try:
            if hasattr(self.knowledge_store, 'list_group_ids'):
                return list(await self.knowledge_store.list_group_ids())
            
            # Fallback: –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ –≤—Å–µ —é–Ω–∏—Ç—ã
            if hasattr(self.knowledge_store, 'list_all'):
                all_units = await self.knowledge_store.list_all()
                group_ids = set()
                for unit in all_units:
                    if unit.group_id:
                        group_ids.add(unit.group_id)
                return list(group_ids)
            
            return []
        except Exception as e:
            logger.error(f"Error getting group IDs: {e}")
            return []
    
    def should_run_clustering(self, pending_count: int) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é —Å–µ–π—á–∞—Å.
        
        Args:
            pending_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            
        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
        """
        current_time = time.time()
        time_since_last_run = current_time - self.last_run_timestamp
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –∑–∞–ø—É—Å–∫–∞
        min_count_reached = pending_count >= self.cluster_min_pending
        timeout_reached = time_since_last_run >= self.cluster_timeout_sec
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ª–æ–≤–∏–π
        logger.info(f"üìä Clustering conditions check:")
        logger.info(f"  ‚Ä¢ Pending segments: {pending_count} (min required: {self.cluster_min_pending}) ‚Üí {'‚úÖ' if min_count_reached else '‚ùå'}")
        logger.info(f"  ‚Ä¢ Time since last run: {time_since_last_run:.0f}s (timeout: {self.cluster_timeout_sec}s) ‚Üí {'‚úÖ' if timeout_reached else '‚ùå'}")
        logger.info(f"  ‚Ä¢ Last run timestamp: {self.last_run_timestamp} ({datetime.fromtimestamp(self.last_run_timestamp) if self.last_run_timestamp > 0 else 'Never'})")
        
        should_run = min_count_reached or timeout_reached
        logger.info(f"  ‚Ä¢ Result: {'üöÄ WILL RUN clustering' if should_run else '‚è∏Ô∏è WILL SKIP clustering'}")
        
        return should_run
    
    async def _select_clustering_provider(self, segments: List[SegmentModel]) -> Optional[Any]:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤.
        
        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –≠–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ None
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            providers = self.provider_service.get_all_providers()
            clustering_providers = [
                p for p in providers 
                if p.provider_type == ProviderType.CLUSTERING
            ]
            
            if not clustering_providers:
                logger.warning("No clustering providers found in system")
                return self._create_fallback_provider()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            first_segment = segments[0] if segments else None
            metadata = {}
            archetype = "generic"
            source = "unknown"
            
            if first_segment and first_segment.metadata:
                metadata = first_segment.metadata.get("source_metadata", {})
                source = metadata.get("source", "unknown")
                # TODO: –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞—Ä—Ö–µ—Ç–∏–ø–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä
            provider_model = ProviderSelector.select_provider(
                providers=[p.dict(exclude={"instance"}) for p in clustering_providers],
                provider_type=ProviderType.CLUSTERING.value,
                archetype=archetype,
                source=source,
                metadata=metadata
            )
            
            if not provider_model:
                logger.warning("No clustering provider selected by ProviderSelector, using fallback")
                return self._create_fallback_provider()
            
            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            provider_class = self._get_provider_class(provider_model.get('id'))
            if not provider_class:
                logger.error(f"Provider class not found for {provider_model.get('id')}, using fallback")
                return self._create_fallback_provider()
            
            try:
                provider_instance = provider_class(provider_model.get('current_config', {}))
                logger.info(f"Successfully created clustering provider: {provider_model.get('id')}")
                return provider_instance
            except Exception as e:
                logger.error(f"Failed to create provider instance for {provider_model.get('id')}: {e}, using fallback")
                return self._create_fallback_provider()
                
        except Exception as e:
            logger.error(f"Error in clustering provider selection: {e}, using fallback provider")
            return self._create_fallback_provider()
    
    def _get_provider_class(self, provider_id: str):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–ª–∞—Å—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ –µ–≥–æ ID.
        
        Args:
            provider_id: ID –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            
        Returns:
            –ö–ª–∞—Å—Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏–ª–∏ None
        """
        try:
            from mindbank_poc.core.providers.clustering import (
                KMeansClusterProvider,
                MockClusterProvider
            )
            
            provider_classes = {
                "kmeans-clustering": KMeansClusterProvider,
                "mock-clustering": MockClusterProvider
            }
            
            return provider_classes.get(provider_id, MockClusterProvider)
        except ImportError as e:
            logger.error(f"Failed to import clustering providers: {e}")
            return None
    
    def _create_fallback_provider(self) -> Optional[Any]:
        """
        –°–æ–∑–¥–∞–µ—Ç fallback –ø—Ä–æ–≤–∞–π–¥–µ—Ä (Mock) –≤ —Å–ª—É—á–∞–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.
        
        Returns:
            –≠–∫–∑–µ–º–ø–ª—è—Ä mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏–ª–∏ None
        """
        try:
            from mindbank_poc.core.providers.clustering import MockClusterProvider
            logger.info("Using MockClusterProvider as fallback")
            return MockClusterProvider({})
        except Exception as e:
            logger.error(f"Failed to create fallback clustering provider: {e}")
            return None
    
    async def run_clustering_if_needed(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ª–æ–≤–∏—è.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            unclustered_segments = await self.get_unclustered_segments()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
            if not self.should_run_clustering(len(unclustered_segments)):
                return {
                    "action": "skipped",
                    "reason": f"Not enough segments ({len(unclustered_segments)}) or timeout not reached",
                    "unclustered_count": len(unclustered_segments)
                }
            
            if not unclustered_segments:
                self.last_run_timestamp = time.time()
                return {
                    "action": "skipped",
                    "reason": "No unclustered segments found",
                    "unclustered_count": 0
                }
            
            logger.info(f"Starting clustering of {len(unclustered_segments)} segments")
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            provider = await self._select_clustering_provider(unclustered_segments)
            if not provider:
                return {
                    "action": "failed",
                    "reason": "No clustering provider available",
                    "unclustered_count": len(unclustered_segments)
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ metadata
            provider_class_name = provider.__class__.__name__
            self._current_provider_name = provider_class_name
            self._current_provider_type = "clustering"
            logger.info(f"üîß Using clustering provider: {provider_class_name}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
            cluster_results = await provider.cluster(unclustered_segments)
            
            if not cluster_results:
                logger.info("Clustering provider returned empty results (clustering disabled or failed)")
                self.last_run_timestamp = time.time()
                return {
                    "action": "completed",
                    "reason": "Clustering disabled or returned empty results",
                    "unclustered_count": len(unclustered_segments),
                    "clusters_created": 0
                }
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏
            created_count = await self._update_segments_with_clusters(cluster_results)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
            try:
                stored_clusters = await self.knowledge_store.list_clusters()
                logger.info(f"üîç Verification: Found {len(stored_clusters)} total clusters in storage")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–µ–∂–µ—Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
                recent_clusters = [
                    c for c in stored_clusters 
                    if c.metadata.get('clustering_provider') == self._current_provider_name
                ]
                logger.info(f"üìä Of which {len(recent_clusters)} were created by {self._current_provider_name}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not verify cluster storage: {e}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
            self.last_run_timestamp = time.time()
            
            logger.info(f"üéØ Clustering completed successfully: {len(cluster_results)} clusters created, "
                       f"covering {sum(len(info.get('segment_ids', [])) for info in cluster_results.values())} segments")
            
            return {
                "action": "completed",
                "reason": "Clustering completed successfully",
                "unclustered_count": len(unclustered_segments),
                "clusters_created": len(cluster_results),
                "clusters_stored": created_count,
                "cluster_info": {
                    cluster_id: {
                        "title": info.get("title", ""),
                        "size": len(info.get("segment_ids", [])),
                        "keywords": info.get("keywords", [])[:5]  # –ü–µ—Ä–≤—ã–µ 5 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    }
                    for cluster_id, info in cluster_results.items()
                }
            }
            
        except Exception as e:
            logger.error(f"Error during clustering: {e}", exc_info=True)
            return {
                "action": "failed",
                "reason": f"Error during clustering: {str(e)}",
                "unclustered_count": len(unclustered_segments) if 'unclustered_segments' in locals() else 0
            }
    
    async def _update_segments_with_clusters(self, cluster_results: Dict[int, Dict[str, Any]]) -> int:
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏.
        
        Args:
            cluster_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        """
        created_count = 0
        
        try:
            for cluster_id, cluster_info in cluster_results.items():
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
                    provider_name = getattr(self, '_current_provider_name', 'unknown')
                    provider_type = getattr(self, '_current_provider_type', 'clustering')
                    
                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç ClusterModel —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    cluster = ClusterModel(
                        title=cluster_info.get("title", f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}"),
                        summary=cluster_info.get("summary", ""),
                        keywords=cluster_info.get("keywords", []),
                        segment_ids=cluster_info.get("segment_ids", []),
                        centroid=cluster_info.get("centroid"),
                        cluster_size=cluster_info.get("size", len(cluster_info.get("segment_ids", []))),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º size –µ—Å–ª–∏ –µ—Å—Ç—å
                        metadata={
                            "clustering_provider": provider_name,
                            "clustering_algorithm": f"{provider_type}_algorithm",
                            "cluster_original_id": cluster_id,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π ID –∏–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                            "cluster_stats": {
                                "original_size": cluster_info.get("size", 0),
                                "has_centroid": cluster_info.get("centroid") is not None,
                                "keywords_count": len(cluster_info.get("keywords", []))
                            }
                        }
                    )
                    
                    logger.info(f"üîß Creating cluster {cluster_id} with {cluster.cluster_size} segments")
                    logger.debug(f"  Title: {cluster.title}")
                    logger.debug(f"  Keywords: {cluster.keywords[:3]}...")
                    logger.debug(f"  Provider: {provider_name}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                    await self.knowledge_store.store_cluster(cluster)
                    created_count += 1
                    
                    logger.info(f"‚úÖ Successfully created and stored cluster {cluster.id} with {cluster.cluster_size} segments")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error creating cluster {cluster_id}: {e}", exc_info=True)
                    continue
            
            logger.info(f"üéØ Created {created_count} clusters successfully out of {len(cluster_results)} total")
            return created_count
            
        except Exception as e:
            logger.error(f"‚ùå Error creating clusters from results: {e}", exc_info=True)
            return created_count 